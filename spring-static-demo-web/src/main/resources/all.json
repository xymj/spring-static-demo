{
  "retrievers": {
    "MultiQueryRetriever": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "prompt": {
          "type": "Text",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "prompt",
          "display_name": "Prompt",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "retriever": {
          "type": "BaseRetriever",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "retriever",
          "display_name": "Retriever",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain.retrievers import MultiQueryRetriever\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseRetriever, LanguageModel, PromptTemplate, Text\n\n\nclass MultiQueryRetrieverComponent(CustomComponent):\n    display_name = \"MultiQueryRetriever\"\n    description = \"Initialize from llm using default template.\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/retrievers/how_to/MultiQueryRetriever\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"prompt\": {\n                \"display_name\": \"Prompt\",\n                \"default\": {\n                    \"input_variables\": [\"question\"],\n                    \"input_types\": {},\n                    \"output_parser\": None,\n                    \"partial_variables\": {},\n                    \"template\": \"You are an AI language model assistant. Your task is \\n\"\n                    \"to generate 3 different versions of the given user \\n\"\n                    \"question to retrieve relevant documents from a vector database. \\n\"\n                    \"By generating multiple perspectives on the user question, \\n\"\n                    \"your goal is to help the user overcome some of the limitations \\n\"\n                    \"of distance-based similarity search. Provide these alternative \\n\"\n                    \"questions separated by newlines. Original question: {question}\",\n                    \"template_format\": \"f-string\",\n                    \"validate_template\": False,\n                    \"_type\": \"prompt\",\n                },\n            },\n            \"retriever\": {\"display_name\": \"Retriever\"},\n            \"parser_key\": {\"display_name\": \"Parser Key\", \"default\": \"lines\"},\n        }\n\n    def build(\n        self,\n        llm: LanguageModel,\n        retriever: BaseRetriever,\n        prompt: Optional[Text] = None,\n        parser_key: str = \"lines\",\n    ) -> MultiQueryRetriever:\n        if not prompt:\n            return MultiQueryRetriever.from_llm(llm=llm, retriever=retriever, parser_key=parser_key)\n        else:\n            prompt_template = PromptTemplate.from_template(prompt)\n            return MultiQueryRetriever.from_llm(\n                llm=llm, retriever=retriever, prompt=prompt_template, parser_key=parser_key\n            )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "parser_key": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "lines",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "parser_key",
          "display_name": "Parser Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Initialize from llm using default template.",
      "base_classes": [
        "BaseRetriever",
        "Generic",
        "MultiQueryRetriever",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable"
      ],
      "display_name": "MultiQueryRetriever",
      "documentation": "https://python.langchain.com/docs/modules/data_connection/retrievers/how_to/MultiQueryRetriever",
      "custom_fields": {
        "llm": null,
        "retriever": null,
        "prompt": null,
        "parser_key": null
      },
      "output_types": [
        "MultiQueryRetriever"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "MultiQueryRetriever"
          ],
          "selected": "MultiQueryRetriever",
          "name": "multiqueryretriever",
          "hidden": null,
          "display_name": "MultiQueryRetriever",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "SelfQueryRetriever": {
      "template": {
        "_type": "CustomComponent",
        "attribute_infos": {
          "type": "Data",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "attribute_infos",
          "display_name": "Metadata Field Info",
          "advanced": false,
          "dynamic": false,
          "info": "Metadata Field Info to be passed as input.",
          "load_from_db": false,
          "title_case": false
        },
        "document_content_description": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "document_content_description",
          "display_name": "Document Content Description",
          "advanced": false,
          "dynamic": false,
          "info": "Document Content Description to be passed as input.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "LLM to be passed as input.",
          "load_from_db": false,
          "title_case": false
        },
        "query": {
          "type": "Message",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "query",
          "display_name": "Query",
          "advanced": false,
          "input_types": [
            "Message",
            "Text"
          ],
          "dynamic": false,
          "info": "Query to be passed as input.",
          "load_from_db": false,
          "title_case": false
        },
        "vectorstore": {
          "type": "VectorStore",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "vectorstore",
          "display_name": "Vector Store",
          "advanced": false,
          "dynamic": false,
          "info": "Vector Store to be passed as input.",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "# from langflow.field_typing import Data\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain_core.vectorstores import VectorStore\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import LanguageModel, Text\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass SelfQueryRetrieverComponent(CustomComponent):\n    display_name: str = \"Self Query Retriever\"\n    description: str = \"Retriever that uses a vector store and an LLM to generate the vector store queries.\"\n    icon = \"LangChain\"\n\n    def build_config(self):\n        return {\n            \"query\": {\n                \"display_name\": \"Query\",\n                \"input_types\": [\"Message\", \"Text\"],\n                \"info\": \"Query to be passed as input.\",\n            },\n            \"vectorstore\": {\n                \"display_name\": \"Vector Store\",\n                \"info\": \"Vector Store to be passed as input.\",\n            },\n            \"attribute_infos\": {\n                \"display_name\": \"Metadata Field Info\",\n                \"info\": \"Metadata Field Info to be passed as input.\",\n            },\n            \"document_content_description\": {\n                \"display_name\": \"Document Content Description\",\n                \"info\": \"Document Content Description to be passed as input.\",\n            },\n            \"llm\": {\n                \"display_name\": \"LLM\",\n                \"info\": \"LLM to be passed as input.\",\n            },\n        }\n\n    def build(\n        self,\n        query: Message,\n        vectorstore: VectorStore,\n        attribute_infos: list[Data],\n        document_content_description: Text,\n        llm: LanguageModel,\n    ) -> Data:\n        metadata_field_infos = [AttributeInfo(**value.data) for value in attribute_infos]\n        self_query_retriever = SelfQueryRetriever.from_llm(\n            llm=llm,\n            vectorstore=vectorstore,\n            document_contents=document_content_description,\n            metadata_field_info=metadata_field_infos,\n            enable_limit=True,\n        )\n\n        if isinstance(query, Message):\n            input_text = query.text\n        elif isinstance(query, str):\n            input_text = query\n\n        if not isinstance(query, str):\n            raise ValueError(f\"Query type {type(query)} not supported.\")\n        documents = self_query_retriever.invoke(input=input_text)\n        data = [Data.from_document(document) for document in documents]\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Retriever that uses a vector store and an LLM to generate the vector store queries.",
      "icon": "LangChain",
      "base_classes": [
        "Data"
      ],
      "display_name": "Self Query Retriever",
      "documentation": "",
      "custom_fields": {
        "query": null,
        "vectorstore": null,
        "attribute_infos": null,
        "document_content_description": null,
        "llm": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "AmazonKendra": {
      "template": {
        "_type": "CustomComponent",
        "attribute_filter": {
          "type": "dict",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "attribute_filter",
          "display_name": "Attribute Filter",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional, cast\n\nfrom langchain_community.retrievers import AmazonKendraRetriever\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Retriever\n\n\nclass AmazonKendraRetrieverComponent(CustomComponent):\n    display_name: str = \"Amazon Kendra Retriever\"\n    description: str = \"Retriever that uses the Amazon Kendra API.\"\n    icon = \"Amazon\"\n\n    def build_config(self):\n        return {\n            \"index_id\": {\"display_name\": \"Index ID\"},\n            \"region_name\": {\"display_name\": \"Region Name\"},\n            \"credentials_profile_name\": {\"display_name\": \"Credentials Profile Name\"},\n            \"attribute_filter\": {\n                \"display_name\": \"Attribute Filter\",\n                \"field_type\": \"code\",\n            },\n            \"top_k\": {\"display_name\": \"Top K\", \"field_type\": \"int\"},\n            \"user_context\": {\n                \"display_name\": \"User Context\",\n                \"field_type\": \"code\",\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        index_id: str,\n        top_k: int = 3,\n        region_name: Optional[str] = None,\n        credentials_profile_name: Optional[str] = None,\n        attribute_filter: Optional[dict] = None,\n        user_context: Optional[dict] = None,\n    ) -> Retriever:  # type: ignore[type-var]\n        try:\n            output = AmazonKendraRetriever(\n                index_id=index_id,\n                top_k=top_k,\n                region_name=region_name,\n                credentials_profile_name=credentials_profile_name,\n                attribute_filter=attribute_filter,\n                user_context=user_context,\n            )  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to AmazonKendra API.\") from e\n        return cast(Retriever, output)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "credentials_profile_name": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "credentials_profile_name",
          "display_name": "Credentials Profile Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "index_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "index_id",
          "display_name": "Index ID",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "region_name": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "region_name",
          "display_name": "Region Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "top_k": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 3,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "top_k",
          "display_name": "Top K",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "user_context": {
          "type": "dict",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "user_context",
          "display_name": "User Context",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Retriever that uses the Amazon Kendra API.",
      "icon": "Amazon",
      "base_classes": [
        "Retriever"
      ],
      "display_name": "Amazon Kendra Retriever",
      "documentation": "",
      "custom_fields": {
        "index_id": null,
        "top_k": null,
        "region_name": null,
        "credentials_profile_name": null,
        "attribute_filter": null,
        "user_context": null
      },
      "output_types": [
        "Retriever"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "retriever",
          "hidden": null,
          "display_name": "Retriever",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "VectorStoreRetriever": {
      "template": {
        "_type": "CustomComponent",
        "vectorstore": {
          "type": "VectorStore",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "vectorstore",
          "display_name": "Vector Store",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_core.vectorstores import VectorStoreRetriever\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import VectorStore\n\n\nclass VectoStoreRetrieverComponent(CustomComponent):\n    display_name = \"VectorStore Retriever\"\n    description = \"A vector store retriever\"\n\n    def build_config(self):\n        return {\n            \"vectorstore\": {\"display_name\": \"Vector Store\", \"type\": VectorStore},\n        }\n\n    def build(self, vectorstore: VectorStore) -> VectorStoreRetriever:\n        return vectorstore.as_retriever()\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "A vector store retriever",
      "base_classes": [
        "BaseRetriever",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable",
        "VectorStoreRetriever"
      ],
      "display_name": "VectorStore Retriever",
      "documentation": "",
      "custom_fields": {
        "vectorstore": null
      },
      "output_types": [
        "VectorStoreRetriever"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "VectorStoreRetriever"
          ],
          "selected": "VectorStoreRetriever",
          "name": "vectorstoreretriever",
          "hidden": null,
          "display_name": "VectorStoreRetriever",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "MetalRetriever": {
      "template": {
        "_type": "CustomComponent",
        "api_key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "api_key",
          "display_name": "API Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "client_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "client_id",
          "display_name": "Client ID",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional, cast\n\nfrom langchain_community.retrievers import MetalRetriever\nfrom metal_sdk.metal import Metal  # type: ignore\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Retriever\n\n\nclass MetalRetrieverComponent(CustomComponent):\n    display_name: str = \"Metal Retriever\"\n    description: str = \"Retriever that uses the Metal API.\"\n\n    def build_config(self):\n        return {\n            \"api_key\": {\"display_name\": \"API Key\", \"password\": True},\n            \"client_id\": {\"display_name\": \"Client ID\", \"password\": True},\n            \"index_id\": {\"display_name\": \"Index ID\"},\n            \"params\": {\"display_name\": \"Parameters\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(self, api_key: str, client_id: str, index_id: str, params: Optional[dict] = None) -> Retriever:  # type: ignore[type-var]\n        try:\n            metal = Metal(api_key=api_key, client_id=client_id, index_id=index_id)\n        except Exception as e:\n            raise ValueError(\"Could not connect to Metal API.\") from e\n        return cast(Retriever, MetalRetriever(client=metal, params=params or {}))\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "index_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "index_id",
          "display_name": "Index ID",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "params": {
          "type": "dict",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "params",
          "display_name": "Parameters",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Retriever that uses the Metal API.",
      "base_classes": [
        "Retriever"
      ],
      "display_name": "Metal Retriever",
      "documentation": "",
      "custom_fields": {
        "api_key": null,
        "client_id": null,
        "index_id": null,
        "params": null
      },
      "output_types": [
        "Retriever"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "retriever",
          "hidden": null,
          "display_name": "Retriever",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "CohereRerank": {
      "template": {
        "_type": "Component",
        "retriever": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "retriever",
          "display_name": "Retriever",
          "advanced": false,
          "input_types": [
            "Retriever"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "api_key",
          "display_name": "API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List, cast\n\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain_cohere import CohereRerank\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.field_typing import Retriever\nfrom langflow.io import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, SecretStrInput\nfrom langflow.schema import Data\n\n\nclass CohereRerankComponent(LCVectorStoreComponent):\n    display_name = \"Cohere Rerank\"\n    description = \"Rerank documents using the Cohere API and a retriever.\"\n    icon = \"Cohere\"\n\n    inputs = [\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\n                \"rerank-english-v3.0\",\n                \"rerank-multilingual-v3.0\",\n                \"rerank-english-v2.0\",\n                \"rerank-multilingual-v2.0\",\n            ],\n            value=\"rerank-english-v3.0\",\n        ),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        IntInput(name=\"top_n\", display_name=\"Top N\", value=3),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", value=\"langflow\", advanced=True),\n        HandleInput(name=\"retriever\", display_name=\"Retriever\", input_types=[\"Retriever\"]),\n    ]\n\n    def build_base_retriever(self) -> Retriever:  # type: ignore[type-var]\n        cohere_reranker = CohereRerank(\n            cohere_api_key=self.api_key, model=self.model, top_n=self.top_n, user_agent=self.user_agent\n        )\n        retriever = ContextualCompressionRetriever(base_compressor=cohere_reranker, base_retriever=self.retriever)\n        return cast(Retriever, retriever)\n\n    async def search_documents(self) -> List[Data]:  # type: ignore\n        retriever = self.build_base_retriever()\n        documents = await retriever.ainvoke(self.search_query)\n        data = self.to_data(documents)\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "model": {
          "trace_as_metadata": true,
          "options": [
            "rerank-english-v3.0",
            "rerank-multilingual-v3.0",
            "rerank-english-v2.0",
            "rerank-multilingual-v2.0"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "rerank-english-v3.0",
          "name": "model",
          "display_name": "Model",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "top_n": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 3,
          "name": "top_n",
          "display_name": "Top N",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "user_agent": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "langflow",
          "name": "user_agent",
          "display_name": "User Agent",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Rerank documents using the Cohere API and a retriever.",
      "icon": "Cohere",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Cohere Rerank",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "search_query",
        "model",
        "api_key",
        "top_n",
        "user_agent",
        "retriever"
      ],
      "beta": false,
      "edited": false
    },
    "VectaraSelfQueryRetriver": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "For self query retriever",
          "load_from_db": false,
          "title_case": false
        },
        "vectorstore": {
          "type": "VectorStore",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "vectorstore",
          "display_name": "Vector Store",
          "advanced": false,
          "dynamic": false,
          "info": "Input Vectara Vectore Store",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "import json\nfrom typing import List, cast\n\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain_core.vectorstores import VectorStore\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Retriever\nfrom langflow.field_typing.constants import LanguageModel\n\n\nclass VectaraSelfQueryRetriverComponent(CustomComponent):\n    \"\"\"\n    A custom component for implementing Vectara Self Query Retriever using a vector store.\n    \"\"\"\n\n    display_name: str = \"Vectara Self Query Retriever for Vectara Vector Store\"\n    description: str = \"Implementation of Vectara Self Query Retriever\"\n    documentation = \"https://python.langchain.com/docs/integrations/retrievers/self_query/vectara_self_query\"\n    icon = \"Vectara\"\n\n    field_config = {\n        \"code\": {\"show\": True},\n        \"vectorstore\": {\"display_name\": \"Vector Store\", \"info\": \"Input Vectara Vectore Store\"},\n        \"llm\": {\"display_name\": \"LLM\", \"info\": \"For self query retriever\"},\n        \"document_content_description\": {\n            \"display_name\": \"Document Content Description\",\n            \"info\": \"For self query retriever\",\n        },\n        \"metadata_field_info\": {\n            \"display_name\": \"Metadata Field Info\",\n            \"info\": 'Each metadata field info is a string in the form of key value pair dictionary containing additional search metadata.\\nExample input: {\"name\":\"speech\",\"description\":\"what name of the speech\",\"type\":\"string or list[string]\"}.\\nThe keys should remain constant(name, description, type)',\n        },\n    }\n\n    def build(\n        self,\n        vectorstore: VectorStore,\n        document_content_description: str,\n        llm: LanguageModel,\n        metadata_field_info: List[str],\n    ) -> Retriever:  # type: ignore\n        metadata_field_obj = []\n\n        for meta in metadata_field_info:\n            meta_obj = json.loads(meta)\n            if \"name\" not in meta_obj or \"description\" not in meta_obj or \"type\" not in meta_obj:\n                raise Exception(\"Incorrect metadata field info format.\")\n            attribute_info = AttributeInfo(\n                name=meta_obj[\"name\"],\n                description=meta_obj[\"description\"],\n                type=meta_obj[\"type\"],\n            )\n            metadata_field_obj.append(attribute_info)\n\n        return cast(\n            Retriever,\n            SelfQueryRetriever.from_llm(\n                llm, vectorstore, document_content_description, metadata_field_obj, verbose=True\n            ),\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "document_content_description": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "document_content_description",
          "display_name": "Document Content Description",
          "advanced": false,
          "dynamic": false,
          "info": "For self query retriever",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "metadata_field_info": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "metadata_field_info",
          "display_name": "Metadata Field Info",
          "advanced": false,
          "dynamic": false,
          "info": "Each metadata field info is a string in the form of key value pair dictionary containing additional search metadata.\nExample input: {\"name\":\"speech\",\"description\":\"what name of the speech\",\"type\":\"string or list[string]\"}.\nThe keys should remain constant(name, description, type)",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Implementation of Vectara Self Query Retriever",
      "icon": "Vectara",
      "base_classes": [
        "Retriever"
      ],
      "display_name": "Vectara Self Query Retriever for Vectara Vector Store",
      "documentation": "https://python.langchain.com/docs/integrations/retrievers/self_query/vectara_self_query",
      "custom_fields": {
        "vectorstore": null,
        "document_content_description": null,
        "llm": null,
        "metadata_field_info": null
      },
      "output_types": [
        "Retriever"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "retriever",
          "hidden": null,
          "display_name": "Retriever",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "code",
        "vectorstore",
        "llm",
        "document_content_description",
        "metadata_field_info"
      ],
      "beta": false,
      "edited": false
    }
  },
  "tools": {
    "SearchApi": {
      "template": {
        "_type": "CustomComponent",
        "api_key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "api_key",
          "display_name": "API Key",
          "advanced": false,
          "dynamic": false,
          "info": "The API key to use SearchApi.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Data\nfrom langflow.services.database.models.base import orjson_dumps\n\n\nclass SearchApi(CustomComponent):\n    display_name: str = \"SearchApi\"\n    description: str = \"Real-time search engine results API.\"\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://www.searchapi.io/docs/google\"\n    field_config = {\n        \"engine\": {\n            \"display_name\": \"Engine\",\n            \"field_type\": \"str\",\n            \"info\": \"The search engine to use.\",\n        },\n        \"params\": {\n            \"display_name\": \"Parameters\",\n            \"info\": \"The parameters to send with the request.\",\n        },\n        \"code\": {\"show\": False},\n        \"api_key\": {\n            \"display_name\": \"API Key\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"password\": True,\n            \"info\": \"The API key to use SearchApi.\",\n        },\n    }\n\n    def build(\n        self,\n        engine: str,\n        api_key: str,\n        params: Optional[dict] = None,\n    ) -> Data:\n        if params is None:\n            params = {}\n\n        search_api_wrapper = SearchApiAPIWrapper(engine=engine, searchapi_api_key=api_key)\n\n        q = params.pop(\"q\", \"SearchApi Langflow\")\n        results = search_api_wrapper.results(q, **params)\n\n        result = orjson_dumps(results, indent_2=False)\n\n        record = Data(data=result)\n        self.status = record\n        return record\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "engine": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "engine",
          "display_name": "Engine",
          "advanced": false,
          "dynamic": false,
          "info": "The search engine to use.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "params": {
          "type": "dict",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "params",
          "display_name": "Parameters",
          "advanced": false,
          "dynamic": false,
          "info": "The parameters to send with the request.",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Real-time search engine results API.",
      "base_classes": [
        "Data"
      ],
      "display_name": "SearchApi",
      "documentation": "https://www.searchapi.io/docs/google",
      "custom_fields": {
        "engine": null,
        "api_key": null,
        "params": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "engine",
        "params",
        "code",
        "api_key"
      ],
      "beta": false,
      "edited": false
    },
    "PythonCodeStructuredTool": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "import ast\nfrom typing import Any, Dict, List, Optional\n\nfrom langchain.agents import Tool\nfrom langchain.tools import StructuredTool\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(CustomComponent):\n    display_name = \"PythonCodeTool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    icon = \"ðŸ\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\", \"tool_class\"]\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"tool_code\": {\n                \"display_name\": \"Tool Code\",\n                \"info\": \"Enter the dataclass code.\",\n                \"placeholder\": \"def my_function(args):\\n    pass\",\n                \"multiline\": True,\n                \"refresh_button\": True,\n                \"field_type\": \"code\",\n            },\n            \"name\": {\n                \"display_name\": \"Tool Name\",\n                \"info\": \"Enter the name of the tool.\",\n            },\n            \"description\": {\n                \"display_name\": \"Description\",\n                \"info\": \"Provide a brief description of what the tool does.\",\n            },\n            \"return_direct\": {\n                \"display_name\": \"Return Directly\",\n                \"info\": \"Should the tool return the function output directly?\",\n            },\n            \"tool_function\": {\n                \"display_name\": \"Tool Function\",\n                \"info\": \"Select the function for additional expressions.\",\n                \"options\": [],\n                \"refresh_button\": True,\n            },\n            \"tool_class\": {\n                \"display_name\": \"Tool Class\",\n                \"info\": \"Select the class for additional expressions.\",\n                \"options\": [],\n                \"refresh_button\": True,\n                \"required\": False,\n            },\n        }\n\n    def parse_source_name(self, code: str) -> Dict:\n        parsed_code = ast.parse(code)\n        class_names = [node.name for node in parsed_code.body if isinstance(node, ast.ClassDef)]\n        function_names = [node.name for node in parsed_code.body if isinstance(node, ast.FunctionDef)]\n        return {\"class\": class_names, \"function\": function_names}\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"tool_code\" or field_name == \"tool_function\" or field_name == \"tool_class\":\n            try:\n                names = self.parse_source_name(build_config.tool_code.value)\n                build_config.tool_class.options = names[\"class\"]\n                build_config.tool_function.options = names[\"function\"]\n            except Exception as e:\n                self.status = f\"Failed to extract class names: {str(e)}\"\n                build_config.tool_class.options = [\"Failed to parse\", str(e)]\n                build_config.tool_function.options = []\n        return build_config\n\n    async def build(\n        self,\n        tool_code: str,\n        name: str,\n        description: str,\n        tool_function: List[str],\n        return_direct: bool,\n        tool_class: Optional[List[str]] = None,\n    ) -> Tool:\n        local_namespace = {}  # type: ignore\n        exec(tool_code, globals(), local_namespace)\n\n        func = local_namespace[tool_function]\n        _class = None\n\n        if tool_class:\n            _class = local_namespace[tool_class]\n\n        tool = StructuredTool.from_function(\n            func=func, args_schema=_class, name=name, description=description, return_direct=return_direct\n        )\n        return tool  # type: ignore\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "description": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "description",
          "display_name": "Description",
          "advanced": false,
          "dynamic": false,
          "info": "Provide a brief description of what the tool does.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "name",
          "display_name": "Tool Name",
          "advanced": false,
          "dynamic": false,
          "info": "Enter the name of the tool.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "return_direct": {
          "type": "bool",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "return_direct",
          "display_name": "Return Directly",
          "advanced": false,
          "dynamic": false,
          "info": "Should the tool return the function output directly?",
          "load_from_db": false,
          "title_case": false
        },
        "tool_class": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [],
          "name": "tool_class",
          "display_name": "Tool Class",
          "advanced": false,
          "dynamic": false,
          "info": "Select the class for additional expressions.",
          "refresh_button": true,
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "tool_code": {
          "type": "str",
          "required": true,
          "placeholder": "def my_function(args):\n    pass",
          "list": false,
          "show": true,
          "multiline": true,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "tool_code",
          "display_name": "Tool Code",
          "advanced": false,
          "dynamic": false,
          "info": "Enter the dataclass code.",
          "refresh_button": true,
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "tool_function": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [],
          "name": "tool_function",
          "display_name": "Tool Function",
          "advanced": false,
          "dynamic": false,
          "info": "Select the function for additional expressions.",
          "refresh_button": true,
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "structuredtool dataclass code to tool",
      "icon": "ðŸ",
      "base_classes": [
        "BaseTool",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable",
        "Tool"
      ],
      "display_name": "PythonCodeTool",
      "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
      "custom_fields": {
        "tool_code": null,
        "name": null,
        "description": null,
        "tool_function": null,
        "return_direct": null,
        "tool_class": null
      },
      "output_types": [
        "Tool"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Tool"
          ],
          "selected": "Tool",
          "name": "tool",
          "hidden": null,
          "display_name": "Tool",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "name",
        "description",
        "tool_code",
        "return_direct",
        "tool_function",
        "tool_class"
      ],
      "beta": false,
      "edited": false
    },
    "SearchAPITool": {
      "template": {
        "_type": "CustomComponent",
        "api_key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "api_key",
          "display_name": "API Key",
          "advanced": false,
          "dynamic": false,
          "info": "The API key to use SearchApi.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_community.tools.searchapi import SearchAPIRun\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Tool\n\n\nclass SearchApiToolComponent(CustomComponent):\n    display_name: str = \"SearchApi Tool\"\n    description: str = \"Real-time search engine results API.\"\n    documentation: str = \"https://www.searchapi.io/docs/google\"\n    field_config = {\n        \"engine\": {\n            \"display_name\": \"Engine\",\n            \"field_type\": \"str\",\n            \"info\": \"The search engine to use.\",\n        },\n        \"api_key\": {\n            \"display_name\": \"API Key\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"password\": True,\n            \"info\": \"The API key to use SearchApi.\",\n        },\n    }\n\n    def build(\n        self,\n        engine: str,\n        api_key: str,\n    ) -> Tool:\n        search_api_wrapper = SearchApiAPIWrapper(engine=engine, searchapi_api_key=api_key)\n\n        tool = SearchAPIRun(api_wrapper=search_api_wrapper)\n\n        self.status = tool\n        return tool  # type: ignore\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "engine": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "engine",
          "display_name": "Engine",
          "advanced": false,
          "dynamic": false,
          "info": "The search engine to use.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Real-time search engine results API.",
      "base_classes": [
        "BaseTool",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable",
        "Tool"
      ],
      "display_name": "SearchApi Tool",
      "documentation": "https://www.searchapi.io/docs/google",
      "custom_fields": {
        "engine": null,
        "api_key": null
      },
      "output_types": [
        "Tool"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Tool"
          ],
          "selected": "Tool",
          "name": "tool",
          "hidden": null,
          "display_name": "Tool",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "engine",
        "api_key"
      ],
      "beta": false,
      "edited": false
    },
    "RetrieverTool": {
      "template": {
        "_type": "CustomComponent",
        "retriever": {
          "type": "BaseRetriever",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "retriever",
          "display_name": "Retriever",
          "advanced": false,
          "dynamic": false,
          "info": "Retriever to interact with",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain.tools.retriever import create_retriever_tool\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseRetriever, Tool\n\n\nclass RetrieverToolComponent(CustomComponent):\n    display_name = \"RetrieverTool\"\n    description = \"Tool for interacting with retriever\"\n\n    def build_config(self):\n        return {\n            \"retriever\": {\n                \"display_name\": \"Retriever\",\n                \"info\": \"Retriever to interact with\",\n                \"type\": BaseRetriever,\n            },\n            \"name\": {\"display_name\": \"Name\", \"info\": \"Name of the tool\"},\n            \"description\": {\"display_name\": \"Description\", \"info\": \"Description of the tool\"},\n        }\n\n    def build(\n        self,\n        retriever: BaseRetriever,\n        name: str,\n        description: str,\n    ) -> Tool:\n        return create_retriever_tool(\n            retriever=retriever,\n            name=name,\n            description=description,\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "description": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "description",
          "display_name": "Description",
          "advanced": false,
          "dynamic": false,
          "info": "Description of the tool",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "name",
          "display_name": "Name",
          "advanced": false,
          "dynamic": false,
          "info": "Name of the tool",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Tool for interacting with retriever",
      "base_classes": [
        "BaseTool",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable",
        "Tool"
      ],
      "display_name": "RetrieverTool",
      "documentation": "",
      "custom_fields": {
        "retriever": null,
        "name": null,
        "description": null
      },
      "output_types": [
        "Tool"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Tool"
          ],
          "selected": "Tool",
          "name": "tool",
          "hidden": null,
          "display_name": "Tool",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "PythonREPLTool": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "import importlib\nfrom langchain_experimental.utilities import PythonREPL\n\nfrom langflow.base.tools.base import build_status_from_tool\nfrom langflow.custom import CustomComponent\nfrom langchain_core.tools import Tool\n\n\nclass PythonREPLToolComponent(CustomComponent):\n    display_name = \"Python REPL Tool\"\n    description = \"A tool for running Python code in a REPL environment.\"\n\n    def build_config(self):\n        return {\n            \"name\": {\"display_name\": \"Name\", \"info\": \"The name of the tool.\"},\n            \"description\": {\"display_name\": \"Description\", \"info\": \"A description of the tool.\"},\n            \"global_imports\": {\n                \"display_name\": \"Global Imports\",\n                \"info\": \"A list of modules to import globally, e.g. ['math', 'numpy'].\",\n            },\n        }\n\n    def get_globals(self, globals: list[str]) -> dict:\n        \"\"\"\n        Retrieves the global variables from the specified modules.\n\n        Args:\n            globals (list[str]): A list of module names.\n\n        Returns:\n            dict: A dictionary containing the global variables from the specified modules.\n        \"\"\"\n        global_dict = {}\n        for module in globals:\n            try:\n                imported_module = importlib.import_module(module)\n                global_dict[imported_module.__name__] = imported_module\n            except ImportError:\n                raise ImportError(f\"Could not import module {module}\")\n        return global_dict\n\n    def build(\n        self,\n        name: str = \"python_repl\",\n        description: str = \"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n        global_imports: list[str] = [\"math\"],\n    ) -> Tool:\n        \"\"\"\n        Builds a Python REPL tool.\n\n        Args:\n            name (str, optional): The name of the tool. Defaults to \"python_repl\".\n            description (str, optional): The description of the tool. Defaults to \"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`. \".\n            global_imports (list[str], optional): A list of global imports to be available in the Python REPL. Defaults to [\"math\"].\n\n        Returns:\n            Tool: The built Python REPL tool.\n        \"\"\"\n        _globals = self.get_globals(global_imports)\n        python_repl = PythonREPL(_globals=_globals)\n        tool = Tool(\n            name=name,\n            description=description,\n            func=python_repl.run,\n        )\n        self.status = build_status_from_tool(tool)\n        return tool\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "description": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "description",
          "display_name": "Description",
          "advanced": false,
          "dynamic": false,
          "info": "A description of the tool.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "global_imports": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "value": [
            "math"
          ],
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "global_imports",
          "display_name": "Global Imports",
          "advanced": false,
          "dynamic": false,
          "info": "A list of modules to import globally, e.g. ['math', 'numpy'].",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "name": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "python_repl",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "name",
          "display_name": "Name",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the tool.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "A tool for running Python code in a REPL environment.",
      "base_classes": [
        "BaseTool",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable",
        "Tool"
      ],
      "display_name": "Python REPL Tool",
      "documentation": "",
      "custom_fields": {
        "name": null,
        "description": null,
        "global_imports": null
      },
      "output_types": [
        "Tool"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Tool"
          ],
          "selected": "Tool",
          "name": "tool",
          "hidden": null,
          "display_name": "Tool",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    }
  },
  "embeddings": {
    "CohereEmbeddings": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_community.embeddings.cohere import CohereEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass CohereEmbeddingsComponent(LCModelComponent):\n    display_name = \"Cohere Embeddings\"\n    description = \"Generate embeddings using Cohere models.\"\n    icon = \"Cohere\"\n    inputs = [\n        SecretStrInput(name=\"cohere_api_key\", display_name=\"Cohere API Key\"),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=True,\n            options=[\n                \"embed-english-v2.0\",\n                \"embed-multilingual-v2.0\",\n                \"embed-english-light-v2.0\",\n                \"embed-multilingual-light-v2.0\",\n            ],\n            value=\"embed-english-v2.0\",\n        ),\n        MessageTextInput(name=\"truncate\", display_name=\"Truncate\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", advanced=True, value=\"langchain\"),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return CohereEmbeddings(  # type: ignore\n            cohere_api_key=self.cohere_api_key,\n            model=self.model,\n            truncate=self.truncate,\n            max_retries=self.max_retries,\n            user_agent=self.user_agent,\n            request_timeout=self.request_timeout or None,\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "cohere_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "cohere_api_key",
          "display_name": "Cohere API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "max_retries": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 3,
          "name": "max_retries",
          "display_name": "Max Retries",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "model": {
          "trace_as_metadata": true,
          "options": [
            "embed-english-v2.0",
            "embed-multilingual-v2.0",
            "embed-english-light-v2.0",
            "embed-multilingual-light-v2.0"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "embed-english-v2.0",
          "name": "model",
          "display_name": "Model",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "request_timeout": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "request_timeout",
          "display_name": "Request Timeout",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        },
        "truncate": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "truncate",
          "display_name": "Truncate",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "user_agent": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "langchain",
          "name": "user_agent",
          "display_name": "User Agent",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Generate embeddings using Cohere models.",
      "icon": "Cohere",
      "base_classes": [
        "Embeddings"
      ],
      "display_name": "Cohere Embeddings",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Embeddings"
          ],
          "selected": "Embeddings",
          "name": "embeddings",
          "display_name": "Embeddings",
          "method": "build_embeddings",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "cohere_api_key",
        "model",
        "truncate",
        "max_retries",
        "user_agent",
        "request_timeout"
      ],
      "beta": false,
      "edited": false
    },
    "VertexAIEmbeddings": {
      "template": {
        "_type": "Component",
        "credentials": {
          "trace_as_metadata": true,
          "file_path": "",
          "fileTypes": [
            "json"
          ],
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "credentials",
          "display_name": "Credentials",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "file"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, FileInput, FloatInput, IntInput, MessageTextInput, Output\n\n\nclass VertexAIEmbeddingsComponent(LCModelComponent):\n    display_name = \"VertexAI Embeddings\"\n    description = \"Generate embeddings using Google Cloud VertexAI models.\"\n    icon = \"VertexAI\"\n\n    inputs = [\n        FileInput(\n            name=\"credentials\",\n            display_name=\"Credentials\",\n            value=\"\",\n            file_types=[\"json\"],  # Removed the dot\n        ),\n        DictInput(\n            name=\"instance\",\n            display_name=\"Instance\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"location\",\n            display_name=\"Location\",\n            value=\"us-central1\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            value=128,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            value=6,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            value=\"textembedding-gecko\",\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            value=1,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"project\",\n            display_name=\"Project\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"request_parallelism\",\n            display_name=\"Request Parallelism\",\n            value=5,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"stop\",\n            display_name=\"Stop\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"streaming\",\n            display_name=\"Streaming\",\n            value=False,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.0,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            value=40,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            value=0.95,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            from langchain_google_vertexai import VertexAIEmbeddings\n        except ImportError:\n            raise ImportError(\n                \"Please install the langchain-google-vertexai package to use the VertexAIEmbeddings component.\"\n            )\n\n        return VertexAIEmbeddings(\n            instance=self.instance,\n            credentials=self.credentials,\n            location=self.location,\n            max_output_tokens=self.max_output_tokens,\n            max_retries=self.max_retries,\n            model_name=self.model_name,\n            n=self.n,\n            project=self.project,\n            request_parallelism=self.request_parallelism,\n            stop=self.stop,\n            streaming=self.streaming,\n            temperature=self.temperature,\n            top_k=self.top_k,\n            top_p=self.top_p,\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "instance": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "instance",
          "display_name": "Instance",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "dict"
        },
        "location": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "us-central1",
          "name": "location",
          "display_name": "Location",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "max_output_tokens": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 128,
          "name": "max_output_tokens",
          "display_name": "Max Output Tokens",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "max_retries": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 6,
          "name": "max_retries",
          "display_name": "Max Retries",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "model_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "textembedding-gecko",
          "name": "model_name",
          "display_name": "Model Name",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "n": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 1,
          "name": "n",
          "display_name": "N",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "project": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "project",
          "display_name": "Project",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "request_parallelism": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 5,
          "name": "request_parallelism",
          "display_name": "Request Parallelism",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "stop": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "stop",
          "display_name": "Stop",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "streaming": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "streaming",
          "display_name": "Streaming",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "bool"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.0,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        },
        "top_k": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 40,
          "name": "top_k",
          "display_name": "Top K",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "top_p": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.95,
          "name": "top_p",
          "display_name": "Top P",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generate embeddings using Google Cloud VertexAI models.",
      "icon": "VertexAI",
      "base_classes": [
        "Embeddings"
      ],
      "display_name": "VertexAI Embeddings",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Embeddings"
          ],
          "selected": "Embeddings",
          "name": "embeddings",
          "display_name": "Embeddings",
          "method": "build_embeddings",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "credentials",
        "instance",
        "location",
        "max_output_tokens",
        "max_retries",
        "model_name",
        "n",
        "project",
        "request_parallelism",
        "stop",
        "streaming",
        "temperature",
        "top_k",
        "top_p"
      ],
      "beta": false,
      "edited": false
    },
    "OllamaEmbeddings": {
      "template": {
        "_type": "Component",
        "base_url": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "http://localhost:11434",
          "name": "base_url",
          "display_name": "Ollama Base URL",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_community.embeddings import OllamaEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import FloatInput, MessageTextInput, Output\n\n\nclass OllamaEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n    icon = \"Ollama\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"model\",\n            display_name=\"Ollama Model\",\n            value=\"llama2\",\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Ollama Base URL\",\n            value=\"http://localhost:11434\",\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Model Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(\n                model=self.model,\n                base_url=self.base_url,\n                temperature=self.temperature,\n            )  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama API.\") from e\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "model": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "llama2",
          "name": "model",
          "display_name": "Ollama Model",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.1,
          "name": "temperature",
          "display_name": "Model Temperature",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generate embeddings using Ollama models.",
      "icon": "Ollama",
      "base_classes": [
        "Embeddings"
      ],
      "display_name": "Ollama Embeddings",
      "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Embeddings"
          ],
          "selected": "Embeddings",
          "name": "embeddings",
          "display_name": "Embeddings",
          "method": "build_embeddings",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "model",
        "base_url",
        "temperature"
      ],
      "beta": false,
      "edited": false
    },
    "AstraVectorize": {
      "template": {
        "_type": "Component",
        "authentication": {
          "trace_as_input": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "authentication",
          "display_name": "Authentication",
          "advanced": false,
          "dynamic": false,
          "info": "Authentication parameters. Use the Astra Portal to add the embedding provider integration to your Astra organization.",
          "title_case": false,
          "type": "dict"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Any\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DictInput, SecretStrInput, MessageTextInput\nfrom langflow.template.field.base import Output\n\n\nclass AstraVectorize(Component):\n    display_name: str = \"Astra Vectorize\"\n    description: str = \"Configuration options for Astra Vectorize server-side embeddings.\"\n    documentation: str = \"https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html\"\n    icon = \"AstraDB\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"provider\",\n            display_name=\"Provider name\",\n            info=\"The embedding provider to use.\",\n        ),\n        MessageTextInput(\n            name=\"model_name\",\n            display_name=\"Model name\",\n            info=\"The embedding model to use.\",\n        ),\n        DictInput(\n            name=\"authentication\",\n            display_name=\"Authentication\",\n            info=\"Authentication parameters. Use the Astra Portal to add the embedding provider integration to your Astra organization.\",\n            is_list=True,\n        ),\n        SecretStrInput(\n            name=\"provider_api_key\",\n            display_name=\"Provider API Key\",\n            info=\"An alternative to the Astra Authentication that let you use directly the API key of the provider.\",\n        ),\n        DictInput(\n            name=\"model_parameters\",\n            display_name=\"Model parameters\",\n            info=\"Additional model parameters.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Vectorize\", name=\"config\", method=\"build_options\", types=[\"dict\"]),\n    ]\n\n    def build_options(self) -> dict[str, Any]:\n        return {\n            # must match exactly astra CollectionVectorServiceOptions\n            \"collection_vector_service_options\": {\n                \"provider\": self.provider,\n                \"modelName\": self.model_name,\n                \"authentication\": self.authentication,\n                \"parameters\": self.model_parameters,\n            },\n            \"collection_embedding_api_key\": self.provider_api_key,\n        }\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "model_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "model_name",
          "display_name": "Model name",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The embedding model to use.",
          "title_case": false,
          "type": "str"
        },
        "model_parameters": {
          "trace_as_input": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "model_parameters",
          "display_name": "Model parameters",
          "advanced": true,
          "dynamic": false,
          "info": "Additional model parameters.",
          "title_case": false,
          "type": "dict"
        },
        "provider": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "provider",
          "display_name": "Provider name",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The embedding provider to use.",
          "title_case": false,
          "type": "str"
        },
        "provider_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "provider_api_key",
          "display_name": "Provider API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "An alternative to the Astra Authentication that let you use directly the API key of the provider.",
          "title_case": false,
          "password": true,
          "type": "str"
        }
      },
      "description": "Configuration options for Astra Vectorize server-side embeddings.",
      "icon": "AstraDB",
      "base_classes": [
        "dict"
      ],
      "display_name": "Astra Vectorize",
      "documentation": "https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "dict"
          ],
          "name": "config",
          "display_name": "Vectorize",
          "method": "build_options",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "provider",
        "model_name",
        "authentication",
        "provider_api_key",
        "model_parameters"
      ],
      "beta": false,
      "edited": false
    },
    "AmazonBedrockEmbeddings": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_community.embeddings import BedrockEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import DropdownInput, MessageTextInput, Output\n\n\nclass AmazonBedrockEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Amazon Bedrock Embeddings\"\n    description: str = \"Generate embeddings using Amazon Bedrock models.\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/bedrock\"\n    icon = \"Amazon\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model_id\",\n            display_name=\"Model Id\",\n            options=[\"amazon.titan-embed-text-v1\"],\n            value=\"amazon.titan-embed-text-v1\",\n        ),\n        MessageTextInput(\n            name=\"credentials_profile_name\",\n            display_name=\"Credentials Profile Name\",\n        ),\n        MessageTextInput(\n            name=\"endpoint_url\",\n            display_name=\"Bedrock Endpoint URL\",\n        ),\n        MessageTextInput(\n            name=\"region_name\",\n            display_name=\"AWS Region\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            output = BedrockEmbeddings(\n                credentials_profile_name=self.credentials_profile_name,\n                model_id=self.model_id,\n                endpoint_url=self.endpoint_url,\n                region_name=self.region_name,\n            )  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to Amazon Bedrock API.\") from e\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "credentials_profile_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "credentials_profile_name",
          "display_name": "Credentials Profile Name",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "endpoint_url": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "endpoint_url",
          "display_name": "Bedrock Endpoint URL",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "model_id": {
          "trace_as_metadata": true,
          "options": [
            "amazon.titan-embed-text-v1"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "amazon.titan-embed-text-v1",
          "name": "model_id",
          "display_name": "Model Id",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "region_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "region_name",
          "display_name": "AWS Region",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Generate embeddings using Amazon Bedrock models.",
      "icon": "Amazon",
      "base_classes": [
        "Embeddings"
      ],
      "display_name": "Amazon Bedrock Embeddings",
      "documentation": "https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/bedrock",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Embeddings"
          ],
          "selected": "Embeddings",
          "name": "embeddings",
          "display_name": "Embeddings",
          "method": "build_embeddings",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "model_id",
        "credentials_profile_name",
        "endpoint_url",
        "region_name"
      ],
      "beta": false,
      "edited": false
    },
    "AzureOpenAIEmbeddings": {
      "template": {
        "_type": "Component",
        "api_key": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "api_key",
          "display_name": "API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "api_version": {
          "trace_as_metadata": true,
          "options": [
            "2022-12-01",
            "2023-03-15-preview",
            "2023-05-15",
            "2023-06-01-preview",
            "2023-07-01-preview",
            "2023-08-01-preview"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "2023-08-01-preview",
          "name": "api_version",
          "display_name": "API Version",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "azure_deployment": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "azure_deployment",
          "display_name": "Deployment Name",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "azure_endpoint": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "azure_endpoint",
          "display_name": "Azure Endpoint",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_openai import AzureOpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass AzureOpenAIEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI Embeddings\"\n    description: str = \"Generate embeddings using Azure OpenAI models.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/text_embedding/azureopenai\"\n    icon = \"Azure\"\n\n    API_VERSION_OPTIONS = [\n        \"2022-12-01\",\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n    ]\n\n    inputs = [\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            required=True,\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n        ),\n        MessageTextInput(\n            name=\"azure_deployment\",\n            display_name=\"Deployment Name\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=API_VERSION_OPTIONS,\n            value=API_VERSION_OPTIONS[-1],\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            required=True,\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.api_key:\n            raise ValueError(\"API Key is required\")\n\n        azure_api_key = SecretStr(self.api_key)\n\n        try:\n            embeddings = AzureOpenAIEmbeddings(\n                azure_endpoint=self.azure_endpoint,\n                azure_deployment=self.azure_deployment,\n                api_version=self.api_version,\n                api_key=azure_api_key,\n                dimensions=self.dimensions,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to AzureOpenAIEmbeddings API.\") from e\n\n        return embeddings\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "dimensions": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "dimensions",
          "display_name": "Dimensions",
          "advanced": true,
          "dynamic": false,
          "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
          "title_case": false,
          "type": "int"
        }
      },
      "description": "Generate embeddings using Azure OpenAI models.",
      "icon": "Azure",
      "base_classes": [
        "Embeddings"
      ],
      "display_name": "Azure OpenAI Embeddings",
      "documentation": "https://python.langchain.com/docs/integrations/text_embedding/azureopenai",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Embeddings"
          ],
          "selected": "Embeddings",
          "name": "embeddings",
          "display_name": "Embeddings",
          "method": "build_embeddings",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "azure_endpoint",
        "azure_deployment",
        "api_version",
        "api_key",
        "dimensions"
      ],
      "beta": false,
      "edited": false
    },
    "HuggingFaceInferenceAPIEmbeddings": {
      "template": {
        "_type": "Component",
        "api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "api_key",
          "display_name": "API Key",
          "advanced": true,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "api_url": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "http://localhost:8080",
          "name": "api_url",
          "display_name": "API URL",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_community.embeddings.huggingface import HuggingFaceInferenceAPIEmbeddings\nfrom pydantic.v1.types import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import MessageTextInput, Output, SecretStrInput\n\n\nclass HuggingFaceInferenceAPIEmbeddingsComponent(LCModelComponent):\n    display_name = \"Hugging Face API Embeddings\"\n    description = \"Generate embeddings using Hugging Face Inference API models.\"\n    documentation = \"https://github.com/huggingface/text-embeddings-inference\"\n    icon = \"HuggingFace\"\n\n    inputs = [\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", advanced=True),\n        MessageTextInput(name=\"api_url\", display_name=\"API URL\", advanced=True, value=\"http://localhost:8080\"),\n        MessageTextInput(name=\"model_name\", display_name=\"Model Name\", value=\"BAAI/bge-large-en-v1.5\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.api_key:\n            raise ValueError(\"API Key is required\")\n\n        api_key = SecretStr(self.api_key)\n\n        return HuggingFaceInferenceAPIEmbeddings(api_key=api_key, api_url=self.api_url, model_name=self.model_name)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "model_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "BAAI/bge-large-en-v1.5",
          "name": "model_name",
          "display_name": "Model Name",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Generate embeddings using Hugging Face Inference API models.",
      "icon": "HuggingFace",
      "base_classes": [
        "Embeddings"
      ],
      "display_name": "Hugging Face API Embeddings",
      "documentation": "https://github.com/huggingface/text-embeddings-inference",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Embeddings"
          ],
          "selected": "Embeddings",
          "name": "embeddings",
          "display_name": "Embeddings",
          "method": "build_embeddings",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "api_key",
        "api_url",
        "model_name"
      ],
      "beta": false,
      "edited": false
    },
    "MistalAIEmbeddings": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_mistralai.embeddings import MistralAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass MistralAIEmbeddingsComponent(LCModelComponent):\n    display_name = \"MistralAI Embeddings\"\n    description = \"Generate embeddings using MistralAI models.\"\n    icon = \"MistralAI\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=[\"mistral-embed\"],\n            value=\"mistral-embed\",\n        ),\n        SecretStrInput(name=\"mistral_api_key\", display_name=\"Mistral API Key\"),\n        IntInput(\n            name=\"max_concurrent_requests\",\n            display_name=\"Max Concurrent Requests\",\n            advanced=True,\n            value=64,\n        ),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", advanced=True, value=5),\n        IntInput(name=\"timeout\", display_name=\"Request Timeout\", advanced=True, value=120),\n        MessageTextInput(\n            name=\"endpoint\",\n            display_name=\"API Endpoint\",\n            advanced=True,\n            value=\"https://api.mistral.ai/v1/\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.mistral_api_key:\n            raise ValueError(\"Mistral API Key is required\")\n\n        api_key = SecretStr(self.mistral_api_key)\n\n        return MistralAIEmbeddings(\n            api_key=api_key,\n            model=self.model,\n            endpoint=self.endpoint,\n            max_concurrent_requests=self.max_concurrent_requests,\n            max_retries=self.max_retries,\n            timeout=self.timeout,\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "endpoint": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "https://api.mistral.ai/v1/",
          "name": "endpoint",
          "display_name": "API Endpoint",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "max_concurrent_requests": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 64,
          "name": "max_concurrent_requests",
          "display_name": "Max Concurrent Requests",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "max_retries": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 5,
          "name": "max_retries",
          "display_name": "Max Retries",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "mistral_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "mistral_api_key",
          "display_name": "Mistral API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "model": {
          "trace_as_metadata": true,
          "options": [
            "mistral-embed"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "mistral-embed",
          "name": "model",
          "display_name": "Model",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "timeout": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 120,
          "name": "timeout",
          "display_name": "Request Timeout",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        }
      },
      "description": "Generate embeddings using MistralAI models.",
      "icon": "MistralAI",
      "base_classes": [
        "Embeddings"
      ],
      "display_name": "MistralAI Embeddings",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Embeddings"
          ],
          "selected": "Embeddings",
          "name": "embeddings",
          "display_name": "Embeddings",
          "method": "build_embeddings",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "model",
        "mistral_api_key",
        "max_concurrent_requests",
        "max_retries",
        "timeout",
        "endpoint"
      ],
      "beta": false,
      "edited": false
    },
    "HuggingFaceEmbeddings": {
      "template": {
        "_type": "Component",
        "cache_folder": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "cache_folder",
          "display_name": "Cache Folder",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, MessageTextInput, Output\n\n\nclass HuggingFaceEmbeddingsComponent(LCModelComponent):\n    display_name = \"Hugging Face Embeddings\"\n    description = \"Generate embeddings using HuggingFace models.\"\n    documentation = (\n        \"https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/sentence_transformers\"\n    )\n    icon = \"HuggingFace\"\n\n    inputs = [\n        MessageTextInput(name=\"cache_folder\", display_name=\"Cache Folder\", advanced=True),\n        DictInput(name=\"encode_kwargs\", display_name=\"Encode Kwargs\", advanced=True),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        MessageTextInput(name=\"model_name\", display_name=\"Model Name\", value=\"sentence-transformers/all-mpnet-base-v2\"),\n        BoolInput(name=\"multi_process\", display_name=\"Multi Process\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return HuggingFaceEmbeddings(\n            cache_folder=self.cache_folder,\n            encode_kwargs=self.encode_kwargs,\n            model_kwargs=self.model_kwargs,\n            model_name=self.model_name,\n            multi_process=self.multi_process,\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "encode_kwargs": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "encode_kwargs",
          "display_name": "Encode Kwargs",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "dict"
        },
        "model_kwargs": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "model_kwargs",
          "display_name": "Model Kwargs",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "dict"
        },
        "model_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "sentence-transformers/all-mpnet-base-v2",
          "name": "model_name",
          "display_name": "Model Name",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "multi_process": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "multi_process",
          "display_name": "Multi Process",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "bool"
        }
      },
      "description": "Generate embeddings using HuggingFace models.",
      "icon": "HuggingFace",
      "base_classes": [
        "Embeddings"
      ],
      "display_name": "Hugging Face Embeddings",
      "documentation": "https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/sentence_transformers",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Embeddings"
          ],
          "selected": "Embeddings",
          "name": "embeddings",
          "display_name": "Embeddings",
          "method": "build_embeddings",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "cache_folder",
        "encode_kwargs",
        "model_kwargs",
        "model_name",
        "multi_process"
      ],
      "beta": false,
      "edited": false
    },
    "OpenAIEmbeddings": {
      "template": {
        "_type": "Component",
        "chunk_size": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 1000,
          "name": "chunk_size",
          "display_name": "Chunk Size",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "client": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "client",
          "display_name": "Client",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=[\n                \"text-embedding-3-small\",\n                \"text-embedding-3-large\",\n                \"text-embedding-ada-002\",\n            ],\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "default_headers": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "default_headers",
          "display_name": "Default Headers",
          "advanced": true,
          "dynamic": false,
          "info": "Default headers to use for the API request.",
          "title_case": false,
          "type": "dict"
        },
        "default_query": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "default_query",
          "display_name": "Default Query",
          "advanced": true,
          "dynamic": false,
          "info": "Default query parameters to use for the API request.",
          "title_case": false,
          "type": "dict"
        },
        "deployment": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "deployment",
          "display_name": "Deployment",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "embedding_ctx_length": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 1536,
          "name": "embedding_ctx_length",
          "display_name": "Embedding Context Length",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "max_retries": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 3,
          "name": "max_retries",
          "display_name": "Max Retries",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "model": {
          "trace_as_metadata": true,
          "options": [
            "text-embedding-3-small",
            "text-embedding-3-large",
            "text-embedding-ada-002"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "text-embedding-3-small",
          "name": "model",
          "display_name": "Model",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "model_kwargs": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "model_kwargs",
          "display_name": "Model Kwargs",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "dict"
        },
        "openai_api_base": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "openai_api_base",
          "display_name": "OpenAI API Base",
          "advanced": true,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "openai_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "openai_api_key",
          "display_name": "OpenAI API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "openai_api_type": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "openai_api_type",
          "display_name": "OpenAI API Type",
          "advanced": true,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "openai_api_version": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "openai_api_version",
          "display_name": "OpenAI API Version",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "openai_organization": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "openai_organization",
          "display_name": "OpenAI Organization",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "openai_proxy": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "openai_proxy",
          "display_name": "OpenAI Proxy",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "request_timeout": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "request_timeout",
          "display_name": "Request Timeout",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        },
        "show_progress_bar": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "show_progress_bar",
          "display_name": "Show Progress Bar",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "bool"
        },
        "skip_empty": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "skip_empty",
          "display_name": "Skip Empty",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "bool"
        },
        "tiktoken_enable": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": true,
          "name": "tiktoken_enable",
          "display_name": "TikToken Enable",
          "advanced": true,
          "dynamic": false,
          "info": "If False, you must have transformers installed.",
          "title_case": false,
          "type": "bool"
        },
        "tiktoken_model_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "tiktoken_model_name",
          "display_name": "TikToken Model Name",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Generate embeddings using OpenAI models.",
      "icon": "OpenAI",
      "base_classes": [
        "Embeddings"
      ],
      "display_name": "OpenAI Embeddings",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Embeddings"
          ],
          "selected": "Embeddings",
          "name": "embeddings",
          "display_name": "Embeddings",
          "method": "build_embeddings",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "default_headers",
        "default_query",
        "chunk_size",
        "client",
        "deployment",
        "embedding_ctx_length",
        "max_retries",
        "model",
        "model_kwargs",
        "openai_api_base",
        "openai_api_key",
        "openai_api_type",
        "openai_api_version",
        "openai_organization",
        "openai_proxy",
        "request_timeout",
        "show_progress_bar",
        "skip_empty",
        "tiktoken_model_name",
        "tiktoken_enable"
      ],
      "beta": false,
      "edited": false
    }
  },
  "langchain_utilities": {
    "SearxSearchWrapper": {
      "template": {
        "_type": "CustomComponent",
        "headers": {
          "type": "Dict[str, str]",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "{\"Authorization\": \"Bearer <token>\"}",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "headers",
          "display_name": "Headers",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Dict, Optional\n\nfrom langchain_community.utilities.searx_search import SearxSearchWrapper\n\nfrom langflow.custom import CustomComponent\n\n\nclass SearxSearchWrapperComponent(CustomComponent):\n    display_name = \"SearxSearchWrapper\"\n    description = \"Wrapper for Searx API.\"\n\n    def build_config(self):\n        return {\n            \"headers\": {\n                \"field_type\": \"dict\",\n                \"display_name\": \"Headers\",\n                \"multiline\": True,\n                \"value\": '{\"Authorization\": \"Bearer <token>\"}',\n            },\n            \"k\": {\"display_name\": \"k\", \"advanced\": True, \"field_type\": \"int\", \"value\": 10},\n            \"searx_host\": {\n                \"display_name\": \"Searx Host\",\n                \"field_type\": \"str\",\n                \"value\": \"https://searx.example.com\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        k: int = 10,\n        headers: Optional[Dict[str, str]] = None,\n        searx_host: str = \"https://searx.example.com\",\n    ) -> SearxSearchWrapper:\n        return SearxSearchWrapper(headers=headers, k=k, searx_host=searx_host)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "k": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 10,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "k",
          "display_name": "k",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "searx_host": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "https://searx.example.com",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "searx_host",
          "display_name": "Searx Host",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Wrapper for Searx API.",
      "base_classes": [
        "SearxSearchWrapper"
      ],
      "display_name": "SearxSearchWrapper",
      "documentation": "",
      "custom_fields": {
        "k": null,
        "headers": null,
        "searx_host": null
      },
      "output_types": [
        "SearxSearchWrapper"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "SearxSearchWrapper"
          ],
          "selected": "SearxSearchWrapper",
          "name": "searxsearchwrapper",
          "hidden": null,
          "display_name": "SearxSearchWrapper",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "SearchApi": {
      "template": {
        "_type": "CustomComponent",
        "api_key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "api_key",
          "display_name": "API Key",
          "advanced": false,
          "dynamic": false,
          "info": "The API key to use SearchApi.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Data\nfrom langflow.services.database.models.base import orjson_dumps\n\n\nclass SearchApi(CustomComponent):\n    display_name: str = \"SearchApi\"\n    description: str = \"Real-time search engine results API.\"\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://www.searchapi.io/docs/google\"\n    field_config = {\n        \"engine\": {\n            \"display_name\": \"Engine\",\n            \"field_type\": \"str\",\n            \"info\": \"The search engine to use.\",\n        },\n        \"params\": {\n            \"display_name\": \"Parameters\",\n            \"info\": \"The parameters to send with the request.\",\n        },\n        \"code\": {\"show\": False},\n        \"api_key\": {\n            \"display_name\": \"API Key\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"password\": True,\n            \"info\": \"The API key to use SearchApi.\",\n        },\n    }\n\n    def build(\n        self,\n        engine: str,\n        api_key: str,\n        params: Optional[dict] = None,\n    ) -> Data:\n        if params is None:\n            params = {}\n\n        search_api_wrapper = SearchApiAPIWrapper(engine=engine, searchapi_api_key=api_key)\n\n        q = params.pop(\"q\", \"SearchApi Langflow\")\n        results = search_api_wrapper.results(q, **params)\n\n        result = orjson_dumps(results, indent_2=False)\n\n        record = Data(data=result)\n        self.status = record\n        return record\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "engine": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "engine",
          "display_name": "Engine",
          "advanced": false,
          "dynamic": false,
          "info": "The search engine to use.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "params": {
          "type": "dict",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "params",
          "display_name": "Parameters",
          "advanced": false,
          "dynamic": false,
          "info": "The parameters to send with the request.",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Real-time search engine results API.",
      "base_classes": [
        "Data"
      ],
      "display_name": "SearchApi",
      "documentation": "https://www.searchapi.io/docs/google",
      "custom_fields": {
        "engine": null,
        "api_key": null,
        "params": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "engine",
        "params",
        "code",
        "api_key"
      ],
      "beta": false,
      "edited": false
    },
    "SerpAPIWrapper": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Callable, Union\n\nfrom langchain_community.utilities.serpapi import SerpAPIWrapper\n\nfrom langflow.custom import CustomComponent\n\n\nclass SerpAPIWrapperComponent(CustomComponent):\n    display_name = \"SerpAPIWrapper\"\n    description = \"Wrapper around SerpAPI\"\n\n    def build_config(self):\n        return {\n            \"serpapi_api_key\": {\"display_name\": \"SerpAPI API Key\", \"type\": \"str\", \"password\": True},\n            \"params\": {\n                \"display_name\": \"Parameters\",\n                \"type\": \"dict\",\n                \"advanced\": True,\n                \"multiline\": True,\n                \"value\": '{\"engine\": \"google\",\"google_domain\": \"google.com\",\"gl\": \"us\",\"hl\": \"en\"}',\n            },\n        }\n\n    def build(\n        self,\n        serpapi_api_key: str,\n        params: dict,\n    ) -> Union[SerpAPIWrapper, Callable]:  # Removed quotes around SerpAPIWrapper\n        return SerpAPIWrapper(  # type: ignore\n            serpapi_api_key=serpapi_api_key,\n            params=params,\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "params": {
          "type": "dict",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "{\"engine\": \"google\",\"google_domain\": \"google.com\",\"gl\": \"us\",\"hl\": \"en\"}",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "params",
          "display_name": "Parameters",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "serpapi_api_key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "serpapi_api_key",
          "display_name": "SerpAPI API Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Wrapper around SerpAPI",
      "base_classes": [
        "Callable",
        "SerpAPIWrapper"
      ],
      "display_name": "SerpAPIWrapper",
      "documentation": "",
      "custom_fields": {
        "serpapi_api_key": null,
        "params": null
      },
      "output_types": [
        "SerpAPIWrapper",
        "Callable"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "SerpAPIWrapper"
          ],
          "selected": "SerpAPIWrapper",
          "name": "serpapiwrapper",
          "hidden": null,
          "display_name": "SerpAPIWrapper",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Callable"
          ],
          "selected": "Callable",
          "name": "callable",
          "hidden": null,
          "display_name": "Callable",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "JSONDocumentBuilder": {
      "template": {
        "_type": "CustomComponent",
        "document": {
          "type": "Document",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "document",
          "display_name": "Document",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "### JSON Document Builder\n\n# Build a Document containing a JSON object using a key and another Document page content.\n\n# **Params**\n\n# - **Key:** The key to use for the JSON object.\n# - **Document:** The Document page to use for the JSON object.\n\n# **Output**\n\n# - **Document:** The Document containing the JSON object.\n\nfrom langchain_core.documents import Document\n\nfrom langflow.custom import CustomComponent\nfrom langflow.services.database.models.base import orjson_dumps\n\n\nclass JSONDocumentBuilder(CustomComponent):\n    display_name: str = \"JSON Document Builder\"\n    description: str = \"Build a Document containing a JSON object using a key and another Document page content.\"\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://docs.langflow.org/components/utilities#json-document-builder\"\n\n    field_config = {\n        \"key\": {\"display_name\": \"Key\"},\n        \"document\": {\"display_name\": \"Document\"},\n    }\n\n    def build(\n        self,\n        key: str,\n        document: Document,\n    ) -> Document:\n        documents = None\n        if isinstance(document, list):\n            documents = [\n                Document(page_content=orjson_dumps({key: doc.page_content}, indent_2=False)) for doc in document\n            ]\n        elif isinstance(document, Document):\n            documents = Document(page_content=orjson_dumps({key: document.page_content}, indent_2=False))\n        else:\n            raise TypeError(f\"Expected Document or list of Documents, got {type(document)}\")\n        self.repr_value = documents\n        return documents\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "key",
          "display_name": "Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Build a Document containing a JSON object using a key and another Document page content.",
      "base_classes": [
        "Document",
        "Serializable"
      ],
      "display_name": "JSON Document Builder",
      "documentation": "https://docs.langflow.org/components/utilities#json-document-builder",
      "custom_fields": {
        "key": null,
        "document": null
      },
      "output_types": [
        "Document"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Document"
          ],
          "selected": "Document",
          "name": "document",
          "hidden": null,
          "display_name": "Document",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "key",
        "document"
      ],
      "beta": false,
      "edited": false
    },
    "SQLDatabase": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_experimental.sql.base import SQLDatabase\n\nfrom langflow.custom import CustomComponent\n\n\nclass SQLDatabaseComponent(CustomComponent):\n    display_name = \"SQLDatabase\"\n    description = \"SQL Database\"\n\n    def build_config(self):\n        return {\n            \"uri\": {\"display_name\": \"URI\", \"info\": \"URI to the database.\"},\n        }\n\n    def clean_up_uri(self, uri: str) -> str:\n        if uri.startswith(\"postgresql://\"):\n            uri = uri.replace(\"postgresql://\", \"postgres://\")\n        return uri.strip()\n\n    def build(self, uri: str) -> SQLDatabase:\n        uri = self.clean_up_uri(uri)\n        return SQLDatabase.from_uri(uri)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "uri": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "uri",
          "display_name": "URI",
          "advanced": false,
          "dynamic": false,
          "info": "URI to the database.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "SQL Database",
      "base_classes": [
        "object",
        "SQLDatabase"
      ],
      "display_name": "SQLDatabase",
      "documentation": "",
      "custom_fields": {
        "uri": null
      },
      "output_types": [
        "SQLDatabase"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "SQLDatabase"
          ],
          "selected": "SQLDatabase",
          "name": "sqldatabase",
          "hidden": null,
          "display_name": "SQLDatabase",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "WikipediaAPIWrapper": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Callable, Union\n\nfrom langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n\nfrom langflow.custom import CustomComponent\n\n# Assuming WikipediaAPIWrapper is a class that needs to be imported.\n# The import statement is not included as it is not provided in the JSON\n# and the actual implementation details are unknown.\n\n\nclass WikipediaAPIWrapperComponent(CustomComponent):\n    display_name = \"WikipediaAPIWrapper\"\n    description = \"Wrapper around WikipediaAPI.\"\n\n    def build_config(self):\n        return {}\n\n    def build(\n        self,\n        top_k_results: int = 3,\n        lang: str = \"en\",\n        load_all_available_meta: bool = False,\n        doc_content_chars_max: int = 4000,\n    ) -> Union[WikipediaAPIWrapper, Callable]:\n        return WikipediaAPIWrapper(  # type: ignore\n            top_k_results=top_k_results,\n            lang=lang,\n            load_all_available_meta=load_all_available_meta,\n            doc_content_chars_max=doc_content_chars_max,\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "doc_content_chars_max": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 4000,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "doc_content_chars_max",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "lang": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "en",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "lang",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "load_all_available_meta": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "load_all_available_meta",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "top_k_results": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 3,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "top_k_results",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Wrapper around WikipediaAPI.",
      "base_classes": [
        "Callable",
        "WikipediaAPIWrapper"
      ],
      "display_name": "WikipediaAPIWrapper",
      "documentation": "",
      "custom_fields": {
        "top_k_results": null,
        "lang": null,
        "load_all_available_meta": null,
        "doc_content_chars_max": null
      },
      "output_types": [
        "WikipediaAPIWrapper",
        "Callable"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "WikipediaAPIWrapper"
          ],
          "selected": "WikipediaAPIWrapper",
          "name": "wikipediaapiwrapper",
          "hidden": null,
          "display_name": "WikipediaAPIWrapper",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Callable"
          ],
          "selected": "Callable",
          "name": "callable",
          "hidden": null,
          "display_name": "Callable",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "WolframAlphaAPIWrapper": {
      "template": {
        "_type": "CustomComponent",
        "appid": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "appid",
          "display_name": "App ID",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Callable, Union\n\nfrom langchain_community.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n\nfrom langflow.custom import CustomComponent\n\n# Since all the fields in the JSON have show=False, we will only create a basic component\n# without any configurable fields.\n\n\nclass WolframAlphaAPIWrapperComponent(CustomComponent):\n    display_name = \"WolframAlphaAPIWrapper\"\n    description = \"Wrapper for Wolfram Alpha.\"\n\n    def build_config(self):\n        return {\"appid\": {\"display_name\": \"App ID\", \"type\": \"str\", \"password\": True}}\n\n    def build(self, appid: str) -> Union[Callable, WolframAlphaAPIWrapper]:\n        return WolframAlphaAPIWrapper(wolfram_alpha_appid=appid)  # type: ignore\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Wrapper for Wolfram Alpha.",
      "base_classes": [
        "Callable",
        "WolframAlphaAPIWrapper"
      ],
      "display_name": "WolframAlphaAPIWrapper",
      "documentation": "",
      "custom_fields": {
        "appid": null
      },
      "output_types": [
        "Callable",
        "WolframAlphaAPIWrapper"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Callable"
          ],
          "selected": "Callable",
          "name": "callable",
          "hidden": null,
          "display_name": "Callable",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "WolframAlphaAPIWrapper"
          ],
          "selected": "WolframAlphaAPIWrapper",
          "name": "wolframalphaapiwrapper",
          "hidden": null,
          "display_name": "WolframAlphaAPIWrapper",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "GoogleSerperAPIWrapper": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Dict\n\n# Assuming the existence of GoogleSerperAPIWrapper class in the serper module\n# If this class does not exist, you would need to create it or import the appropriate class from another module\nfrom langchain_community.utilities.google_serper import GoogleSerperAPIWrapper\n\nfrom langflow.custom import CustomComponent\n\n\nclass GoogleSerperAPIWrapperComponent(CustomComponent):\n    display_name = \"GoogleSerperAPIWrapper\"\n    description = \"Wrapper around the Serper.dev Google Search API.\"\n\n    def build_config(self) -> Dict[str, Dict]:\n        return {\n            \"result_key_for_type\": {\n                \"display_name\": \"Result Key for Type\",\n                \"show\": True,\n                \"multiline\": False,\n                \"password\": False,\n                \"advanced\": False,\n                \"dynamic\": False,\n                \"info\": \"\",\n                \"field_type\": \"dict\",\n                \"list\": False,\n                \"value\": {\n                    \"news\": \"news\",\n                    \"places\": \"places\",\n                    \"images\": \"images\",\n                    \"search\": \"organic\",\n                },\n            },\n            \"serper_api_key\": {\n                \"display_name\": \"Serper API Key\",\n                \"show\": True,\n                \"multiline\": False,\n                \"password\": True,\n                \"advanced\": False,\n                \"dynamic\": False,\n                \"info\": \"\",\n                \"type\": \"str\",\n                \"list\": False,\n            },\n        }\n\n    def build(\n        self,\n        serper_api_key: str,\n    ) -> GoogleSerperAPIWrapper:\n        return GoogleSerperAPIWrapper(serper_api_key=serper_api_key)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "serper_api_key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "serper_api_key",
          "display_name": "Serper API Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Wrapper around the Serper.dev Google Search API.",
      "base_classes": [
        "GoogleSerperAPIWrapper"
      ],
      "display_name": "GoogleSerperAPIWrapper",
      "documentation": "",
      "custom_fields": {
        "serper_api_key": null
      },
      "output_types": [
        "GoogleSerperAPIWrapper"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "GoogleSerperAPIWrapper"
          ],
          "selected": "GoogleSerperAPIWrapper",
          "name": "googleserperapiwrapper",
          "hidden": null,
          "display_name": "GoogleSerperAPIWrapper",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "GoogleSearchAPIWrapper": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Callable, Union\n\nfrom langchain_community.utilities.google_search import GoogleSearchAPIWrapper\n\nfrom langflow.custom import CustomComponent\n\n\nclass GoogleSearchAPIWrapperComponent(CustomComponent):\n    display_name = \"GoogleSearchAPIWrapper\"\n    description = \"Wrapper for Google Search API.\"\n\n    def build_config(self):\n        return {\n            \"google_api_key\": {\"display_name\": \"Google API Key\", \"password\": True},\n            \"google_cse_id\": {\"display_name\": \"Google CSE ID\", \"password\": True},\n        }\n\n    def build(\n        self,\n        google_api_key: str,\n        google_cse_id: str,\n    ) -> Union[GoogleSearchAPIWrapper, Callable]:\n        return GoogleSearchAPIWrapper(google_api_key=google_api_key, google_cse_id=google_cse_id)  # type: ignore\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "google_api_key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "google_api_key",
          "display_name": "Google API Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "google_cse_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "google_cse_id",
          "display_name": "Google CSE ID",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Wrapper for Google Search API.",
      "base_classes": [
        "Callable",
        "GoogleSearchAPIWrapper"
      ],
      "display_name": "GoogleSearchAPIWrapper",
      "documentation": "",
      "custom_fields": {
        "google_api_key": null,
        "google_cse_id": null
      },
      "output_types": [
        "GoogleSearchAPIWrapper",
        "Callable"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "GoogleSearchAPIWrapper"
          ],
          "selected": "GoogleSearchAPIWrapper",
          "name": "googlesearchapiwrapper",
          "hidden": null,
          "display_name": "GoogleSearchAPIWrapper",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Callable"
          ],
          "selected": "Callable",
          "name": "callable",
          "hidden": null,
          "display_name": "Callable",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "BingSearchAPIWrapper": {
      "template": {
        "_type": "CustomComponent",
        "bing_search_url": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "bing_search_url",
          "display_name": "Bing Search URL",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "bing_subscription_key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "bing_subscription_key",
          "display_name": "Bing Subscription Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "# Assuming `BingSearchAPIWrapper` is a class that exists in the context\n# and has the appropriate methods and attributes.\n# We need to make sure this class is importable from the context where this code will be running.\nfrom langchain_community.utilities.bing_search import BingSearchAPIWrapper\n\nfrom langflow.custom import CustomComponent\n\n\nclass BingSearchAPIWrapperComponent(CustomComponent):\n    display_name = \"BingSearchAPIWrapper\"\n    description = \"Wrapper for Bing Search API.\"\n\n    def build_config(self):\n        return {\n            \"bing_search_url\": {\"display_name\": \"Bing Search URL\"},\n            \"bing_subscription_key\": {\n                \"display_name\": \"Bing Subscription Key\",\n                \"password\": True,\n            },\n            \"k\": {\"display_name\": \"Number of results\", \"advanced\": True},\n            # 'k' is not included as it is not shown (show=False)\n        }\n\n    def build(\n        self,\n        bing_search_url: str,\n        bing_subscription_key: str,\n        k: int = 10,\n    ) -> BingSearchAPIWrapper:\n        # 'k' has a default value and is not shown (show=False), so it is hardcoded here\n        return BingSearchAPIWrapper(bing_search_url=bing_search_url, bing_subscription_key=bing_subscription_key, k=k)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "k": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 10,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "k",
          "display_name": "Number of results",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Wrapper for Bing Search API.",
      "base_classes": [
        "BingSearchAPIWrapper"
      ],
      "display_name": "BingSearchAPIWrapper",
      "documentation": "",
      "custom_fields": {
        "bing_search_url": null,
        "bing_subscription_key": null,
        "k": null
      },
      "output_types": [
        "BingSearchAPIWrapper"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "BingSearchAPIWrapper"
          ],
          "selected": "BingSearchAPIWrapper",
          "name": "bingsearchapiwrapper",
          "hidden": null,
          "display_name": "BingSearchAPIWrapper",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    }
  },
  "agents": {
    "VectorStoreAgent": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "vector_store_toolkit": {
          "type": "VectorStoreToolkit",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "vector_store_toolkit",
          "display_name": "Vector Store Info",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Callable, Union\n\nfrom langchain.agents import AgentExecutor, create_vectorstore_agent\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreToolkit\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import LanguageModel\n\n\nclass VectorStoreAgentComponent(CustomComponent):\n    display_name = \"VectorStoreAgent\"\n    description = \"Construct an agent from a Vector Store.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"vector_store_toolkit\": {\"display_name\": \"Vector Store Info\"},\n        }\n\n    def build(\n        self,\n        llm: LanguageModel,\n        vector_store_toolkit: VectorStoreToolkit,\n    ) -> Union[AgentExecutor, Callable]:\n        return create_vectorstore_agent(llm=llm, toolkit=vector_store_toolkit)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Construct an agent from a Vector Store.",
      "base_classes": [
        "AgentExecutor",
        "Callable",
        "Chain",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable"
      ],
      "display_name": "VectorStoreAgent",
      "documentation": "",
      "custom_fields": {
        "llm": null,
        "vector_store_toolkit": null
      },
      "output_types": [
        "AgentExecutor",
        "Callable"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "AgentExecutor"
          ],
          "selected": "AgentExecutor",
          "name": "agentexecutor",
          "hidden": null,
          "display_name": "AgentExecutor",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Callable"
          ],
          "selected": "Callable",
          "name": "callable",
          "hidden": null,
          "display_name": "Callable",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "SQLAgent": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Callable, Union\n\nfrom langchain.agents import AgentExecutor\nfrom langchain_community.agent_toolkits import SQLDatabaseToolkit\nfrom langchain_community.agent_toolkits.sql.base import create_sql_agent\nfrom langchain_community.utilities import SQLDatabase\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import LanguageModel\n\n\nclass SQLAgentComponent(CustomComponent):\n    display_name = \"SQLAgent\"\n    description = \"Construct an SQL agent from an LLM and tools.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"database_uri\": {\"display_name\": \"Database URI\"},\n            \"verbose\": {\"display_name\": \"Verbose\", \"value\": False, \"advanced\": True},\n        }\n\n    def build(\n        self,\n        llm: LanguageModel,\n        database_uri: str,\n        verbose: bool = False,\n    ) -> Union[AgentExecutor, Callable]:\n        db = SQLDatabase.from_uri(database_uri)\n        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n        return create_sql_agent(llm=llm, toolkit=toolkit)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "database_uri": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "database_uri",
          "display_name": "Database URI",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "verbose": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "verbose",
          "display_name": "Verbose",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Construct an SQL agent from an LLM and tools.",
      "base_classes": [
        "AgentExecutor",
        "Callable",
        "Chain",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable"
      ],
      "display_name": "SQLAgent",
      "documentation": "",
      "custom_fields": {
        "llm": null,
        "database_uri": null,
        "verbose": null
      },
      "output_types": [
        "AgentExecutor",
        "Callable"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "AgentExecutor"
          ],
          "selected": "AgentExecutor",
          "name": "agentexecutor",
          "hidden": null,
          "display_name": "AgentExecutor",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Callable"
          ],
          "selected": "Callable",
          "name": "callable",
          "hidden": null,
          "display_name": "Callable",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "JsonAgent": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "toolkit": {
          "type": "JsonToolkit",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "toolkit",
          "display_name": "Toolkit",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain.agents import AgentExecutor\nfrom langchain_community.agent_toolkits import create_json_agent\nfrom langchain_community.agent_toolkits.json.toolkit import JsonToolkit\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import LanguageModel\n\n\nclass JsonAgentComponent(CustomComponent):\n    display_name = \"JsonAgent\"\n    description = \"Construct a json agent from an LLM and tools.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"toolkit\": {\"display_name\": \"Toolkit\"},\n        }\n\n    def build(\n        self,\n        llm: LanguageModel,\n        toolkit: JsonToolkit,\n    ) -> AgentExecutor:\n        return create_json_agent(llm=llm, toolkit=toolkit)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Construct a json agent from an LLM and tools.",
      "base_classes": [
        "AgentExecutor",
        "Chain",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable"
      ],
      "display_name": "JsonAgent",
      "documentation": "",
      "custom_fields": {
        "llm": null,
        "toolkit": null
      },
      "output_types": [
        "AgentExecutor"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "AgentExecutor"
          ],
          "selected": "AgentExecutor",
          "name": "agentexecutor",
          "hidden": null,
          "display_name": "AgentExecutor",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "VectorStoreRouterAgent": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "vectorstoreroutertoolkit": {
          "type": "VectorStoreRouterToolkit",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "vectorstoreroutertoolkit",
          "display_name": "Vector Store Router Toolkit",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Callable\n\nfrom langchain.agents import create_vectorstore_router_agent\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreRouterToolkit\nfrom langflow.field_typing import LanguageModel\n\nfrom langflow.custom import CustomComponent\n\n\nclass VectorStoreRouterAgentComponent(CustomComponent):\n    display_name = \"VectorStoreRouterAgent\"\n    description = \"Construct an agent from a Vector Store Router.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"vectorstoreroutertoolkit\": {\"display_name\": \"Vector Store Router Toolkit\"},\n        }\n\n    def build(self, llm: LanguageModel, vectorstoreroutertoolkit: VectorStoreRouterToolkit) -> Callable:\n        return create_vectorstore_router_agent(llm=llm, toolkit=vectorstoreroutertoolkit)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Construct an agent from a Vector Store Router.",
      "base_classes": [
        "Callable"
      ],
      "display_name": "VectorStoreRouterAgent",
      "documentation": "",
      "custom_fields": {
        "llm": null,
        "vectorstoreroutertoolkit": null
      },
      "output_types": [
        "Callable"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Callable"
          ],
          "selected": "Callable",
          "name": "callable",
          "hidden": null,
          "display_name": "Callable",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "CSVAgent": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "agent_type": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "value": "openai-tools",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [
            "zero-shot-react-description",
            "openai-functions",
            "openai-tools"
          ],
          "name": "agent_type",
          "display_name": "Agent Type",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_experimental.agents.agent_toolkits.csv.base import create_csv_agent\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import AgentExecutor, LanguageModel\n\n\nclass CSVAgentComponent(CustomComponent):\n    display_name = \"CSVAgent\"\n    description = \"Construct a CSV agent from a CSV and tools.\"\n    documentation = \"https://python.langchain.com/docs/modules/agents/toolkits/csv\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\", \"type\": LanguageModel},\n            \"path\": {\"display_name\": \"Path\", \"field_type\": \"file\", \"suffixes\": [\".csv\"], \"file_types\": [\".csv\"]},\n            \"handle_parsing_errors\": {\"display_name\": \"Handle Parse Errors\", \"advanced\": True},\n            \"agent_type\": {\n                \"display_name\": \"Agent Type\",\n                \"options\": [\"zero-shot-react-description\", \"openai-functions\", \"openai-tools\"],\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self, llm: LanguageModel, path: str, handle_parsing_errors: bool = True, agent_type: str = \"openai-tools\"\n    ) -> AgentExecutor:\n        # Instantiate and return the CSV agent class with the provided llm and path\n        return create_csv_agent(\n            llm=llm,\n            path=path,\n            agent_type=agent_type,\n            verbose=True,\n            agent_executor_kwargs=dict(handle_parsing_errors=handle_parsing_errors),\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "handle_parsing_errors": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": true,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "handle_parsing_errors",
          "display_name": "Handle Parse Errors",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "path": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [
            ".csv"
          ],
          "file_path": "",
          "password": false,
          "name": "path",
          "display_name": "Path",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Construct a CSV agent from a CSV and tools.",
      "base_classes": [
        "AgentExecutor",
        "Chain",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable"
      ],
      "display_name": "CSVAgent",
      "documentation": "https://python.langchain.com/docs/modules/agents/toolkits/csv",
      "custom_fields": {
        "llm": null,
        "path": null,
        "handle_parsing_errors": null,
        "agent_type": null
      },
      "output_types": [
        "AgentExecutor"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "AgentExecutor"
          ],
          "selected": "AgentExecutor",
          "name": "agentexecutor",
          "hidden": null,
          "display_name": "AgentExecutor",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "ToolCallingAgent": {
      "template": {
        "_type": "Component",
        "llm": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "input_types": [
            "LanguageModel"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "memory": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "memory",
          "display_name": "Memory",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "Memory to use for the agent.",
          "title_case": false,
          "type": "other"
        },
        "tools": {
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "tools",
          "display_name": "Tools",
          "advanced": false,
          "input_types": [
            "Tool"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Dict, List, cast\n\nfrom langchain.agents import AgentExecutor, BaseSingleActionAgent\nfrom langchain.agents.tool_calling_agent.base import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, HandleInput, MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ToolCallingAgentComponent(Component):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools. Only models that are compatible with function calling are supported.\"\n    icon = \"LangChain\"\n    beta = True\n\n    inputs = [\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Input text to pass to the agent.\",\n        ),\n        MessageTextInput(\n            name=\"user_prompt\",\n            display_name=\"Prompt\",\n            info=\"This prompt must contain 'input' key.\",\n            value=\"{input}\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"handle_parsing_errors\",\n            display_name=\"Handle Parsing Errors\",\n            info=\"If True, the agent will handle parsing errors. If False, the agent will raise an error.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"Data\"],\n            info=\"Memory to use for the agent.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"LLM\",\n            input_types=[\"LanguageModel\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"run_agent\"),\n    ]\n\n    async def run_agent(self) -> Message:\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\n                \"placeholder\",\n                \"{chat_history}\",\n            ),\n            (\"human\", self.user_prompt),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        agent = create_tool_calling_agent(self.llm, self.tools, prompt)\n\n        runnable = AgentExecutor.from_agent_and_tools(\n            agent=cast(BaseSingleActionAgent, agent),\n            tools=self.tools,\n            verbose=True,\n            handle_parsing_errors=self.handle_parsing_errors,\n        )\n        input_dict: dict[str, str | list[Dict[str, str]]] = {\"input\": self.input_value}\n        if hasattr(self, \"memory\") and self.memory:\n            input_dict[\"chat_history\"] = self.convert_chat_history(self.memory)\n        result = await runnable.ainvoke(input_dict)\n        self.status = result\n\n        if \"output\" not in result:\n            raise ValueError(\"Output key not found in result. Tried 'output'.\")\n\n        result_string = result[\"output\"]\n\n        return Message(text=result_string)\n\n    def convert_chat_history(self, chat_history: List[Data]) -> List[Dict[str, str]]:\n        messages = []\n        for item in chat_history:\n            role = \"user\" if item.sender == \"User\" else \"assistant\"\n            messages.append({\"role\": role, \"content\": item.text})\n        return messages\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "handle_parsing_errors": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": true,
          "name": "handle_parsing_errors",
          "display_name": "Handle Parsing Errors",
          "advanced": true,
          "dynamic": false,
          "info": "If True, the agent will handle parsing errors. If False, the agent will raise an error.",
          "title_case": false,
          "type": "bool"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Inputs",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Input text to pass to the agent.",
          "title_case": false,
          "type": "str"
        },
        "system_prompt": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "You are a helpful assistant",
          "name": "system_prompt",
          "display_name": "System Prompt",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "System prompt for the agent.",
          "title_case": false,
          "type": "str"
        },
        "user_prompt": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "{input}",
          "name": "user_prompt",
          "display_name": "Prompt",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "This prompt must contain 'input' key.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Agent that uses tools. Only models that are compatible with function calling are supported.",
      "icon": "LangChain",
      "base_classes": [
        "Message"
      ],
      "display_name": "Tool Calling Agent",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "run_agent",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "system_prompt",
        "input_value",
        "user_prompt",
        "handle_parsing_errors",
        "memory",
        "tools",
        "llm"
      ],
      "beta": true,
      "edited": false
    },
    "XMLAgent": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "message_history": {
          "type": "Data",
          "required": false,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "message_history",
          "display_name": "Message History",
          "advanced": false,
          "dynamic": false,
          "info": "Message history to pass to the agent.",
          "load_from_db": false,
          "title_case": false
        },
        "tools": {
          "type": "Tool",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "tools",
          "display_name": "Tools",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List, Optional\n\nfrom langchain.agents import create_xml_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\nfrom langflow.base.agents.agent import LCAgentComponent\nfrom langflow.field_typing import LanguageModel, Text, Tool\nfrom langflow.schema import Data\n\n\nclass XMLAgentComponent(LCAgentComponent):\n    display_name = \"XMLAgent\"\n    description = \"Construct an XML agent from an LLM and tools.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"tools\": {\"display_name\": \"Tools\"},\n            \"user_prompt\": {\n                \"display_name\": \"Prompt\",\n                \"multiline\": True,\n                \"info\": \"This prompt must contain 'tools' and 'agent_scratchpad' keys.\",\n                \"value\": \"\"\"You are a helpful assistant. Help the user answer any questions.\n\n            You have access to the following tools:\n\n            {tools}\n\n            In order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\n            For example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n            <tool>search</tool><tool_input>weather in SF</tool_input>\n            <observation>64 degrees</observation>\n\n            When you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n            <final_answer>The weather in SF is 64 degrees</final_answer>\n\n            Begin!\n\n            Previous Conversation:\n            {chat_history}\n\n            Question: {input}\n            {agent_scratchpad}\"\"\",\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to be passed to the LLM.\",\n                \"advanced\": True,\n            },\n            \"tool_template\": {\n                \"display_name\": \"Tool Template\",\n                \"info\": \"Template for rendering tools in the prompt. Tools have 'name' and 'description' keys.\",\n                \"advanced\": True,\n            },\n            \"handle_parsing_errors\": {\n                \"display_name\": \"Handle Parsing Errors\",\n                \"info\": \"If True, the agent will handle parsing errors. If False, the agent will raise an error.\",\n                \"advanced\": True,\n            },\n            \"message_history\": {\n                \"display_name\": \"Message History\",\n                \"info\": \"Message history to pass to the agent.\",\n            },\n            \"input_value\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"Input text to pass to the agent.\",\n            },\n        }\n\n    async def build(\n        self,\n        input_value: str,\n        llm: LanguageModel,\n        tools: List[Tool],\n        user_prompt: str = \"{input}\",\n        system_message: str = \"You are a helpful assistant\",\n        message_history: Optional[List[Data]] = None,\n        tool_template: str = \"{name}: {description}\",\n        handle_parsing_errors: bool = True,\n    ) -> Text:\n        if \"input\" not in user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n\n        def render_tool_description(tools):\n            return \"\\n\".join(\n                [tool_template.format(name=tool.name, description=tool.description, args=tool.args) for tool in tools]\n            )\n\n        messages = [\n            (\"system\", system_message),\n            (\n                \"placeholder\",\n                \"{chat_history}\",\n            ),\n            (\"human\", user_prompt),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        agent = create_xml_agent(llm, tools, prompt, tools_renderer=render_tool_description)\n        result = await self.run_agent(\n            agent=agent,\n            inputs=input_value,\n            tools=tools,\n            message_history=message_history,\n            handle_parsing_errors=handle_parsing_errors,\n        )\n        self.status = result\n        return result\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "handle_parsing_errors": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": true,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "handle_parsing_errors",
          "display_name": "Handle Parsing Errors",
          "advanced": true,
          "dynamic": false,
          "info": "If True, the agent will handle parsing errors. If False, the agent will raise an error.",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Inputs",
          "advanced": false,
          "dynamic": false,
          "info": "Input text to pass to the agent.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "system_message": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "You are a helpful assistant",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to be passed to the LLM.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "tool_template": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "{name}: {description}",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "tool_template",
          "display_name": "Tool Template",
          "advanced": true,
          "dynamic": false,
          "info": "Template for rendering tools in the prompt. Tools have 'name' and 'description' keys.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "user_prompt": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "You are a helpful assistant. Help the user answer any questions.\n\n            You have access to the following tools:\n\n            {tools}\n\n            In order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\n            For example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n            <tool>search</tool><tool_input>weather in SF</tool_input>\n            <observation>64 degrees</observation>\n\n            When you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n            <final_answer>The weather in SF is 64 degrees</final_answer>\n\n            Begin!\n\n            Previous Conversation:\n            {chat_history}\n\n            Question: {input}\n            {agent_scratchpad}",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "user_prompt",
          "display_name": "Prompt",
          "advanced": false,
          "dynamic": false,
          "info": "This prompt must contain 'tools' and 'agent_scratchpad' keys.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Construct an XML agent from an LLM and tools.",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "XMLAgent",
      "documentation": "",
      "custom_fields": {
        "input_value": null,
        "llm": null,
        "tools": null,
        "user_prompt": null,
        "system_message": null,
        "message_history": null,
        "tool_template": null,
        "handle_parsing_errors": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    }
  },
  "toolkits": {
    "VectorStoreRouterToolkit": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "vectorstores": {
          "type": "VectorStoreInfo",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "vectorstores",
          "display_name": "Vector Stores",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List, Union\n\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreInfo, VectorStoreRouterToolkit\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import LanguageModel, Tool\n\n\nclass VectorStoreRouterToolkitComponent(CustomComponent):\n    display_name = \"VectorStoreRouterToolkit\"\n    description = \"Toolkit for routing between Vector Stores.\"\n\n    def build_config(self):\n        return {\n            \"vectorstores\": {\"display_name\": \"Vector Stores\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n        }\n\n    def build(self, vectorstores: List[VectorStoreInfo], llm: LanguageModel) -> Union[Tool, VectorStoreRouterToolkit]:\n        print(\"vectorstores\", vectorstores)\n        print(\"llm\", llm)\n        return VectorStoreRouterToolkit(vectorstores=vectorstores, llm=llm)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Toolkit for routing between Vector Stores.",
      "base_classes": [
        "BaseTool",
        "BaseToolkit",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable",
        "Tool",
        "VectorStoreRouterToolkit"
      ],
      "display_name": "VectorStoreRouterToolkit",
      "documentation": "",
      "custom_fields": {
        "vectorstores": null,
        "llm": null
      },
      "output_types": [
        "Tool",
        "VectorStoreRouterToolkit"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Tool"
          ],
          "selected": "Tool",
          "name": "tool",
          "hidden": null,
          "display_name": "Tool",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "VectorStoreRouterToolkit"
          ],
          "selected": "VectorStoreRouterToolkit",
          "name": "vectorstoreroutertoolkit",
          "hidden": null,
          "display_name": "VectorStoreRouterToolkit",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "JsonToolkit": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from pathlib import Path\n\nimport yaml\nfrom langchain_community.agent_toolkits.json.toolkit import JsonToolkit\nfrom langchain_community.tools.json.tool import JsonSpec\n\nfrom langflow.custom import CustomComponent\n\n\nclass JsonToolkitComponent(CustomComponent):\n    display_name = \"JsonToolkit\"\n    description = \"Toolkit for interacting with a JSON spec.\"\n\n    def build_config(self):\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n                \"field_type\": \"file\",\n                \"file_types\": [\"json\", \"yaml\", \"yml\"],\n            },\n        }\n\n    def build(self, path: str) -> JsonToolkit:\n        if path.endswith(\"yaml\") or path.endswith(\"yml\"):\n            yaml_dict = yaml.load(open(path, \"r\"), Loader=yaml.FullLoader)\n            spec = JsonSpec(dict_=yaml_dict)\n        else:\n            spec = JsonSpec.from_file(Path(path))\n        return JsonToolkit(spec=spec)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "path": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [
            ".json",
            ".yaml",
            ".yml"
          ],
          "file_path": "",
          "password": false,
          "name": "path",
          "display_name": "Path",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Toolkit for interacting with a JSON spec.",
      "base_classes": [
        "BaseToolkit",
        "JsonToolkit"
      ],
      "display_name": "JsonToolkit",
      "documentation": "",
      "custom_fields": {
        "path": null
      },
      "output_types": [
        "JsonToolkit"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "JsonToolkit"
          ],
          "selected": "JsonToolkit",
          "name": "jsontoolkit",
          "hidden": null,
          "display_name": "JsonToolkit",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "Metaphor": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List, Union\n\nfrom langchain_community.agent_toolkits.base import BaseToolkit\nfrom langchain_core.tools import Tool, tool\nfrom metaphor_python import Metaphor  # type: ignore\n\nfrom langflow.custom import CustomComponent\n\n\nclass MetaphorToolkit(CustomComponent):\n    display_name: str = \"Metaphor\"\n    description: str = \"Metaphor Toolkit\"\n    documentation = \"https://python.langchain.com/docs/integrations/tools/metaphor_search\"\n    beta: bool = True\n    # api key should be password = True\n    field_config = {\n        \"metaphor_api_key\": {\"display_name\": \"Metaphor API Key\", \"password\": True},\n        \"code\": {\"advanced\": True},\n    }\n\n    def build(\n        self,\n        metaphor_api_key: str,\n        use_autoprompt: bool = True,\n        search_num_results: int = 5,\n        similar_num_results: int = 5,\n    ) -> Union[Tool, BaseToolkit]:\n        # If documents, then we need to create a Vectara instance using .from_documents\n        client = Metaphor(api_key=metaphor_api_key)\n\n        @tool\n        def search(query: str):\n            \"\"\"Call search engine with a query.\"\"\"\n            return client.search(query, use_autoprompt=use_autoprompt, num_results=search_num_results)\n\n        @tool\n        def get_contents(ids: List[str]):\n            \"\"\"Get contents of a webpage.\n\n            The ids passed in should be a list of ids as fetched from `search`.\n            \"\"\"\n            return client.get_contents(ids)\n\n        @tool\n        def find_similar(url: str):\n            \"\"\"Get search results similar to a given URL.\n\n            The url passed in should be a URL returned from `search`\n            \"\"\"\n            return client.find_similar(url, num_results=similar_num_results)\n\n        return [search, get_contents, find_similar]  # type: ignore\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "metaphor_api_key": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "metaphor_api_key",
          "display_name": "Metaphor API Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "search_num_results": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 5,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "search_num_results",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "similar_num_results": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 5,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "similar_num_results",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "use_autoprompt": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": true,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "use_autoprompt",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Metaphor Toolkit",
      "base_classes": [
        "BaseTool",
        "BaseToolkit",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable",
        "Tool"
      ],
      "display_name": "Metaphor",
      "documentation": "https://python.langchain.com/docs/integrations/tools/metaphor_search",
      "custom_fields": {
        "metaphor_api_key": null,
        "use_autoprompt": null,
        "search_num_results": null,
        "similar_num_results": null
      },
      "output_types": [
        "Tool",
        "BaseToolkit"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Tool"
          ],
          "selected": "Tool",
          "name": "tool",
          "hidden": null,
          "display_name": "Tool",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "BaseToolkit"
          ],
          "selected": "BaseToolkit",
          "name": "basetoolkit",
          "hidden": null,
          "display_name": "BaseToolkit",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "metaphor_api_key",
        "code"
      ],
      "beta": true,
      "edited": false
    },
    "VectorStoreToolkit": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "vectorstore_info": {
          "type": "VectorStoreInfo",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "vectorstore_info",
          "display_name": "Vector Store Info",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Union\n\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreInfo, VectorStoreToolkit\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import LanguageModel, Tool\n\n\nclass VectorStoreToolkitComponent(CustomComponent):\n    display_name = \"VectorStoreToolkit\"\n    description = \"Toolkit for interacting with a Vector Store.\"\n\n    def build_config(self):\n        return {\n            \"vectorstore_info\": {\"display_name\": \"Vector Store Info\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n        }\n\n    def build(\n        self,\n        vectorstore_info: VectorStoreInfo,\n        llm: LanguageModel,\n    ) -> Union[Tool, VectorStoreToolkit]:\n        return VectorStoreToolkit(vectorstore_info=vectorstore_info, llm=llm)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Toolkit for interacting with a Vector Store.",
      "base_classes": [
        "BaseTool",
        "BaseToolkit",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable",
        "Tool",
        "VectorStoreToolkit"
      ],
      "display_name": "VectorStoreToolkit",
      "documentation": "",
      "custom_fields": {
        "vectorstore_info": null,
        "llm": null
      },
      "output_types": [
        "Tool",
        "VectorStoreToolkit"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Tool"
          ],
          "selected": "Tool",
          "name": "tool",
          "hidden": null,
          "display_name": "Tool",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "VectorStoreToolkit"
          ],
          "selected": "VectorStoreToolkit",
          "name": "vectorstoretoolkit",
          "hidden": null,
          "display_name": "VectorStoreToolkit",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "OpenAPIToolkit": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "allow_dangerous_requests": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "allow_dangerous_requests",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from pathlib import Path\n\nimport yaml\nfrom langchain_community.agent_toolkits.openapi.toolkit import BaseToolkit, OpenAPIToolkit\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_community.utilities.requests import TextRequestsWrapper\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import LanguageModel\n\n\nclass OpenAPIToolkitComponent(CustomComponent):\n    display_name = \"OpenAPIToolkit\"\n    description = \"Toolkit for interacting with an OpenAPI API.\"\n\n    def build_config(self):\n        return {\n            \"json_agent\": {\"display_name\": \"JSON Agent\"},\n            \"requests_wrapper\": {\"display_name\": \"Text Requests Wrapper\"},\n        }\n\n    def build(self, llm: LanguageModel, path: str, allow_dangerous_requests: bool = False) -> BaseToolkit:\n        if path.endswith(\"yaml\") or path.endswith(\"yml\"):\n            yaml_dict = yaml.load(open(path, \"r\"), Loader=yaml.FullLoader)\n            spec = JsonSpec(dict_=yaml_dict)\n        else:\n            spec = JsonSpec.from_file(Path(path))\n        requests_wrapper = TextRequestsWrapper()\n        return OpenAPIToolkit.from_llm(\n            llm=llm,\n            json_spec=spec,\n            requests_wrapper=requests_wrapper,\n            allow_dangerous_requests=allow_dangerous_requests,\n        )\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "path": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "path",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Toolkit for interacting with an OpenAPI API.",
      "base_classes": [
        "BaseToolkit"
      ],
      "display_name": "OpenAPIToolkit",
      "documentation": "",
      "custom_fields": {
        "llm": null,
        "path": null,
        "allow_dangerous_requests": null
      },
      "output_types": [
        "BaseToolkit"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "BaseToolkit"
          ],
          "selected": "BaseToolkit",
          "name": "basetoolkit",
          "hidden": null,
          "display_name": "BaseToolkit",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "VectorStoreInfo": {
      "template": {
        "_type": "CustomComponent",
        "vectorstore": {
          "type": "VectorStore",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "vectorstore",
          "display_name": "VectorStore",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreInfo\nfrom langchain_core.vectorstores import VectorStore\n\nfrom langflow.custom import CustomComponent\n\n\nclass VectorStoreInfoComponent(CustomComponent):\n    display_name = \"VectorStoreInfo\"\n    description = \"Information about a VectorStore\"\n\n    def build_config(self):\n        return {\n            \"vectorstore\": {\"display_name\": \"VectorStore\"},\n            \"description\": {\"display_name\": \"Description\", \"multiline\": True},\n            \"name\": {\"display_name\": \"Name\"},\n        }\n\n    def build(\n        self,\n        vectorstore: VectorStore,\n        description: str,\n        name: str,\n    ) -> VectorStoreInfo:\n        return VectorStoreInfo(vectorstore=vectorstore, description=description, name=name)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "description": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "description",
          "display_name": "Description",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "name",
          "display_name": "Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Information about a VectorStore",
      "base_classes": [
        "VectorStoreInfo"
      ],
      "display_name": "VectorStoreInfo",
      "documentation": "",
      "custom_fields": {
        "vectorstore": null,
        "description": null,
        "name": null
      },
      "output_types": [
        "VectorStoreInfo"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "VectorStoreInfo"
          ],
          "selected": "VectorStoreInfo",
          "name": "vectorstoreinfo",
          "hidden": null,
          "display_name": "VectorStoreInfo",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    }
  },
  "models": {
    "MistralModel": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_mistralai import ChatMistralAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageInput, Output, SecretStrInput, StrInput\n\n\nclass MistralAIModelComponent(LCModelComponent):\n    display_name = \"MistralAI\"\n    description = \"Generates text using MistralAI LLMs.\"\n    icon = \"MistralAI\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"open-mixtral-8x7b\",\n                \"open-mixtral-8x22b\",\n                \"mistral-small-latest\",\n                \"mistral-medium-latest\",\n                \"mistral-large-latest\",\n                \"codestral-latest\",\n            ],\n            value=\"codestral-latest\",\n        ),\n        StrInput(\n            name=\"mistral_api_base\",\n            display_name=\"Mistral API Base\",\n            advanced=True,\n            info=(\n                \"The base URL of the Mistral API. Defaults to https://api.mistral.ai/v1. \"\n                \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n            ),\n        ),\n        SecretStrInput(\n            name=\"mistral_api_key\",\n            display_name=\"Mistral API Key\",\n            info=\"The Mistral API Key to use for the Mistral model.\",\n            advanced=False,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", advanced=False, value=0.5),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", advanced=True, value=5),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", advanced=True, value=60),\n        IntInput(name=\"max_concurrent_requests\", display_name=\"Max Concurrent Requests\", advanced=True, value=3),\n        FloatInput(name=\"top_p\", display_name=\"Top P\", advanced=True, value=1),\n        IntInput(name=\"random_seed\", display_name=\"Random Seed\", value=1, advanced=True),\n        BoolInput(name=\"safe_mode\", display_name=\"Safe Mode\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"text_response\"),\n        Output(display_name=\"Language Model\", name=\"model_output\", method=\"build_model\"),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        mistral_api_key = self.mistral_api_key\n        temperature = self.temperature\n        model_name = self.model_name\n        max_tokens = self.max_tokens\n        mistral_api_base = self.mistral_api_base or \"https://api.mistral.ai/v1\"\n        max_retries = self.max_retries\n        timeout = self.timeout\n        max_concurrent_requests = self.max_concurrent_requests\n        top_p = self.top_p\n        random_seed = self.random_seed\n        safe_mode = self.safe_mode\n\n        if mistral_api_key:\n            api_key = SecretStr(mistral_api_key)\n        else:\n            api_key = None\n\n        output = ChatMistralAI(\n            max_tokens=max_tokens or None,\n            model_name=model_name,\n            endpoint=mistral_api_base,\n            api_key=api_key,\n            temperature=temperature,\n            max_retries=max_retries,\n            timeout=timeout,\n            max_concurrent_requests=max_concurrent_requests,\n            top_p=top_p,\n            random_seed=random_seed,\n            safe_mode=safe_mode,\n        )\n\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "max_concurrent_requests": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 3,
          "name": "max_concurrent_requests",
          "display_name": "Max Concurrent Requests",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "max_retries": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 5,
          "name": "max_retries",
          "display_name": "Max Retries",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "max_tokens": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "max_tokens",
          "display_name": "Max Tokens",
          "advanced": true,
          "dynamic": false,
          "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
          "title_case": false,
          "type": "int"
        },
        "mistral_api_base": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "mistral_api_base",
          "display_name": "Mistral API Base",
          "advanced": true,
          "dynamic": false,
          "info": "The base URL of the Mistral API. Defaults to https://api.mistral.ai/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
          "title_case": false,
          "type": "str"
        },
        "mistral_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "mistral_api_key",
          "display_name": "Mistral API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "The Mistral API Key to use for the Mistral model.",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "model_name": {
          "trace_as_metadata": true,
          "options": [
            "open-mixtral-8x7b",
            "open-mixtral-8x22b",
            "mistral-small-latest",
            "mistral-medium-latest",
            "mistral-large-latest",
            "codestral-latest"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "codestral-latest",
          "name": "model_name",
          "display_name": "Model Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "random_seed": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 1,
          "name": "random_seed",
          "display_name": "Random Seed",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "safe_mode": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "safe_mode",
          "display_name": "Safe Mode",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "bool"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.5,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        },
        "timeout": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 60,
          "name": "timeout",
          "display_name": "Timeout",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "top_p": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 1,
          "name": "top_p",
          "display_name": "Top P",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generates text using MistralAI LLMs.",
      "icon": "MistralAI",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "MistralAI",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "max_tokens",
        "model_name",
        "mistral_api_base",
        "mistral_api_key",
        "temperature",
        "stream",
        "system_message",
        "max_retries",
        "timeout",
        "max_concurrent_requests",
        "top_p",
        "random_seed",
        "safe_mode"
      ],
      "beta": false,
      "edited": false
    },
    "AmazonBedrockModel": {
      "template": {
        "_type": "Component",
        "cache": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "cache",
          "display_name": "Cache",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "bool"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_aws import ChatBedrock\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DictInput, DropdownInput, MessageInput, Output, StrInput\n\n\nclass AmazonBedrockComponent(LCModelComponent):\n    display_name: str = \"Amazon Bedrock\"\n    description: str = \"Generate text using Amazon Bedrock LLMs.\"\n    icon = \"Amazon\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        DropdownInput(\n            name=\"model_id\",\n            display_name=\"Model ID\",\n            options=[\n                \"amazon.titan-text-express-v1\",\n                \"amazon.titan-text-lite-v1\",\n                \"amazon.titan-text-premier-v1:0\",\n                \"amazon.titan-embed-text-v1\",\n                \"amazon.titan-embed-text-v2:0\",\n                \"amazon.titan-embed-image-v1\",\n                \"amazon.titan-image-generator-v1\",\n                \"anthropic.claude-v2\",\n                \"anthropic.claude-v2:1\",\n                \"anthropic.claude-3-sonnet-20240229-v1:0\",\n                \"anthropic.claude-3-haiku-20240307-v1:0\",\n                \"anthropic.claude-3-opus-20240229-v1:0\",\n                \"anthropic.claude-instant-v1\",\n                \"ai21.j2-mid-v1\",\n                \"ai21.j2-ultra-v1\",\n                \"cohere.command-text-v14\",\n                \"cohere.command-light-text-v14\",\n                \"cohere.command-r-v1:0\",\n                \"cohere.command-r-plus-v1:0\",\n                \"cohere.embed-english-v3\",\n                \"cohere.embed-multilingual-v3\",\n                \"meta.llama2-13b-chat-v1\",\n                \"meta.llama2-70b-chat-v1\",\n                \"meta.llama3-8b-instruct-v1:0\",\n                \"meta.llama3-70b-instruct-v1:0\",\n                \"mistral.mistral-7b-instruct-v0:2\",\n                \"mistral.mixtral-8x7b-instruct-v0:1\",\n                \"mistral.mistral-large-2402-v1:0\",\n                \"mistral.mistral-small-2402-v1:0\",\n                \"stability.stable-diffusion-xl-v0\",\n                \"stability.stable-diffusion-xl-v1\",\n            ],\n            value=\"anthropic.claude-3-haiku-20240307-v1:0\",\n        ),\n        StrInput(name=\"credentials_profile_name\", display_name=\"Credentials Profile Name\"),\n        StrInput(name=\"region_name\", display_name=\"Region Name\"),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        StrInput(name=\"endpoint_url\", display_name=\"Endpoint URL\"),\n        BoolInput(name=\"cache\", display_name=\"Cache\"),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"text_response\"),\n        Output(display_name=\"Language Model\", name=\"model_output\", method=\"build_model\"),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        model_id = self.model_id\n        credentials_profile_name = self.credentials_profile_name\n        region_name = self.region_name\n        model_kwargs = self.model_kwargs\n        endpoint_url = self.endpoint_url\n        cache = self.cache\n        stream = self.stream\n        try:\n            output = ChatBedrock(  # type: ignore\n                credentials_profile_name=credentials_profile_name,\n                model_id=model_id,\n                region_name=region_name,\n                model_kwargs=model_kwargs,\n                endpoint_url=endpoint_url,\n                streaming=stream,\n                cache=cache,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to AmazonBedrock API.\") from e\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "credentials_profile_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "credentials_profile_name",
          "display_name": "Credentials Profile Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "endpoint_url": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "endpoint_url",
          "display_name": "Endpoint URL",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "model_id": {
          "trace_as_metadata": true,
          "options": [
            "amazon.titan-text-express-v1",
            "amazon.titan-text-lite-v1",
            "amazon.titan-text-premier-v1:0",
            "amazon.titan-embed-text-v1",
            "amazon.titan-embed-text-v2:0",
            "amazon.titan-embed-image-v1",
            "amazon.titan-image-generator-v1",
            "anthropic.claude-v2",
            "anthropic.claude-v2:1",
            "anthropic.claude-3-sonnet-20240229-v1:0",
            "anthropic.claude-3-haiku-20240307-v1:0",
            "anthropic.claude-3-opus-20240229-v1:0",
            "anthropic.claude-instant-v1",
            "ai21.j2-mid-v1",
            "ai21.j2-ultra-v1",
            "cohere.command-text-v14",
            "cohere.command-light-text-v14",
            "cohere.command-r-v1:0",
            "cohere.command-r-plus-v1:0",
            "cohere.embed-english-v3",
            "cohere.embed-multilingual-v3",
            "meta.llama2-13b-chat-v1",
            "meta.llama2-70b-chat-v1",
            "meta.llama3-8b-instruct-v1:0",
            "meta.llama3-70b-instruct-v1:0",
            "mistral.mistral-7b-instruct-v0:2",
            "mistral.mixtral-8x7b-instruct-v0:1",
            "mistral.mistral-large-2402-v1:0",
            "mistral.mistral-small-2402-v1:0",
            "stability.stable-diffusion-xl-v0",
            "stability.stable-diffusion-xl-v1"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "anthropic.claude-3-haiku-20240307-v1:0",
          "name": "model_id",
          "display_name": "Model ID",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "model_kwargs": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "model_kwargs",
          "display_name": "Model Kwargs",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "dict"
        },
        "region_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "region_name",
          "display_name": "Region Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Generate text using Amazon Bedrock LLMs.",
      "icon": "Amazon",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "Amazon Bedrock",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "model_id",
        "credentials_profile_name",
        "region_name",
        "model_kwargs",
        "endpoint_url",
        "cache",
        "system_message",
        "stream"
      ],
      "beta": false,
      "edited": false
    },
    "AzureOpenAIModel": {
      "template": {
        "_type": "Component",
        "api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "api_key",
          "display_name": "API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "api_version": {
          "trace_as_metadata": true,
          "options": [
            "2023-03-15-preview",
            "2023-05-15",
            "2023-06-01-preview",
            "2023-07-01-preview",
            "2023-08-01-preview",
            "2023-09-01-preview",
            "2023-12-01-preview",
            "2024-04-09",
            "2024-05-13"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "2024-05-13",
          "name": "api_version",
          "display_name": "API Version",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "azure_deployment": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "azure_deployment",
          "display_name": "Deployment Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "azure_endpoint": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "azure_endpoint",
          "display_name": "Azure Endpoint",
          "advanced": false,
          "dynamic": false,
          "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_openai import AzureChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageInput, Output, SecretStrInput, StrInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n\n    AZURE_OPENAI_MODELS = [\n        \"gpt-35-turbo\",\n        \"gpt-35-turbo-16k\",\n        \"gpt-35-turbo-instruct\",\n        \"gpt-4\",\n        \"gpt-4-32k\",\n        \"gpt-4o\",\n        \"gpt-4-turbo\",\n    ]\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n        \"2024-04-09\",\n        \"2024-05-13\",\n    ]\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=AZURE_OPENAI_MODELS,\n            value=AZURE_OPENAI_MODELS[0],\n        ),\n        StrInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n        ),\n        StrInput(name=\"azure_deployment\", display_name=\"Deployment Name\"),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=AZURE_OPENAI_API_VERSIONS,\n            value=AZURE_OPENAI_API_VERSIONS[-1],\n            advanced=True,\n        ),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", password=True),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            advanced=True,\n            info=\"System message to pass to the model.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"text_response\"),\n        Output(display_name=\"Language Model\", name=\"model_output\", method=\"model_response\"),\n    ]\n\n    def model_response(self) -> LanguageModel:\n        model = self.model\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        if api_key:\n            secret_api_key = SecretStr(api_key)\n        else:\n            secret_api_key = None\n\n        try:\n            output = AzureChatOpenAI(\n                model=model,\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=secret_api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to AzureOpenAI API.\") from e\n\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "max_tokens": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "max_tokens",
          "display_name": "Max Tokens",
          "advanced": true,
          "dynamic": false,
          "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
          "title_case": false,
          "type": "int"
        },
        "model": {
          "trace_as_metadata": true,
          "options": [
            "gpt-35-turbo",
            "gpt-35-turbo-16k",
            "gpt-35-turbo-instruct",
            "gpt-4",
            "gpt-4-32k",
            "gpt-4o",
            "gpt-4-turbo"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "gpt-35-turbo",
          "name": "model",
          "display_name": "Model Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.7,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generate text using Azure OpenAI LLMs.",
      "icon": "Azure",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "Azure OpenAI",
      "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "model_response",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "model",
        "azure_endpoint",
        "azure_deployment",
        "api_version",
        "api_key",
        "temperature",
        "max_tokens",
        "input_value",
        "stream",
        "system_message"
      ],
      "beta": false,
      "edited": false
    },
    "CohereModel": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_cohere import ChatCohere\nfrom langchain_core.language_models.chat_models import BaseChatModel\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, FloatInput, MessageInput, Output, SecretStrInput, StrInput\n\n\nclass CohereComponent(LCModelComponent):\n    display_name = \"Cohere\"\n    description = \"Generate text using Cohere LLMs.\"\n    documentation = \"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere\"\n    icon = \"Cohere\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"cohere_api_key\",\n            display_name=\"Cohere API Key\",\n            info=\"The Cohere API Key to use for the Cohere model.\",\n            advanced=False,\n            value=\"COHERE_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.75),\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"text_response\"),\n        Output(display_name=\"Language Model\", name=\"model_output\", method=\"build_model\"),\n    ]\n\n    def build_model(self) -> LanguageModel | BaseChatModel:\n        cohere_api_key = self.cohere_api_key\n        temperature = self.temperature\n\n        if cohere_api_key:\n            api_key = SecretStr(cohere_api_key)\n        else:\n            api_key = None\n\n        output = ChatCohere(\n            temperature=temperature or 0.75,\n            cohere_api_key=api_key,\n        )\n\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "cohere_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "COHERE_API_KEY",
          "name": "cohere_api_key",
          "display_name": "Cohere API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "The Cohere API Key to use for the Cohere model.",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.75,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generate text using Cohere LLMs.",
      "icon": "Cohere",
      "base_classes": [
        "BaseChatModel",
        "LanguageModel",
        "Message"
      ],
      "display_name": "Cohere",
      "documentation": "https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel",
            "BaseChatModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "cohere_api_key",
        "temperature",
        "input_value",
        "stream",
        "system_message"
      ],
      "beta": false,
      "edited": false
    },
    "BaiduQianfanChatModel": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_community.chat_models.baidu_qianfan_endpoint import QianfanChatEndpoint\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing.constants import LanguageModel\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, MessageTextInput, Output, SecretStrInput\n\n\nclass QianfanChatEndpointComponent(LCModelComponent):\n    display_name: str = \"Qianfan\"\n    description: str = \"Generate text using Baidu Qianfan LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\"\n    icon = \"BaiduQianfan\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"ERNIE-Bot\",\n                \"ERNIE-Bot-turbo\",\n                \"BLOOMZ-7B\",\n                \"Llama-2-7b-chat\",\n                \"Llama-2-13b-chat\",\n                \"Llama-2-70b-chat\",\n                \"Qianfan-BLOOMZ-7B-compressed\",\n                \"Qianfan-Chinese-Llama-2-7B\",\n                \"ChatGLM2-6B-32K\",\n                \"AquilaChat-7B\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\",\n            value=\"ERNIE-Bot-turbo\",\n        ),\n        SecretStrInput(\n            name=\"qianfan_ak\",\n            display_name=\"Qianfan Ak\",\n            info=\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\n        ),\n        SecretStrInput(\n            name=\"qianfan_sk\",\n            display_name=\"Qianfan Sk\",\n            info=\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top p\",\n            info=\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\n            value=0.8,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            info=\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\n            value=0.95,\n        ),\n        FloatInput(\n            name=\"penalty_score\",\n            display_name=\"Penalty Score\",\n            info=\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\n            value=1.0,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"endpoint\",\n            display_name=\"Endpoint\",\n            info=\"Endpoint of the Qianfan LLM, required if custom model used.\",\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=STREAM_INFO_TEXT,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"text_response\"),\n        Output(display_name=\"Language Model\", name=\"model_output\", method=\"build_model\"),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        model = self.model\n        qianfan_ak = self.qianfan_ak\n        qianfan_sk = self.qianfan_sk\n        top_p = self.top_p\n        temperature = self.temperature\n        penalty_score = self.penalty_score\n        endpoint = self.endpoint\n\n        try:\n            output = QianfanChatEndpoint(  # type: ignore\n                model=model,\n                qianfan_ak=SecretStr(qianfan_ak) if qianfan_ak else None,\n                qianfan_sk=SecretStr(qianfan_sk) if qianfan_sk else None,\n                top_p=top_p,\n                temperature=temperature,\n                penalty_score=penalty_score,\n                endpoint=endpoint,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Baidu Qianfan API.\") from e\n\n        return output  # type: ignore\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "endpoint": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "endpoint",
          "display_name": "Endpoint",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Endpoint of the Qianfan LLM, required if custom model used.",
          "title_case": false,
          "type": "str"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "model": {
          "trace_as_metadata": true,
          "options": [
            "ERNIE-Bot",
            "ERNIE-Bot-turbo",
            "BLOOMZ-7B",
            "Llama-2-7b-chat",
            "Llama-2-13b-chat",
            "Llama-2-70b-chat",
            "Qianfan-BLOOMZ-7B-compressed",
            "Qianfan-Chinese-Llama-2-7B",
            "ChatGLM2-6B-32K",
            "AquilaChat-7B"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "ERNIE-Bot-turbo",
          "name": "model",
          "display_name": "Model Name",
          "advanced": false,
          "dynamic": false,
          "info": "https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint",
          "title_case": false,
          "type": "str"
        },
        "penalty_score": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 1.0,
          "name": "penalty_score",
          "display_name": "Penalty Score",
          "advanced": true,
          "dynamic": false,
          "info": "Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo",
          "title_case": false,
          "type": "float"
        },
        "qianfan_ak": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "qianfan_ak",
          "display_name": "Qianfan Ak",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "which you could get from  https://cloud.baidu.com/product/wenxinworkshop",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "qianfan_sk": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "qianfan_sk",
          "display_name": "Qianfan Sk",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "which you could get from  https://cloud.baidu.com/product/wenxinworkshop",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.95,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo",
          "title_case": false,
          "type": "float"
        },
        "top_p": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.8,
          "name": "top_p",
          "display_name": "Top p",
          "advanced": true,
          "dynamic": false,
          "info": "Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generate text using Baidu Qianfan LLMs.",
      "icon": "BaiduQianfan",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "Qianfan",
      "documentation": "https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "model",
        "qianfan_ak",
        "qianfan_sk",
        "top_p",
        "temperature",
        "penalty_score",
        "endpoint",
        "stream",
        "system_message"
      ],
      "beta": false,
      "edited": false
    },
    "HuggingFaceModel": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_community.chat_models.huggingface import ChatHuggingFace\nfrom langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DictInput, DropdownInput, MessageInput, Output, SecretStrInput, StrInput\n\n\nclass HuggingFaceEndpointsComponent(LCModelComponent):\n    display_name: str = \"Hugging Face API\"\n    description: str = \"Generate text using Hugging Face Inference APIs.\"\n    icon = \"HuggingFace\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        SecretStrInput(name=\"endpoint_url\", display_name=\"Endpoint URL\", password=True),\n        DropdownInput(\n            name=\"task\",\n            display_name=\"Task\",\n            options=[\"text2text-generation\", \"text-generation\", \"summarization\"],\n        ),\n        SecretStrInput(name=\"huggingfacehub_api_token\", display_name=\"API token\", password=True),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Keyword Arguments\", advanced=True),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"text_response\"),\n        Output(display_name=\"Language Model\", name=\"model_output\", method=\"build_model\"),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        endpoint_url = self.endpoint_url\n        task = self.task\n        huggingfacehub_api_token = self.huggingfacehub_api_token\n        model_kwargs = self.model_kwargs or {}\n\n        try:\n            llm = HuggingFaceEndpoint(  # type: ignore\n                endpoint_url=endpoint_url,\n                task=task,\n                huggingfacehub_api_token=huggingfacehub_api_token,\n                model_kwargs=model_kwargs,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to HuggingFace Endpoints API.\") from e\n\n        output = ChatHuggingFace(llm=llm)\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "endpoint_url": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "endpoint_url",
          "display_name": "Endpoint URL",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "huggingfacehub_api_token": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "huggingfacehub_api_token",
          "display_name": "API token",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "model_kwargs": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "model_kwargs",
          "display_name": "Model Keyword Arguments",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "dict"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "task": {
          "trace_as_metadata": true,
          "options": [
            "text2text-generation",
            "text-generation",
            "summarization"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "task",
          "display_name": "Task",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Generate text using Hugging Face Inference APIs.",
      "icon": "HuggingFace",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "Hugging Face API",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "endpoint_url",
        "task",
        "huggingfacehub_api_token",
        "model_kwargs",
        "stream",
        "system_message"
      ],
      "beta": false,
      "edited": false
    },
    "GoogleGenerativeAIModel": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=[\"gemini-1.5-pro\", \"gemini-1.5-flash\", \"gemini-1.0-pro\", \"gemini-1.0-pro-vision\"],\n            value=\"gemini-1.5-pro\",\n        ),\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError:\n            raise ImportError(\"The 'langchain_google_genai' package is required to use the Google Generative AI model.\")\n\n        google_api_key = self.google_api_key\n        model = self.model\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatGoogleGenerativeAI(  # type: ignore\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key),\n        )\n\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "google_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "google_api_key",
          "display_name": "Google API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "The Google API Key to use for the Google Generative AI.",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "max_output_tokens": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "max_output_tokens",
          "display_name": "Max Output Tokens",
          "advanced": false,
          "dynamic": false,
          "info": "The maximum number of tokens to generate.",
          "title_case": false,
          "type": "int"
        },
        "model": {
          "trace_as_metadata": true,
          "options": [
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-1.0-pro",
            "gemini-1.0-pro-vision"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "gemini-1.5-pro",
          "name": "model",
          "display_name": "Model",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the model to use.",
          "title_case": false,
          "type": "str"
        },
        "n": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "n",
          "display_name": "N",
          "advanced": true,
          "dynamic": false,
          "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
          "title_case": false,
          "type": "int"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.1,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        },
        "top_k": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "top_k",
          "display_name": "Top K",
          "advanced": true,
          "dynamic": false,
          "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
          "title_case": false,
          "type": "int"
        },
        "top_p": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "top_p",
          "display_name": "Top P",
          "advanced": true,
          "dynamic": false,
          "info": "The maximum cumulative probability of tokens to consider when sampling.",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generate text using Google Generative AI.",
      "icon": "GoogleGenerativeAI",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "Google Generative AI",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "max_output_tokens",
        "model",
        "google_api_key",
        "top_p",
        "temperature",
        "stream",
        "n",
        "system_message",
        "top_k"
      ],
      "beta": false,
      "edited": false
    },
    "OllamaModel": {
      "template": {
        "_type": "Component",
        "base_url": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "http://localhost:11434",
          "name": "base_url",
          "display_name": "Base URL",
          "advanced": false,
          "dynamic": false,
          "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Any\n\nimport httpx\nfrom langchain_community.chat_models import ChatOllama\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageInput, Output, StrInput\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"mirostat\":\n            if field_value == \"Disabled\":\n                build_config[\"mirostat_eta\"][\"advanced\"] = True\n                build_config[\"mirostat_tau\"][\"advanced\"] = True\n                build_config[\"mirostat_eta\"][\"value\"] = None\n                build_config[\"mirostat_tau\"][\"value\"] = None\n\n            else:\n                build_config[\"mirostat_eta\"][\"advanced\"] = False\n                build_config[\"mirostat_tau\"][\"advanced\"] = False\n\n                if field_value == \"Mirostat 2.0\":\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.2\n                    build_config[\"mirostat_tau\"][\"value\"] = 10\n                else:\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.1\n                    build_config[\"mirostat_tau\"][\"value\"] = 5\n\n        if field_name == \"model\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = self.variables(base_url_value)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:11434\"\n            build_config[\"model\"][\"options\"] = self.get_model(base_url_value + \"/api/tags\")\n\n        if field_name == \"keep_alive_flag\":\n            if field_value == \"Keep\":\n                build_config[\"keep_alive\"][\"value\"] = \"-1\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            elif field_value == \"Immediately\":\n                build_config[\"keep_alive\"][\"value\"] = \"0\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            else:\n                build_config[\"keep_alive\"][\"advanced\"] = False\n\n        return build_config\n\n    def get_model(self, url: str) -> list[str]:\n        try:\n            with httpx.Client() as client:\n                response = client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                model_names = [model[\"name\"] for model in data.get(\"models\", [])]\n                return model_names\n        except Exception as e:\n            raise ValueError(\"Could not retrieve models. Please, make sure Ollama is running.\") from e\n\n    inputs = [\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            info=\"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            value=\"http://localhost:11434\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            value=\"llama2\",\n            info=\"Refer to https://ollama.ai/library for more models.\",\n            refresh_button=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.2,\n            info=\"Controls the creativity of model responses.\",\n        ),\n        StrInput(\n            name=\"format\",\n            display_name=\"Format\",\n            info=\"Specify the format of the output (e.g., json).\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"metadata\",\n            display_name=\"Metadata\",\n            info=\"Metadata to add to the run trace.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"mirostat\",\n            display_name=\"Mirostat\",\n            options=[\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n            info=\"Enable/disable Mirostat sampling for controlling perplexity.\",\n            value=\"Disabled\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"mirostat_eta\",\n            display_name=\"Mirostat Eta\",\n            info=\"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"mirostat_tau\",\n            display_name=\"Mirostat Tau\",\n            info=\"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_ctx\",\n            display_name=\"Context Window Size\",\n            info=\"Size of the context window for generating tokens. (Default: 2048)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_gpu\",\n            display_name=\"Number of GPUs\",\n            info=\"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_thread\",\n            display_name=\"Number of Threads\",\n            info=\"Number of threads to use during computation. (Default: detected for optimal performance)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"repeat_last_n\",\n            display_name=\"Repeat Last N\",\n            info=\"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"repeat_penalty\",\n            display_name=\"Repeat Penalty\",\n            info=\"Penalty for repetitions in generated text. (Default: 1.1)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"tfs_z\",\n            display_name=\"TFS Z\",\n            info=\"Tail free sampling value. (Default: 1)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the request stream.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Limits token selection to top K. (Default: 40)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"Works together with top-k. (Default: 0.9)\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            info=\"Whether to print out response text.\",\n        ),\n        StrInput(\n            name=\"tags\",\n            display_name=\"Tags\",\n            info=\"Comma-separated list of tags to add to the run trace.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"stop_tokens\",\n            display_name=\"Stop Tokens\",\n            info=\"Comma-separated list of tokens to signal the model to stop generating text.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"system\",\n            display_name=\"System\",\n            info=\"System to use for generating text.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"Template to use for generating text.\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=STREAM_INFO_TEXT,\n        ),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"text_response\"),\n        Output(display_name=\"Language Model\", name=\"model_output\", method=\"build_model\"),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(self.mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n        else:\n            mirostat_eta = self.mirostat_eta\n            mirostat_tau = self.mirostat_tau\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": self.base_url,\n            \"model\": self.model,\n            \"mirostat\": mirostat_value,\n            \"format\": self.format,\n            \"metadata\": self.metadata,\n            \"tags\": self.tags.split(\",\") if self.tags else None,\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": self.num_ctx or None,\n            \"num_gpu\": self.num_gpu or None,\n            \"num_thread\": self.num_thread or None,\n            \"repeat_last_n\": self.repeat_last_n or None,\n            \"repeat_penalty\": self.repeat_penalty or None,\n            \"temperature\": self.temperature or None,\n            \"stop\": self.stop_tokens.split(\",\") if self.stop_tokens else None,\n            \"system\": self.system,\n            \"template\": self.template,\n            \"tfs_z\": self.tfs_z or None,\n            \"timeout\": self.timeout or None,\n            \"top_k\": self.top_k or None,\n            \"top_p\": self.top_p or None,\n            \"verbose\": self.verbose,\n        }\n\n        # Remove parameters with None values\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not initialize Ollama LLM.\") from e\n\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "format": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "format",
          "display_name": "Format",
          "advanced": true,
          "dynamic": false,
          "info": "Specify the format of the output (e.g., json).",
          "title_case": false,
          "type": "str"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "metadata": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "metadata",
          "display_name": "Metadata",
          "advanced": true,
          "dynamic": false,
          "info": "Metadata to add to the run trace.",
          "title_case": false,
          "type": "dict"
        },
        "mirostat": {
          "trace_as_metadata": true,
          "options": [
            "Disabled",
            "Mirostat",
            "Mirostat 2.0"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Disabled",
          "name": "mirostat",
          "display_name": "Mirostat",
          "advanced": true,
          "dynamic": false,
          "info": "Enable/disable Mirostat sampling for controlling perplexity.",
          "title_case": false,
          "type": "str"
        },
        "mirostat_eta": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "mirostat_eta",
          "display_name": "Mirostat Eta",
          "advanced": true,
          "dynamic": false,
          "info": "Learning rate for Mirostat algorithm. (Default: 0.1)",
          "title_case": false,
          "type": "float"
        },
        "mirostat_tau": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "mirostat_tau",
          "display_name": "Mirostat Tau",
          "advanced": true,
          "dynamic": false,
          "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)",
          "title_case": false,
          "type": "float"
        },
        "model": {
          "trace_as_metadata": true,
          "options": [],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "llama2",
          "name": "model",
          "display_name": "Model Name",
          "advanced": false,
          "dynamic": false,
          "info": "Refer to https://ollama.ai/library for more models.",
          "refresh_button": true,
          "title_case": false,
          "type": "str"
        },
        "num_ctx": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "num_ctx",
          "display_name": "Context Window Size",
          "advanced": true,
          "dynamic": false,
          "info": "Size of the context window for generating tokens. (Default: 2048)",
          "title_case": false,
          "type": "int"
        },
        "num_gpu": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "num_gpu",
          "display_name": "Number of GPUs",
          "advanced": true,
          "dynamic": false,
          "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
          "title_case": false,
          "type": "int"
        },
        "num_thread": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "num_thread",
          "display_name": "Number of Threads",
          "advanced": true,
          "dynamic": false,
          "info": "Number of threads to use during computation. (Default: detected for optimal performance)",
          "title_case": false,
          "type": "int"
        },
        "repeat_last_n": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "repeat_last_n",
          "display_name": "Repeat Last N",
          "advanced": true,
          "dynamic": false,
          "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
          "title_case": false,
          "type": "int"
        },
        "repeat_penalty": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "repeat_penalty",
          "display_name": "Repeat Penalty",
          "advanced": true,
          "dynamic": false,
          "info": "Penalty for repetitions in generated text. (Default: 1.1)",
          "title_case": false,
          "type": "float"
        },
        "stop_tokens": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "stop_tokens",
          "display_name": "Stop Tokens",
          "advanced": true,
          "dynamic": false,
          "info": "Comma-separated list of tokens to signal the model to stop generating text.",
          "title_case": false,
          "type": "str"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": false,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system",
          "display_name": "System",
          "advanced": true,
          "dynamic": false,
          "info": "System to use for generating text.",
          "title_case": false,
          "type": "str"
        },
        "system_message": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "tags": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "tags",
          "display_name": "Tags",
          "advanced": true,
          "dynamic": false,
          "info": "Comma-separated list of tags to add to the run trace.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.2,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "Controls the creativity of model responses.",
          "title_case": false,
          "type": "float"
        },
        "template": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "template",
          "display_name": "Template",
          "advanced": true,
          "dynamic": false,
          "info": "Template to use for generating text.",
          "title_case": false,
          "type": "str"
        },
        "tfs_z": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "tfs_z",
          "display_name": "TFS Z",
          "advanced": true,
          "dynamic": false,
          "info": "Tail free sampling value. (Default: 1)",
          "title_case": false,
          "type": "float"
        },
        "timeout": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "timeout",
          "display_name": "Timeout",
          "advanced": true,
          "dynamic": false,
          "info": "Timeout for the request stream.",
          "title_case": false,
          "type": "int"
        },
        "top_k": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "top_k",
          "display_name": "Top K",
          "advanced": true,
          "dynamic": false,
          "info": "Limits token selection to top K. (Default: 40)",
          "title_case": false,
          "type": "int"
        },
        "top_p": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "top_p",
          "display_name": "Top P",
          "advanced": true,
          "dynamic": false,
          "info": "Works together with top-k. (Default: 0.9)",
          "title_case": false,
          "type": "float"
        },
        "verbose": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "verbose",
          "display_name": "Verbose",
          "advanced": false,
          "dynamic": false,
          "info": "Whether to print out response text.",
          "title_case": false,
          "type": "bool"
        }
      },
      "description": "Generate text using Ollama Local LLMs.",
      "icon": "Ollama",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "Ollama",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "base_url",
        "model",
        "temperature",
        "format",
        "metadata",
        "mirostat",
        "mirostat_eta",
        "mirostat_tau",
        "num_ctx",
        "num_gpu",
        "num_thread",
        "repeat_last_n",
        "repeat_penalty",
        "tfs_z",
        "timeout",
        "top_k",
        "top_p",
        "verbose",
        "tags",
        "stop_tokens",
        "system",
        "template",
        "input_value",
        "stream",
        "system_message"
      ],
      "beta": false,
      "edited": false
    },
    "OpenAIModel": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        # self.output_schea is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict)\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "max_tokens": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "max_tokens",
          "display_name": "Max Tokens",
          "advanced": true,
          "dynamic": false,
          "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
          "title_case": false,
          "type": "int"
        },
        "model_kwargs": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "model_kwargs",
          "display_name": "Model Kwargs",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "dict"
        },
        "model_name": {
          "trace_as_metadata": true,
          "options": [
            "gpt-4o",
            "gpt-4-turbo",
            "gpt-4-turbo-preview",
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-0125"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "gpt-4o",
          "name": "model_name",
          "display_name": "Model Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "openai_api_base": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "openai_api_base",
          "display_name": "OpenAI API Base",
          "advanced": true,
          "dynamic": false,
          "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
          "title_case": false,
          "type": "str"
        },
        "openai_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "OPENAI_API_KEY",
          "name": "openai_api_key",
          "display_name": "OpenAI API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "The OpenAI API Key to use for the OpenAI model.",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "output_schema": {
          "trace_as_input": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "output_schema",
          "display_name": "Schema",
          "advanced": true,
          "dynamic": false,
          "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
          "title_case": false,
          "type": "dict"
        },
        "seed": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 1,
          "name": "seed",
          "display_name": "Seed",
          "advanced": true,
          "dynamic": false,
          "info": "The seed controls the reproducibility of the job.",
          "title_case": false,
          "type": "int"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.1,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generates text using OpenAI LLMs.",
      "icon": "OpenAI",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "OpenAI",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "max_tokens",
        "model_kwargs",
        "output_schema",
        "model_name",
        "openai_api_base",
        "openai_api_key",
        "temperature",
        "stream",
        "system_message",
        "seed"
      ],
      "beta": false,
      "edited": false
    },
    "GroqModel": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_groq import ChatGroq\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.groq_constants import MODEL_NAMES\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass GroqModel(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"groq_api_key\",\n            display_name=\"Groq API Key\",\n            info=\"API key for the Groq API.\",\n        ),\n        MessageTextInput(\n            name=\"groq_api_base\",\n            display_name=\"Groq API Base\",\n            info=\"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            info=\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            value=0.1,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=MODEL_NAMES,\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input to the model.\",\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=STREAM_INFO_TEXT,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        groq_api_key = self.groq_api_key\n        model_name = self.model_name\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        groq_api_base = self.groq_api_base\n        n = self.n\n        stream = self.stream\n\n        output = ChatGroq(\n            model=model_name,\n            max_tokens=max_tokens or None,\n            temperature=temperature,\n            base_url=groq_api_base,\n            n=n or 1,\n            api_key=SecretStr(groq_api_key),\n            streaming=stream,\n        )\n\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "groq_api_base": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "groq_api_base",
          "display_name": "Groq API Base",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Base URL path for API requests, leave blank if not using a proxy or service emulator.",
          "title_case": false,
          "type": "str"
        },
        "groq_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "groq_api_key",
          "display_name": "Groq API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "API key for the Groq API.",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The input to the model.",
          "title_case": false,
          "type": "str"
        },
        "max_tokens": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "max_tokens",
          "display_name": "Max Output Tokens",
          "advanced": true,
          "dynamic": false,
          "info": "The maximum number of tokens to generate.",
          "title_case": false,
          "type": "int"
        },
        "model_name": {
          "trace_as_metadata": true,
          "options": [
            "llama3-8b-8192",
            "llama3-70b-8192",
            "mixtral-8x7b-32768",
            "gemma-7b-it"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "model_name",
          "display_name": "Model",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the model to use.",
          "title_case": false,
          "type": "str"
        },
        "n": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "n",
          "display_name": "N",
          "advanced": true,
          "dynamic": false,
          "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
          "title_case": false,
          "type": "int"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.1,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "Run inference with this temperature. Must by in the closed interval [0.0, 1.0].",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generate text using Groq.",
      "icon": "Groq",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "Groq",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "groq_api_key",
        "groq_api_base",
        "max_tokens",
        "temperature",
        "n",
        "model_name",
        "input_value",
        "stream",
        "system_message"
      ],
      "beta": false,
      "edited": false
    },
    "VertexAiModel": {
      "template": {
        "_type": "Component",
        "credentials": {
          "trace_as_metadata": true,
          "file_path": "",
          "fileTypes": [
            "json"
          ],
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "credentials",
          "display_name": "Credentials",
          "advanced": true,
          "dynamic": false,
          "info": "Path to the JSON file containing the credentials.",
          "title_case": false,
          "type": "file"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_google_vertexai import ChatVertexAI\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, FileInput, FloatInput, IntInput, MessageInput, MultilineInput, Output, StrInput\n\n\nclass ChatVertexAIComponent(LCModelComponent):\n    display_name = \"Vertex AI\"\n    description = \"Generate text using Vertex AI LLMs.\"\n    icon = \"VertexAI\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        FileInput(\n            name=\"credentials\",\n            display_name=\"Credentials\",\n            info=\"Path to the JSON file containing the credentials.\",\n            file_types=[\"json\"],\n            advanced=True,\n        ),\n        StrInput(name=\"project\", display_name=\"Project\", info=\"The project ID.\"),\n        MultilineInput(\n            name=\"examples\",\n            display_name=\"Examples\",\n            info=\"Examples to pass to the model.\",\n            advanced=True,\n        ),\n        StrInput(name=\"location\", display_name=\"Location\", value=\"us-central1\", advanced=True),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            value=128,\n            advanced=True,\n        ),\n        StrInput(name=\"model_name\", display_name=\"Model Name\", value=\"gemini-1.5-pro\"),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.0),\n        IntInput(name=\"top_k\", display_name=\"Top K\", value=40, advanced=True),\n        FloatInput(name=\"top_p\", display_name=\"Top P\", value=0.95, advanced=True),\n        BoolInput(name=\"verbose\", display_name=\"Verbose\", value=False, advanced=True),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"text_response\"),\n        Output(display_name=\"Language Model\", name=\"model_output\", method=\"build_model\"),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        credentials = self.credentials\n        location = self.location\n        max_output_tokens = self.max_output_tokens\n        model_name = self.model_name\n        project = self.project\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        verbose = self.verbose\n\n        output = ChatVertexAI(\n            credentials=credentials,\n            location=location,\n            max_output_tokens=max_output_tokens,\n            model_name=model_name,\n            project=project,\n            temperature=temperature,\n            top_k=top_k,\n            top_p=top_p,\n            verbose=verbose,\n        )\n\n        return output\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "examples": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "examples",
          "display_name": "Examples",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Examples to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "location": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "us-central1",
          "name": "location",
          "display_name": "Location",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "max_output_tokens": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 128,
          "name": "max_output_tokens",
          "display_name": "Max Output Tokens",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "model_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "gemini-1.5-pro",
          "name": "model_name",
          "display_name": "Model Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "project": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "project",
          "display_name": "Project",
          "advanced": false,
          "dynamic": false,
          "info": "The project ID.",
          "title_case": false,
          "type": "str"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.0,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        },
        "top_k": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 40,
          "name": "top_k",
          "display_name": "Top K",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "top_p": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.95,
          "name": "top_p",
          "display_name": "Top P",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        },
        "verbose": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "verbose",
          "display_name": "Verbose",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "bool"
        }
      },
      "description": "Generate text using Vertex AI LLMs.",
      "icon": "VertexAI",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "Vertex AI",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "credentials",
        "project",
        "examples",
        "location",
        "max_output_tokens",
        "model_name",
        "temperature",
        "top_k",
        "top_p",
        "verbose",
        "stream",
        "system_message"
      ],
      "beta": false,
      "edited": false
    },
    "AnthropicModel": {
      "template": {
        "_type": "Component",
        "anthropic_api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "anthropic_api_key",
          "display_name": "Anthropic API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "Your Anthropic API key.",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "anthropic_api_url": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "anthropic_api_url",
          "display_name": "Anthropic API URL",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_anthropic.chat_models import ChatAnthropic\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic Chat&Completion LLMs with prefill support.\"\n    icon = \"Anthropic\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"claude-3-5-sonnet-20240620\",\n                \"claude-3-opus-20240229\",\n                \"claude-3-sonnet-20240229\",\n                \"claude-3-haiku-20240307\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/anthropic\",\n            value=\"claude-3-5-sonnet-20240620\",\n        ),\n        SecretStrInput(\n            name=\"anthropic_api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        MessageTextInput(\n            name=\"anthropic_api_url\",\n            display_name=\"Anthropic API URL\",\n            advanced=True,\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n        ),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True, value=False),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"prefill\",\n            display_name=\"Prefill\",\n            info=\"Prefill text to guide the model's response.\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"text_response\"),\n        Output(display_name=\"Language Model\", name=\"model_output\", method=\"build_model\"),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        model = self.model\n        anthropic_api_key = self.anthropic_api_key\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        anthropic_api_url = self.anthropic_api_url or \"https://api.anthropic.com\"\n\n        try:\n            output = ChatAnthropic(\n                model=model,\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\n                max_tokens_to_sample=max_tokens,  # type: ignore\n                temperature=temperature,\n                anthropic_api_url=anthropic_api_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Anthropic API.\") from e\n\n        return output\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"\n        Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")  # type: ignore\n            if message:\n                return message\n        return None\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "max_tokens": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4096,
          "name": "max_tokens",
          "display_name": "Max Tokens",
          "advanced": true,
          "dynamic": false,
          "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
          "title_case": false,
          "type": "int"
        },
        "model": {
          "trace_as_metadata": true,
          "options": [
            "claude-3-5-sonnet-20240620",
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "claude-3-5-sonnet-20240620",
          "name": "model",
          "display_name": "Model Name",
          "advanced": false,
          "dynamic": false,
          "info": "https://python.langchain.com/docs/integrations/chat/anthropic",
          "title_case": false,
          "type": "str"
        },
        "prefill": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "prefill",
          "display_name": "Prefill",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Prefill text to guide the model's response.",
          "title_case": false,
          "type": "str"
        },
        "stream": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "stream",
          "display_name": "Stream",
          "advanced": true,
          "dynamic": false,
          "info": "Stream the response from the model. Streaming works only in Chat.",
          "title_case": false,
          "type": "bool"
        },
        "system_message": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "system_message",
          "display_name": "System Message",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "System message to pass to the model.",
          "title_case": false,
          "type": "str"
        },
        "temperature": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0.1,
          "name": "temperature",
          "display_name": "Temperature",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "float"
        }
      },
      "description": "Generate text using Anthropic Chat&Completion LLMs with prefill support.",
      "icon": "Anthropic",
      "base_classes": [
        "LanguageModel",
        "Message"
      ],
      "display_name": "Anthropic",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text_output",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "LanguageModel"
          ],
          "selected": "LanguageModel",
          "name": "model_output",
          "display_name": "Language Model",
          "method": "build_model",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "max_tokens",
        "model",
        "anthropic_api_key",
        "temperature",
        "anthropic_api_url",
        "stream",
        "system_message",
        "prefill"
      ],
      "beta": false,
      "edited": false
    }
  },
  "vectorstores": {
    "Cassandra": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "batch_size": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 16,
          "name": "batch_size",
          "display_name": "Batch Size",
          "advanced": true,
          "dynamic": false,
          "info": "Optional number of data to process in a single batch.",
          "title_case": false,
          "type": "int"
        },
        "body_index_options": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "body_index_options",
          "display_name": "Body Index Options",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Optional options used to create the body index.",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_community.vectorstores import Cassandra\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import (\n    DataInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MessageTextInput,\n    MultilineInput,\n    SecretStrInput,\n)\nfrom langflow.schema import Data\n\n\nclass CassandraVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Cassandra\"\n    description = \"Cassandra Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/cassandra\"\n    icon = \"Cassandra\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Token\",\n            info=\"Authentication token for accessing Cassandra on Astra DB.\",\n            required=True,\n        ),\n        MessageTextInput(name=\"database_id\", display_name=\"Database ID\", info=\"The Astra database ID.\", required=True),\n        MessageTextInput(\n            name=\"table_name\",\n            display_name=\"Table Name\",\n            info=\"The name of the table where vectors will be stored.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional key space within Astra DB. The keyspace should already be created.\",\n            advanced=False,\n        ),\n        IntInput(\n            name=\"ttl_seconds\",\n            display_name=\"TTL Seconds\",\n            info=\"Optional time-to-live for the added texts.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            value=16,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"body_index_options\",\n            display_name=\"Body Index Options\",\n            info=\"Optional options used to create the body index.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the Cassandra table, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            value=\"Sync\",\n            advanced=True,\n        ),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> Cassandra:\n        return self._build_cassandra()\n\n    def _build_cassandra(self) -> Cassandra:\n        try:\n            import cassio\n        except ImportError:\n            raise ImportError(\n                \"Could not import cassio integration package. \" \"Please install it with `pip install cassio`.\"\n            )\n\n        cassio.init(\n            database_id=self.database_id,\n            token=self.token,\n        )\n\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            table = Cassandra.from_documents(\n                documents=documents,\n                embedding=self.embedding,\n                table_name=self.table_name,\n                keyspace=self.keyspace,\n                ttl_seconds=self.ttl_seconds,\n                batch_size=self.batch_size,\n                body_index_options=self.body_index_options,\n            )\n\n        else:\n            table = Cassandra(\n                embedding=self.embedding,\n                table_name=self.table_name,\n                keyspace=self.keyspace,\n                ttl_seconds=self.ttl_seconds,\n                body_index_options=self.body_index_options,\n                setup_mode=self.setup_mode,\n            )\n\n        return table\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_cassandra()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                docs = vector_store.similarity_search(\n                    query=self.search_query,\n                    k=self.number_of_results,\n                )\n            except KeyError as e:\n                if \"content\" in str(e):\n                    raise ValueError(\n                        \"You should ingest data through Langflow (or LangChain) to query it in Langflow. Your collection does not contain a field name 'content'.\"\n                    )\n                else:\n                    raise e\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "database_id": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "database_id",
          "display_name": "Database ID",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The Astra database ID.",
          "title_case": false,
          "type": "str"
        },
        "keyspace": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "keyspace",
          "display_name": "Keyspace",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Optional key space within Astra DB. The keyspace should already be created.",
          "title_case": false,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "setup_mode": {
          "trace_as_metadata": true,
          "options": [
            "Sync",
            "Async",
            "Off"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Sync",
          "name": "setup_mode",
          "display_name": "Setup Mode",
          "advanced": true,
          "dynamic": false,
          "info": "Configuration mode for setting up the Cassandra table, with options like 'Sync', 'Async', or 'Off'.",
          "title_case": false,
          "type": "str"
        },
        "table_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "table_name",
          "display_name": "Table Name",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The name of the table where vectors will be stored.",
          "title_case": false,
          "type": "str"
        },
        "token": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "token",
          "display_name": "Token",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "Authentication token for accessing Cassandra on Astra DB.",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "ttl_seconds": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ttl_seconds",
          "display_name": "TTL Seconds",
          "advanced": true,
          "dynamic": false,
          "info": "Optional time-to-live for the added texts.",
          "title_case": false,
          "type": "int"
        }
      },
      "description": "Cassandra Vector Store with search capabilities",
      "icon": "Cassandra",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Cassandra",
      "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/cassandra",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "token",
        "database_id",
        "table_name",
        "keyspace",
        "ttl_seconds",
        "batch_size",
        "body_index_options",
        "setup_mode",
        "search_query",
        "ingest_data",
        "embedding",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    },
    "SupabaseVectorStore": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_community.vectorstores import SupabaseVectorStore\nfrom supabase.client import Client, create_client\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass SupabaseVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Supabase\"\n    description = \"Supabase Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/vectorstores/supabase/\"\n    icon = \"Supabase\"\n\n    inputs = [\n        StrInput(name=\"supabase_url\", display_name=\"Supabase URL\", required=True),\n        SecretStrInput(name=\"supabase_service_key\", display_name=\"Supabase Service Key\", required=True),\n        StrInput(name=\"table_name\", display_name=\"Table Name\", advanced=True),\n        StrInput(name=\"query_name\", display_name=\"Query Name\"),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> SupabaseVectorStore:\n        return self._build_supabase()\n\n    def _build_supabase(self) -> SupabaseVectorStore:\n        supabase: Client = create_client(self.supabase_url, supabase_key=self.supabase_service_key)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            supabase_vs = SupabaseVectorStore.from_documents(\n                documents=documents,\n                embedding=self.embedding,\n                query_name=self.query_name,\n                client=supabase,\n                table_name=self.table_name,\n            )\n        else:\n            supabase_vs = SupabaseVectorStore(\n                client=supabase,\n                embedding=self.embedding,\n                table_name=self.table_name,\n                query_name=self.query_name,\n            )\n\n        return supabase_vs\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_supabase()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "query_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "query_name",
          "display_name": "Query Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "supabase_service_key": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "supabase_service_key",
          "display_name": "Supabase Service Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "supabase_url": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "supabase_url",
          "display_name": "Supabase URL",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "table_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "table_name",
          "display_name": "Table Name",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Supabase Vector Store with search capabilities",
      "icon": "Supabase",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Supabase",
      "documentation": "https://python.langchain.com/v0.2/docs/integrations/vectorstores/supabase/",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "supabase_url",
        "supabase_service_key",
        "table_name",
        "query_name",
        "search_query",
        "ingest_data",
        "embedding",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    },
    "MongoDBAtlasVector": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass MongoVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"MongoDB Atlas\"\n    description = \"MongoDB Atlas Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/mongodb_atlas\"\n    icon = \"MongoDB\"\n\n    inputs = [\n        SecretStrInput(name=\"mongodb_atlas_cluster_uri\", display_name=\"MongoDB Atlas Cluster URI\", required=True),\n        StrInput(name=\"db_name\", display_name=\"Database Name\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> MongoDBAtlasVectorSearch:\n        return self._build_mongodb_atlas()\n\n    def _build_mongodb_atlas(self) -> MongoDBAtlasVectorSearch:\n        try:\n            from pymongo import MongoClient\n        except ImportError:\n            raise ImportError(\"Please install pymongo to use MongoDB Atlas Vector Store\")\n\n        try:\n            mongo_client: MongoClient = MongoClient(self.mongodb_atlas_cluster_uri)\n            collection = mongo_client[self.db_name][self.collection_name]\n        except Exception as e:\n            raise ValueError(f\"Failed to connect to MongoDB Atlas: {e}\")\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n            if documents:\n                vector_store = MongoDBAtlasVectorSearch.from_documents(\n                    documents=documents, embedding=self.embedding, collection=collection, index_name=self.index_name\n                )\n            else:\n                vector_store = MongoDBAtlasVectorSearch(\n                    embedding=self.embedding,\n                    collection=collection,\n                    index_name=self.index_name,\n                )\n        else:\n            vector_store = MongoDBAtlasVectorSearch(\n                embedding=self.embedding,\n                collection=collection,\n                index_name=self.index_name,\n            )\n\n        return vector_store\n\n    def search_documents(self) -> List[Data]:\n        from bson import ObjectId\n\n        vector_store = self._build_mongodb_atlas()\n\n        if self.search_query and isinstance(self.search_query, str):\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            for doc in docs:\n                doc.metadata = {\n                    key: str(value) if isinstance(value, ObjectId) else value for key, value in doc.metadata.items()\n                }\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "collection_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "collection_name",
          "display_name": "Collection Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "db_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "db_name",
          "display_name": "Database Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "index_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "index_name",
          "display_name": "Index Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "mongodb_atlas_cluster_uri": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "mongodb_atlas_cluster_uri",
          "display_name": "MongoDB Atlas Cluster URI",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "MongoDB Atlas Vector Store with search capabilities",
      "icon": "MongoDB",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "MongoDB Atlas",
      "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/mongodb_atlas",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "mongodb_atlas_cluster_uri",
        "db_name",
        "collection_name",
        "index_name",
        "search_query",
        "ingest_data",
        "embedding",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    },
    "Pinecone": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_pinecone import Pinecone\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    StrInput,\n    SecretStrInput,\n    DataInput,\n    MultilineInput,\n)\nfrom langflow.schema import Data\n\n\nclass PineconeVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Pinecone\"\n    description = \"Pinecone Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/vectorstores/pinecone/\"\n    icon = \"Pinecone\"\n\n    inputs = [\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        StrInput(name=\"namespace\", display_name=\"Namespace\", info=\"Namespace for the index.\"),\n        DropdownInput(\n            name=\"distance_strategy\",\n            display_name=\"Distance Strategy\",\n            options=[\"Cosine\", \"Euclidean\", \"Dot Product\"],\n            value=\"Cosine\",\n            advanced=True,\n        ),\n        SecretStrInput(name=\"pinecone_api_key\", display_name=\"Pinecone API Key\", required=True),\n        StrInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key in the record to use as text.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> Pinecone:\n        return self._build_pinecone()\n\n    def _build_pinecone(self) -> Pinecone:\n        from langchain_pinecone._utilities import DistanceStrategy\n        from langchain_pinecone.vectorstores import Pinecone\n\n        distance_strategy = self.distance_strategy.replace(\" \", \"_\").upper()\n        _distance_strategy = DistanceStrategy[distance_strategy]\n\n        pinecone = Pinecone(\n            index_name=self.index_name,\n            embedding=self.embedding,\n            text_key=self.text_key,\n            namespace=self.namespace,\n            distance_strategy=_distance_strategy,\n            pinecone_api_key=self.pinecone_api_key,\n        )\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            pinecone.add_documents(documents)\n\n        return pinecone\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_pinecone()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "distance_strategy": {
          "trace_as_metadata": true,
          "options": [
            "Cosine",
            "Euclidean",
            "Dot Product"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Cosine",
          "name": "distance_strategy",
          "display_name": "Distance Strategy",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "index_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "index_name",
          "display_name": "Index Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "namespace": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "namespace",
          "display_name": "Namespace",
          "advanced": false,
          "dynamic": false,
          "info": "Namespace for the index.",
          "title_case": false,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "pinecone_api_key": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "pinecone_api_key",
          "display_name": "Pinecone API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "text_key": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "text",
          "name": "text_key",
          "display_name": "Text Key",
          "advanced": true,
          "dynamic": false,
          "info": "Key in the record to use as text.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Pinecone Vector Store with search capabilities",
      "icon": "Pinecone",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Pinecone",
      "documentation": "https://python.langchain.com/v0.2/docs/integrations/vectorstores/pinecone/",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "index_name",
        "namespace",
        "distance_strategy",
        "pinecone_api_key",
        "text_key",
        "search_query",
        "ingest_data",
        "embedding",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    },
    "Qdrant": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "api_key",
          "display_name": "API Key",
          "advanced": true,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_community.vectorstores import Qdrant\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    StrInput,\n    SecretStrInput,\n    DataInput,\n    MultilineInput,\n)\n\nfrom langflow.schema import Data\n\n\nclass QdrantVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Qdrant\"\n    description = \"Qdrant Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/qdrant\"\n    icon = \"Qdrant\"\n\n    inputs = [\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"host\", display_name=\"Host\", value=\"localhost\", advanced=True),\n        IntInput(name=\"port\", display_name=\"Port\", value=6333, advanced=True),\n        IntInput(name=\"grpc_port\", display_name=\"gRPC Port\", value=6334, advanced=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", advanced=True),\n        StrInput(name=\"prefix\", display_name=\"Prefix\", advanced=True),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", advanced=True),\n        StrInput(name=\"path\", display_name=\"Path\", advanced=True),\n        StrInput(name=\"url\", display_name=\"URL\", advanced=True),\n        DropdownInput(\n            name=\"distance_func\",\n            display_name=\"Distance Function\",\n            options=[\"Cosine\", \"Euclidean\", \"Dot Product\"],\n            value=\"Cosine\",\n            advanced=True,\n        ),\n        StrInput(name=\"content_payload_key\", display_name=\"Content Payload Key\", value=\"page_content\", advanced=True),\n        StrInput(name=\"metadata_payload_key\", display_name=\"Metadata Payload Key\", value=\"metadata\", advanced=True),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> Qdrant:\n        return self._build_qdrant()\n\n    def _build_qdrant(self) -> Qdrant:\n        qdrant_kwargs = {\n            \"collection_name\": self.collection_name,\n            \"content_payload_key\": self.content_payload_key,\n            \"distance_func\": self.distance_func,\n            \"metadata_payload_key\": self.metadata_payload_key,\n        }\n\n        server_kwargs = {\n            \"host\": self.host,\n            \"port\": self.port,\n            \"grpc_port\": self.grpc_port,\n            \"api_key\": self.api_key,\n            \"prefix\": self.prefix,\n            \"timeout\": self.timeout,\n            \"path\": self.path,\n            \"url\": self.url,\n        }\n\n        server_kwargs = {k: v for k, v in server_kwargs.items() if v is not None}\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            qdrant = Qdrant.from_documents(documents, embedding=self.embedding, **qdrant_kwargs)\n        else:\n            from qdrant_client import QdrantClient\n\n            client = QdrantClient(**server_kwargs)\n            qdrant = Qdrant(embedding_function=self.embedding.embed_query, client=client, **qdrant_kwargs)\n\n        return qdrant\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_qdrant()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "collection_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "collection_name",
          "display_name": "Collection Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "content_payload_key": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "page_content",
          "name": "content_payload_key",
          "display_name": "Content Payload Key",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "distance_func": {
          "trace_as_metadata": true,
          "options": [
            "Cosine",
            "Euclidean",
            "Dot Product"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Cosine",
          "name": "distance_func",
          "display_name": "Distance Function",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "grpc_port": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 6334,
          "name": "grpc_port",
          "display_name": "gRPC Port",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "host": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "localhost",
          "name": "host",
          "display_name": "Host",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "metadata_payload_key": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "metadata",
          "name": "metadata_payload_key",
          "display_name": "Metadata Payload Key",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "path": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "path",
          "display_name": "Path",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "port": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 6333,
          "name": "port",
          "display_name": "Port",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "prefix": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "prefix",
          "display_name": "Prefix",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "timeout": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "timeout",
          "display_name": "Timeout",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "url": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "url",
          "display_name": "URL",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Qdrant Vector Store with search capabilities",
      "icon": "Qdrant",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Qdrant",
      "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/qdrant",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "collection_name",
        "host",
        "port",
        "grpc_port",
        "api_key",
        "prefix",
        "timeout",
        "path",
        "url",
        "distance_func",
        "content_payload_key",
        "metadata_payload_key",
        "search_query",
        "ingest_data",
        "embedding",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    },
    "AstraDB": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding or Astra Vectorize",
          "advanced": false,
          "input_types": [
            "Embeddings",
            "dict"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "api_endpoint": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "ASTRA_DB_API_ENDPOINT",
          "name": "api_endpoint",
          "display_name": "API Endpoint",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "API endpoint URL for the Astra DB service.",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "batch_size": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "batch_size",
          "display_name": "Batch Size",
          "advanced": true,
          "dynamic": false,
          "info": "Optional number of data to process in a single batch.",
          "title_case": false,
          "type": "int"
        },
        "bulk_delete_concurrency": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "bulk_delete_concurrency",
          "display_name": "Bulk Delete Concurrency",
          "advanced": true,
          "dynamic": false,
          "info": "Optional concurrency level for bulk delete operations.",
          "title_case": false,
          "type": "int"
        },
        "bulk_insert_batch_concurrency": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "bulk_insert_batch_concurrency",
          "display_name": "Bulk Insert Batch Concurrency",
          "advanced": true,
          "dynamic": false,
          "info": "Optional concurrency level for bulk insert operations.",
          "title_case": false,
          "type": "int"
        },
        "bulk_insert_overwrite_concurrency": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "bulk_insert_overwrite_concurrency",
          "display_name": "Bulk Insert Overwrite Concurrency",
          "advanced": true,
          "dynamic": false,
          "info": "Optional concurrency level for bulk insert operations that overwrite existing data.",
          "title_case": false,
          "type": "int"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\n\n\nclass AstraVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Implementation of Vector Store using Astra DB with search capabilities\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/vectorstores/astradb\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n        ),\n        MultilineInput(\n            name=\"search_input\",\n            display_name=\"Search Input\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding or Astra Vectorize\",\n            input_types=[\"Embeddings\", \"dict\"],\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info=\"Optional dictionary defining the indexing policy for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError:\n            raise ImportError(\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid setup mode: {self.setup_mode}\")\n\n        if not isinstance(self.embedding, dict):\n            embedding_dict = {\"embedding\": self.embedding}\n        else:\n            from astrapy.info import CollectionVectorServiceOptions\n\n            dict_options = self.embedding.get(\"collection_vector_service_options\", {})\n            dict_options[\"authentication\"] = {\n                k: v for k, v in dict_options.get(\"authentication\", {}).items() if k and v\n            }\n            dict_options[\"parameters\"] = {k: v for k, v in dict_options.get(\"parameters\", {}).items() if k and v}\n            embedding_dict = {\n                \"collection_vector_service_options\": CollectionVectorServiceOptions.from_dict(dict_options),\n                \"collection_embedding_api_key\": self.embedding.get(\"collection_embedding_api_key\"),\n            }\n        vector_store_kwargs = {\n            **embedding_dict,\n            \"collection_name\": self.collection_name,\n            \"token\": self.token,\n            \"api_endpoint\": self.api_endpoint,\n            \"namespace\": self.namespace or None,\n            \"metric\": self.metric or None,\n            \"batch_size\": self.batch_size or None,\n            \"bulk_insert_batch_concurrency\": self.bulk_insert_batch_concurrency or None,\n            \"bulk_insert_overwrite_concurrency\": self.bulk_insert_overwrite_concurrency or None,\n            \"bulk_delete_concurrency\": self.bulk_delete_concurrency or None,\n            \"setup_mode\": setup_mode_value,\n            \"pre_delete_collection\": self.pre_delete_collection or False,\n        }\n\n        if self.metadata_indexing_include:\n            vector_store_kwargs[\"metadata_indexing_include\"] = self.metadata_indexing_include\n        elif self.metadata_indexing_exclude:\n            vector_store_kwargs[\"metadata_indexing_exclude\"] = self.metadata_indexing_exclude\n        elif self.collection_indexing_policy:\n            vector_store_kwargs[\"collection_indexing_policy\"] = self.collection_indexing_policy\n\n        try:\n            vector_store = AstraDBVectorStore(**vector_store_kwargs)\n        except Exception as e:\n            raise ValueError(f\"Error initializing AstraDBVectorStore: {str(e)}\") from e\n\n        if hasattr(self, \"ingest_data\") and self.ingest_data:\n            logger.debug(\"Ingesting data into the Vector Store.\")\n            self._add_documents_to_vector_store(vector_store)\n\n        self.status = self._astradb_collection_to_data(vector_store.collection)\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store):\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                raise ValueError(f\"Error adding documents to AstraDBVectorStore: {str(e)}\") from e\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        logger.debug(f\"Search input: {self.search_input}\")\n        logger.debug(f\"Search type: {self.search_type}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_input and isinstance(self.search_input, str) and self.search_input.strip():\n            try:\n                if self.search_type == \"Similarity\":\n                    docs = vector_store.similarity_search(\n                        query=self.search_input,\n                        k=self.number_of_results,\n                    )\n                elif self.search_type == \"MMR\":\n                    docs = vector_store.max_marginal_relevance_search(\n                        query=self.search_input,\n                        k=self.number_of_results,\n                    )\n                else:\n                    raise ValueError(f\"Invalid search type: {self.search_type}\")\n            except Exception as e:\n                raise ValueError(f\"Error performing search in AstraDBVectorStore: {str(e)}\") from e\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = [Data.from_document(doc) for doc in docs]\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            self.status = data\n            return data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n\n    def _astradb_collection_to_data(self, collection):\n        data = []\n        data_dict = collection.find()\n        if data_dict and \"data\" in data_dict:\n            data_dict = data_dict[\"data\"].get(\"documents\", [])\n\n        for item in data_dict:\n            data.append(Data(content=item[\"content\"]))\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "collection_indexing_policy": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "collection_indexing_policy",
          "display_name": "Collection Indexing Policy",
          "advanced": true,
          "dynamic": false,
          "info": "Optional dictionary defining the indexing policy for the collection.",
          "title_case": false,
          "type": "str"
        },
        "collection_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "collection_name",
          "display_name": "Collection Name",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the collection within Astra DB where the vectors will be stored.",
          "title_case": false,
          "type": "str"
        },
        "metadata_indexing_exclude": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "metadata_indexing_exclude",
          "display_name": "Metadata Indexing Exclude",
          "advanced": true,
          "dynamic": false,
          "info": "Optional list of metadata fields to exclude from the indexing.",
          "title_case": false,
          "type": "str"
        },
        "metadata_indexing_include": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "metadata_indexing_include",
          "display_name": "Metadata Indexing Include",
          "advanced": true,
          "dynamic": false,
          "info": "Optional list of metadata fields to include in the indexing.",
          "title_case": false,
          "type": "str"
        },
        "metric": {
          "trace_as_metadata": true,
          "options": [
            "cosine",
            "dot_product",
            "euclidean"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "metric",
          "display_name": "Metric",
          "advanced": true,
          "dynamic": false,
          "info": "Optional distance metric for vector comparisons in the vector store.",
          "title_case": false,
          "type": "str"
        },
        "namespace": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "namespace",
          "display_name": "Namespace",
          "advanced": true,
          "dynamic": false,
          "info": "Optional namespace within Astra DB to use for the collection.",
          "title_case": false,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "pre_delete_collection": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "pre_delete_collection",
          "display_name": "Pre Delete Collection",
          "advanced": true,
          "dynamic": false,
          "info": "Boolean flag to determine whether to delete the collection before creating a new one.",
          "title_case": false,
          "type": "bool"
        },
        "search_input": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_input",
          "display_name": "Search Input",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "search_type": {
          "trace_as_metadata": true,
          "options": [
            "Similarity",
            "MMR"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Similarity",
          "name": "search_type",
          "display_name": "Search Type",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "setup_mode": {
          "trace_as_metadata": true,
          "options": [
            "Sync",
            "Async",
            "Off"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Sync",
          "name": "setup_mode",
          "display_name": "Setup Mode",
          "advanced": true,
          "dynamic": false,
          "info": "Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.",
          "title_case": false,
          "type": "str"
        },
        "token": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "ASTRA_DB_APPLICATION_TOKEN",
          "name": "token",
          "display_name": "Astra DB Application Token",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "Authentication token for accessing Astra DB.",
          "title_case": false,
          "password": true,
          "type": "str"
        }
      },
      "description": "Implementation of Vector Store using Astra DB with search capabilities",
      "icon": "AstraDB",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Astra DB",
      "documentation": "https://python.langchain.com/docs/integrations/vectorstores/astradb",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "collection_name",
        "token",
        "api_endpoint",
        "search_input",
        "ingest_data",
        "namespace",
        "metric",
        "batch_size",
        "bulk_insert_batch_concurrency",
        "bulk_insert_overwrite_concurrency",
        "bulk_delete_concurrency",
        "setup_mode",
        "pre_delete_collection",
        "metadata_indexing_include",
        "embedding",
        "metadata_indexing_exclude",
        "collection_indexing_policy",
        "search_type",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    },
    "FAISS": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "allow_dangerous_deserialization": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": true,
          "name": "allow_dangerous_deserialization",
          "display_name": "Allow Dangerous Deserialization",
          "advanced": true,
          "dynamic": false,
          "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
          "title_case": false,
          "type": "bool"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom langflow.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    FAISS Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    def build_vector_store(self) -> FAISS:\n        \"\"\"\n        Builds the FAISS object.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to save the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> List[Data]:\n        \"\"\"\n        Search for documents in the FAISS vector store.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to load the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            raise ValueError(\"Failed to load the FAISS index.\")\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "index_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "langflow_index",
          "name": "index_name",
          "display_name": "Index Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "persist_directory": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "persist_directory",
          "display_name": "Persist Directory",
          "advanced": false,
          "dynamic": false,
          "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
          "title_case": false,
          "type": "str"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "FAISS Vector Store with search capabilities",
      "icon": "FAISS",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "FAISS",
      "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "index_name",
        "persist_directory",
        "search_query",
        "ingest_data",
        "allow_dangerous_deserialization",
        "embedding",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    },
    "pgvector": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingestion Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_community.vectorstores import PGVector\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass PGVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"PGVector\"\n    description = \"PGVector Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/vectorstores/pgvector/\"\n    icon = \"PGVector\"\n\n    inputs = [\n        SecretStrInput(name=\"pg_server_url\", display_name=\"PostgreSQL Server Connection String\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Table\", required=True),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingestion Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n    ]\n\n    def build_vector_store(self) -> PGVector:\n        return self._build_pgvector()\n\n    def _build_pgvector(self) -> PGVector:\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            pgvector = PGVector.from_documents(\n                embedding=self.embedding,\n                documents=documents,\n                collection_name=self.collection_name,\n                connection_string=self.pg_server_url,\n            )\n        else:\n            pgvector = PGVector.from_existing_index(\n                embedding=self.embedding,\n                collection_name=self.collection_name,\n                connection_string=self.pg_server_url,\n            )\n\n        return pgvector\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_pgvector()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "collection_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "collection_name",
          "display_name": "Table",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "pg_server_url": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "pg_server_url",
          "display_name": "PostgreSQL Server Connection String",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "PGVector Vector Store with search capabilities",
      "icon": "PGVector",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "PGVector",
      "documentation": "https://python.langchain.com/v0.2/docs/integrations/vectorstores/pgvector/",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "pg_server_url",
        "collection_name",
        "search_query",
        "ingest_data",
        "embedding",
        "number_of_results",
        "embedding"
      ],
      "beta": false,
      "edited": false
    },
    "Redis": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_community.vectorstores.redis import Redis\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langchain.text_splitter import CharacterTextSplitter\n\n\nclass RedisVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    A custom component for implementing a Vector Store using Redis.\n    \"\"\"\n\n    display_name: str = \"Redis\"\n    description: str = \"Implementation of Vector Store using Redis\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/redis\"\n\n    inputs = [\n        SecretStrInput(name=\"redis_server_url\", display_name=\"Redis Server Connection String\", required=True),\n        StrInput(\n            name=\"redis_index_name\",\n            display_name=\"Redis Index\",\n        ),\n        StrInput(name=\"code\", display_name=\"Code\", advanced=True),\n        StrInput(\n            name=\"schema\",\n            display_name=\"Schema\",\n        ),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n    ]\n\n    def build_vector_store(self) -> Redis:\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        with open(\"docuemnts.txt\", \"w\") as f:\n            f.write(str(documents))\n\n        if not documents:\n            if self.schema is None:\n                raise ValueError(\"If no documents are provided, a schema must be provided.\")\n            redis_vs = Redis.from_existing_index(\n                embedding=self.embedding,\n                index_name=self.redis_index_name,\n                schema=self.schema,\n                key_prefix=None,\n                redis_url=self.redis_server_url,\n            )\n        else:\n            text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n            docs = text_splitter.split_documents(documents)\n            redis_vs = Redis.from_documents(\n                documents=docs,\n                embedding=self.embedding,\n                redis_url=self.redis_server_url,\n                index_name=self.redis_index_name,\n            )\n        return redis_vs\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "redis_index_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "redis_index_name",
          "display_name": "Redis Index",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "redis_server_url": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "redis_server_url",
          "display_name": "Redis Server Connection String",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "schema": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "schema",
          "display_name": "Schema",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Implementation of Vector Store using Redis",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Redis",
      "documentation": "https://python.langchain.com/docs/integrations/vectorstores/redis",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "redis_server_url",
        "redis_index_name",
        "code",
        "schema",
        "search_query",
        "ingest_data",
        "number_of_results",
        "embedding"
      ],
      "beta": false,
      "edited": false
    },
    "Vectara": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Document",
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import TYPE_CHECKING, List\n\nfrom langchain_community.vectorstores import Vectara\nfrom loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import HandleInput, IntInput, MessageTextInput, SecretStrInput, StrInput\nfrom langflow.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_community.vectorstores import Vectara\n\n\nclass VectaraVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Vectara Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Vectara\"\n    description: str = \"Vectara Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/vectara\"\n    icon = \"Vectara\"\n\n    inputs = [\n        StrInput(name=\"vectara_customer_id\", display_name=\"Vectara Customer ID\", required=True),\n        StrInput(name=\"vectara_corpus_id\", display_name=\"Vectara Corpus ID\", required=True),\n        SecretStrInput(name=\"vectara_api_key\", display_name=\"Vectara API Key\", required=True),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding\",\n            input_types=[\"Embeddings\"],\n        ),\n        HandleInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            input_types=[\"Document\", \"Data\"],\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> \"Vectara\":\n        \"\"\"\n        Builds the Vectara object.\n        \"\"\"\n        try:\n            from langchain_community.vectorstores import Vectara\n        except ImportError:\n            raise ImportError(\"Could not import Vectara. Please install it with `pip install langchain-community`.\")\n\n        vectara = Vectara(\n            vectara_customer_id=self.vectara_customer_id,\n            vectara_corpus_id=self.vectara_corpus_id,\n            vectara_api_key=self.vectara_api_key,\n        )\n\n        self._add_documents_to_vector_store(vectara)\n        return vectara\n\n    def _add_documents_to_vector_store(self, vector_store: \"Vectara\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"No documents to add to Vectara\"\n            return\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            logger.debug(f\"Adding {len(documents)} documents to Vectara.\")\n            vector_store.add_documents(documents)\n            self.status = f\"Added {len(documents)} documents to Vectara\"\n        else:\n            logger.debug(\"No documents to add to Vectara.\")\n            self.status = \"No valid documents to add to Vectara\"\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = f\"Found {len(data)} results for the query: {self.search_query}\"\n            return data\n        else:\n            self.status = \"No search query provided\"\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "search_query": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "vectara_api_key": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "vectara_api_key",
          "display_name": "Vectara API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "vectara_corpus_id": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "vectara_corpus_id",
          "display_name": "Vectara Corpus ID",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "vectara_customer_id": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "vectara_customer_id",
          "display_name": "Vectara Customer ID",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Vectara Vector Store with search capabilities",
      "icon": "Vectara",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Vectara",
      "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/vectara",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "vectara_customer_id",
        "vectara_corpus_id",
        "vectara_api_key",
        "embedding",
        "ingest_data",
        "search_query",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    },
    "Weaviate": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "api_key": {
          "load_from_db": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "api_key",
          "display_name": "API Key",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nimport weaviate  # type: ignore\nfrom langchain_community.vectorstores import Weaviate\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import BoolInput, HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass WeaviateVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Weaviate\"\n    description = \"Weaviate Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate\"\n    icon = \"Weaviate\"\n\n    inputs = [\n        StrInput(name=\"url\", display_name=\"Weaviate URL\", value=\"http://localhost:8080\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=False),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        StrInput(name=\"text_key\", display_name=\"Text Key\", value=\"text\", advanced=True),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        BoolInput(name=\"search_by_text\", display_name=\"Search By Text\", advanced=True),\n    ]\n\n    def build_vector_store(self) -> Weaviate:\n        return self._build_weaviate()\n\n    def _build_weaviate(self) -> Weaviate:\n        if self.api_key:\n            auth_config = weaviate.AuthApiKey(api_key=self.api_key)\n            client = weaviate.Client(url=self.url, auth_client_secret=auth_config)\n        else:\n            client = weaviate.Client(url=self.url)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents and self.embedding:\n            return Weaviate.from_documents(\n                client=client,\n                index_name=self.index_name,\n                documents=documents,\n                embedding=self.embedding,\n                by_text=self.search_by_text,\n            )\n\n        return Weaviate(\n            client=client,\n            index_name=self.index_name,\n            text_key=self.text_key,\n            embedding=self.embedding,\n            by_text=self.search_by_text,\n        )\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_weaviate()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "index_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "index_name",
          "display_name": "Index Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "search_by_text": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "search_by_text",
          "display_name": "Search By Text",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "bool"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "text_key": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "text",
          "name": "text_key",
          "display_name": "Text Key",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "url": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "http://localhost:8080",
          "name": "url",
          "display_name": "Weaviate URL",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Weaviate Vector Store with search capabilities",
      "icon": "Weaviate",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Weaviate",
      "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "url",
        "api_key",
        "index_name",
        "text_key",
        "search_query",
        "ingest_data",
        "embedding",
        "number_of_results",
        "search_by_text"
      ],
      "beta": false,
      "edited": false
    },
    "Chroma": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "allow_duplicates": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "allow_duplicates",
          "display_name": "Allow Duplicates",
          "advanced": true,
          "dynamic": false,
          "info": "If false, will not add documents that are already in the Vector Store.",
          "title_case": false,
          "type": "bool"
        },
        "chroma_server_cors_allow_origins": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "chroma_server_cors_allow_origins",
          "display_name": "Server CORS Allow Origins",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "chroma_server_grpc_port": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "chroma_server_grpc_port",
          "display_name": "Server gRPC Port",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "chroma_server_host": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "chroma_server_host",
          "display_name": "Server Host",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "chroma_server_http_port": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "chroma_server_http_port",
          "display_name": "Server HTTP Port",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "int"
        },
        "chroma_server_ssl_enabled": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "chroma_server_ssl_enabled",
          "display_name": "Server SSL Enabled",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "bool"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma.vectorstores import Chroma\nfrom loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.base.vectorstores.utils import chroma_collection_to_data\nfrom langflow.io import BoolInput, DataInput, DropdownInput, HandleInput, IntInput, StrInput, MultilineInput\nfrom langflow.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_chroma import Chroma\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Chroma Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"langflow\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    def build_vector_store(self) -> Chroma:\n        \"\"\"\n        Builds the Chroma object.\n        \"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError:\n            raise ImportError(\n                \"Could not import Chroma integration package. \" \"Please install it with `pip install langchain-chroma`.\"\n            )\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        if self.persist_directory is not None:\n            persist_directory = self.resolve_path(self.persist_directory)\n        else:\n            persist_directory = None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"\"\n            return\n\n        _stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                _stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "collection_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "langflow",
          "name": "collection_name",
          "display_name": "Collection Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "limit": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "limit",
          "display_name": "Limit",
          "advanced": true,
          "dynamic": false,
          "info": "Limit the number of records to compare when Allow Duplicates is False.",
          "title_case": false,
          "type": "int"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 10,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "persist_directory": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "persist_directory",
          "display_name": "Persist Directory",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "search_type": {
          "trace_as_metadata": true,
          "options": [
            "Similarity",
            "MMR"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Similarity",
          "name": "search_type",
          "display_name": "Search Type",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Chroma Vector Store with search capabilities",
      "icon": "Chroma",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Chroma DB",
      "documentation": "https://python.langchain.com/docs/integrations/vectorstores/chroma",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "collection_name",
        "persist_directory",
        "search_query",
        "ingest_data",
        "embedding",
        "chroma_server_cors_allow_origins",
        "chroma_server_host",
        "chroma_server_http_port",
        "chroma_server_grpc_port",
        "chroma_server_ssl_enabled",
        "allow_duplicates",
        "search_type",
        "number_of_results",
        "limit"
      ],
      "beta": false,
      "edited": false
    },
    "Upstash": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "To use Upstash's embeddings, don't provide an embedding.",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_community.vectorstores import UpstashVectorStore\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass UpstashVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Upstash\"\n    description = \"Upstash Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/vectorstores/upstash/\"\n    icon = \"Upstash\"\n\n    inputs = [\n        StrInput(name=\"index_url\", display_name=\"Index URL\", info=\"The URL of the Upstash index.\", required=True),\n        SecretStrInput(\n            name=\"index_token\", display_name=\"Index Token\", info=\"The token for the Upstash index.\", required=True\n        ),\n        StrInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key in the record to use as text.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding\",\n            input_types=[\"Embeddings\"],\n            info=\"To use Upstash's embeddings, don't provide an embedding.\",\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> UpstashVectorStore:\n        return self._build_upstash()\n\n    def _build_upstash(self) -> UpstashVectorStore:\n        use_upstash_embedding = self.embedding is None\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            if use_upstash_embedding:\n                upstash_vs = UpstashVectorStore(\n                    embedding=use_upstash_embedding,\n                    text_key=self.text_key,\n                    index_url=self.index_url,\n                    index_token=self.index_token,\n                )\n                upstash_vs.add_documents(documents)\n            else:\n                upstash_vs = UpstashVectorStore.from_documents(\n                    documents=documents,\n                    embedding=self.embedding,\n                    text_key=self.text_key,\n                    index_url=self.index_url,\n                    index_token=self.index_token,\n                )\n        else:\n            upstash_vs = UpstashVectorStore(\n                embedding=self.embedding or use_upstash_embedding,\n                text_key=self.text_key,\n                index_url=self.index_url,\n                index_token=self.index_token,\n            )\n\n        return upstash_vs\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_upstash()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "index_token": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "index_token",
          "display_name": "Index Token",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "The token for the Upstash index.",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "index_url": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "index_url",
          "display_name": "Index URL",
          "advanced": false,
          "dynamic": false,
          "info": "The URL of the Upstash index.",
          "title_case": false,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "text_key": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "text",
          "name": "text_key",
          "display_name": "Text Key",
          "advanced": true,
          "dynamic": false,
          "info": "The key in the record to use as text.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Upstash Vector Store with search capabilities",
      "icon": "Upstash",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Upstash",
      "documentation": "https://python.langchain.com/v0.2/docs/integrations/vectorstores/upstash/",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "index_url",
        "index_token",
        "text_key",
        "search_query",
        "ingest_data",
        "embedding",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    },
    "Couchbase": {
      "template": {
        "_type": "Component",
        "embedding": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "embedding",
          "display_name": "Embedding",
          "advanced": false,
          "input_types": [
            "Embeddings"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "ingest_data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "ingest_data",
          "display_name": "Ingest Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "other"
        },
        "bucket_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "bucket_name",
          "display_name": "Bucket Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from datetime import timedelta\nfrom typing import List\n\nfrom langchain_community.vectorstores import CouchbaseVectorStore\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass CouchbaseVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Couchbase\"\n    description = \"Couchbase Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/v0.1/docs/integrations/document_loaders/couchbase/\"\n    icon = \"Couchbase\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"couchbase_connection_string\", display_name=\"Couchbase Cluster connection string\", required=True\n        ),\n        StrInput(name=\"couchbase_username\", display_name=\"Couchbase username\", required=True),\n        SecretStrInput(name=\"couchbase_password\", display_name=\"Couchbase password\", required=True),\n        StrInput(name=\"bucket_name\", display_name=\"Bucket Name\", required=True),\n        StrInput(name=\"scope_name\", display_name=\"Scope Name\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> CouchbaseVectorStore:\n        return self._build_couchbase()\n\n    def _build_couchbase(self) -> CouchbaseVectorStore:\n        try:\n            from couchbase.auth import PasswordAuthenticator  # type: ignore\n            from couchbase.cluster import Cluster  # type: ignore\n            from couchbase.options import ClusterOptions  # type: ignore\n        except ImportError as e:\n            raise ImportError(\n                \"Failed to import Couchbase dependencies. Install it using `pip install langflow[couchbase] --pre`\"\n            ) from e\n\n        try:\n            auth = PasswordAuthenticator(self.couchbase_username, self.couchbase_password)\n            options = ClusterOptions(auth)\n            cluster = Cluster(self.couchbase_connection_string, options)\n\n            cluster.wait_until_ready(timedelta(seconds=5))\n        except Exception as e:\n            raise ValueError(f\"Failed to connect to Couchbase: {e}\")\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            couchbase_vs = CouchbaseVectorStore.from_documents(\n                documents=documents,\n                cluster=cluster,\n                bucket_name=self.bucket_name,\n                scope_name=self.scope_name,\n                collection_name=self.collection_name,\n                embedding=self.embedding,\n                index_name=self.index_name,\n            )\n\n        else:\n            couchbase_vs = CouchbaseVectorStore(\n                cluster=cluster,\n                bucket_name=self.bucket_name,\n                scope_name=self.scope_name,\n                collection_name=self.collection_name,\n                embedding=self.embedding,\n                index_name=self.index_name,\n            )\n\n        return couchbase_vs\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_couchbase()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "collection_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "collection_name",
          "display_name": "Collection Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "couchbase_connection_string": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "couchbase_connection_string",
          "display_name": "Couchbase Cluster connection string",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "couchbase_password": {
          "load_from_db": true,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "couchbase_password",
          "display_name": "Couchbase password",
          "advanced": false,
          "input_types": [],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "password": true,
          "type": "str"
        },
        "couchbase_username": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "couchbase_username",
          "display_name": "Couchbase username",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "index_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "index_name",
          "display_name": "Index Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "number_of_results": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 4,
          "name": "number_of_results",
          "display_name": "Number of Results",
          "advanced": true,
          "dynamic": false,
          "info": "Number of results to return.",
          "title_case": false,
          "type": "int"
        },
        "scope_name": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": true,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "scope_name",
          "display_name": "Scope Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "search_query": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "search_query",
          "display_name": "Search Query",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Couchbase Vector Store with search capabilities",
      "icon": "Couchbase",
      "base_classes": [
        "Data",
        "Retriever"
      ],
      "display_name": "Couchbase",
      "documentation": "https://python.langchain.com/v0.1/docs/integrations/document_loaders/couchbase/",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Retriever"
          ],
          "selected": "Retriever",
          "name": "base_retriever",
          "display_name": "Retriever",
          "method": "build_base_retriever",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "search_results",
          "display_name": "Search Results",
          "method": "search_documents",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "couchbase_connection_string",
        "couchbase_username",
        "couchbase_password",
        "bucket_name",
        "scope_name",
        "collection_name",
        "index_name",
        "search_query",
        "ingest_data",
        "embedding",
        "number_of_results"
      ],
      "beta": false,
      "edited": false
    }
  },
  "prototypes": {
    "PythonFunction": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Callable\n\nfrom langflow.custom import CustomComponent\nfrom langflow.custom.utils import get_function\nfrom langflow.field_typing import Code\n\n\nclass PythonFunctionComponent(CustomComponent):\n    display_name = \"Python Function\"\n    description = \"Define a Python function.\"\n    icon = \"Python\"\n    beta = True\n\n    def build_config(self):\n        return {\n            \"function_code\": {\n                \"display_name\": \"Code\",\n                \"info\": \"The code for the function.\",\n                \"show\": True,\n            },\n        }\n\n    def build(self, function_code: Code) -> Callable:\n        self.status = function_code\n        func = get_function(function_code)\n        return func\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "function_code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "function_code",
          "display_name": "Code",
          "advanced": false,
          "dynamic": false,
          "info": "The code for the function.",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Define a Python function.",
      "icon": "Python",
      "base_classes": [
        "Callable"
      ],
      "display_name": "Python Function",
      "documentation": "",
      "custom_fields": {
        "function_code": null
      },
      "output_types": [
        "Callable"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Callable"
          ],
          "selected": "Callable",
          "name": "callable",
          "hidden": null,
          "display_name": "Callable",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    },
    "SQLExecutor": {
      "template": {
        "_type": "CustomComponent",
        "add_error": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "add_error",
          "display_name": "Add Error",
          "advanced": false,
          "dynamic": false,
          "info": "Add the error to the result.",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\nfrom langchain_community.utilities import SQLDatabase\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\n\n\nclass SQLExecutorComponent(CustomComponent):\n    display_name = \"SQL Executor\"\n    description = \"Execute SQL query.\"\n    beta: bool = True\n\n    def build_config(self):\n        return {\n            \"database_url\": {\n                \"display_name\": \"Database URL\",\n                \"info\": \"The URL of the database.\",\n            },\n            \"include_columns\": {\n                \"display_name\": \"Include Columns\",\n                \"info\": \"Include columns in the result.\",\n            },\n            \"passthrough\": {\n                \"display_name\": \"Passthrough\",\n                \"info\": \"If an error occurs, return the query instead of raising an exception.\",\n            },\n            \"add_error\": {\n                \"display_name\": \"Add Error\",\n                \"info\": \"Add the error to the result.\",\n            },\n        }\n\n    def clean_up_uri(self, uri: str) -> str:\n        if uri.startswith(\"postgresql://\"):\n            uri = uri.replace(\"postgresql://\", \"postgres://\")\n        return uri.strip()\n\n    def build(\n        self,\n        query: str,\n        database_url: str,\n        include_columns: bool = False,\n        passthrough: bool = False,\n        add_error: bool = False,\n    ) -> Text:\n        error = None\n        try:\n            database = SQLDatabase.from_uri(database_url)\n        except Exception as e:\n            raise ValueError(f\"An error occurred while connecting to the database: {e}\")\n        try:\n            tool = QuerySQLDataBaseTool(db=database)\n            result = tool.run(query, include_columns=include_columns)\n            self.status = result\n        except Exception as e:\n            result = str(e)\n            self.status = result\n            if not passthrough:\n                raise e\n            error = repr(e)\n\n        if add_error and error is not None:\n            result = f\"{result}\\n\\nError: {error}\\n\\nQuery: {query}\"\n        elif error is not None:\n            # Then we won't add the error to the result\n            # but since we are in passthrough mode, we will return the query\n            result = query\n\n        return result\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "database_url": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "database_url",
          "display_name": "Database URL",
          "advanced": false,
          "dynamic": false,
          "info": "The URL of the database.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "include_columns": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "include_columns",
          "display_name": "Include Columns",
          "advanced": false,
          "dynamic": false,
          "info": "Include columns in the result.",
          "load_from_db": false,
          "title_case": false
        },
        "passthrough": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "passthrough",
          "display_name": "Passthrough",
          "advanced": false,
          "dynamic": false,
          "info": "If an error occurs, return the query instead of raising an exception.",
          "load_from_db": false,
          "title_case": false
        },
        "query": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "query",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Execute SQL query.",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "SQL Executor",
      "documentation": "",
      "custom_fields": {
        "query": null,
        "database_url": null,
        "include_columns": null,
        "passthrough": null,
        "add_error": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    },
    "FlowTool": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Any, List, Optional\n\nfrom loguru import logger\n\nfrom langflow.base.tools.flow_tool import FlowTool\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Tool\nfrom langflow.graph.graph.base import Graph\nfrom langflow.helpers.flow import get_flow_inputs\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass FlowToolComponent(CustomComponent):\n    display_name = \"Flow as Tool\"\n    description = \"Construct a Tool from a function that runs the loaded Flow.\"\n    field_order = [\"flow_name\", \"name\", \"description\", \"return_direct\"]\n    trace_type = \"tool\"\n    beta = True\n\n    def get_flow_names(self) -> List[str]:\n        flow_datas = self.list_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_datas]\n\n    def get_flow(self, flow_name: str) -> Optional[Data]:\n        \"\"\"\n        Retrieves a flow by its name.\n\n        Args:\n            flow_name (str): The name of the flow to retrieve.\n\n        Returns:\n            Optional[Text]: The flow record if found, None otherwise.\n        \"\"\"\n        flow_datas = self.list_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        logger.debug(f\"Updating build config with field value {field_value} and field name {field_name}\")\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = self.get_flow_names()\n\n        return build_config\n\n    def build_config(self):\n        return {\n            \"flow_name\": {\n                \"display_name\": \"Flow Name\",\n                \"info\": \"The name of the flow to run.\",\n                \"options\": [],\n                \"real_time_refresh\": True,\n                \"refresh_button\": True,\n            },\n            \"name\": {\n                \"display_name\": \"Name\",\n                \"description\": \"The name of the tool.\",\n            },\n            \"description\": {\n                \"display_name\": \"Description\",\n                \"description\": \"The description of the tool.\",\n            },\n            \"return_direct\": {\n                \"display_name\": \"Return Direct\",\n                \"description\": \"Return the result directly from the Tool.\",\n                \"advanced\": True,\n            },\n        }\n\n    async def build(self, flow_name: str, name: str, description: str, return_direct: bool = False) -> Tool:\n        FlowTool.update_forward_refs()\n        flow_data = self.get_flow(flow_name)\n        if not flow_data:\n            raise ValueError(\"Flow not found.\")\n        graph = Graph.from_payload(flow_data.data[\"data\"])\n        inputs = get_flow_inputs(graph)\n        tool = FlowTool(\n            name=name,\n            description=description,\n            graph=graph,\n            return_direct=return_direct,\n            inputs=inputs,\n            flow_id=str(flow_data.id),\n            user_id=str(self._user_id),\n        )\n        description_repr = repr(tool.description).strip(\"'\")\n        args_str = \"\\n\".join([f\"- {arg_name}: {arg_data['description']}\" for arg_name, arg_data in tool.args.items()])\n        self.status = f\"{description_repr}\\nArguments:\\n{args_str}\"\n        return tool  # type: ignore\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "description": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "description",
          "display_name": "Description",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "flow_name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [],
          "name": "flow_name",
          "display_name": "Flow Name",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the flow to run.",
          "real_time_refresh": true,
          "refresh_button": true,
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "name",
          "display_name": "Name",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "return_direct": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "return_direct",
          "display_name": "Return Direct",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Construct a Tool from a function that runs the loaded Flow.",
      "base_classes": [
        "BaseTool",
        "Generic",
        "object",
        "Runnable",
        "RunnableSerializable",
        "Serializable",
        "Tool"
      ],
      "display_name": "Flow as Tool",
      "documentation": "",
      "custom_fields": {
        "flow_name": null,
        "name": null,
        "description": null,
        "return_direct": null
      },
      "output_types": [
        "Tool"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Tool"
          ],
          "selected": "Tool",
          "name": "tool",
          "hidden": null,
          "display_name": "Tool",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "flow_name",
        "name",
        "description",
        "return_direct"
      ],
      "beta": true,
      "edited": false
    },
    "RunFlow": {
      "template": {
        "_type": "CustomComponent",
        "input_value": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input Value",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Any, List, Optional\n\nfrom langflow.base.flow_processing.utils import build_data_from_run_outputs\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import NestedDict, Text\nfrom langflow.graph.schema import RunOutputs\nfrom langflow.schema import Data, dotdict\n\n\nclass RunFlowComponent(CustomComponent):\n    display_name = \"Run Flow\"\n    description = \"A component to run a flow.\"\n    beta: bool = True\n\n    def get_flow_names(self) -> List[str]:\n        flow_data = self.list_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_data]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = self.get_flow_names()\n\n        return build_config\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"multiline\": True,\n            },\n            \"flow_name\": {\n                \"display_name\": \"Flow Name\",\n                \"info\": \"The name of the flow to run.\",\n                \"options\": [],\n                \"refresh_button\": True,\n            },\n            \"tweaks\": {\n                \"display_name\": \"Tweaks\",\n                \"info\": \"Tweaks to apply to the flow.\",\n            },\n        }\n\n    async def build(self, input_value: Text, flow_name: str, tweaks: NestedDict) -> List[Data]:\n        results: List[Optional[RunOutputs]] = await self.run_flow(\n            inputs={\"input_value\": input_value}, flow_name=flow_name, tweaks=tweaks\n        )\n        if isinstance(results, list):\n            data = []\n            for result in results:\n                if result:\n                    data.extend(build_data_from_run_outputs(result))\n        else:\n            data = build_data_from_run_outputs()(results)\n\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "flow_name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [],
          "name": "flow_name",
          "display_name": "Flow Name",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the flow to run.",
          "refresh_button": true,
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "tweaks": {
          "type": "NestedDict",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "tweaks",
          "display_name": "Tweaks",
          "advanced": false,
          "dynamic": false,
          "info": "Tweaks to apply to the flow.",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "A component to run a flow.",
      "base_classes": [
        "Data"
      ],
      "display_name": "Run Flow",
      "documentation": "",
      "custom_fields": {
        "input_value": null,
        "flow_name": null,
        "tweaks": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    },
    "SubFlow": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Any, List, Optional\n\nfrom langflow.base.flow_processing.utils import build_data_from_result_data\nfrom langflow.custom import CustomComponent\nfrom langflow.graph.graph.base import Graph\nfrom langflow.graph.schema import RunOutputs\nfrom langflow.graph.vertex.base import Vertex\nfrom langflow.helpers.flow import get_flow_inputs\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.template.field.base import Input\nfrom loguru import logger\n\n\nclass SubFlowComponent(CustomComponent):\n    display_name = \"Sub Flow\"\n    description = (\n        \"Dynamically Generates a Component from a Flow. The output is a list of data with keys 'result' and 'message'.\"\n    )\n    beta: bool = True\n    field_order = [\"flow_name\"]\n\n    def get_flow_names(self) -> List[str]:\n        flow_datas = self.list_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_datas]\n\n    def get_flow(self, flow_name: str) -> Optional[Data]:\n        flow_datas = self.list_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        logger.debug(f\"Updating build config with field value {field_value} and field name {field_name}\")\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = self.get_flow_names()\n        # Clean up the build config\n        for key in list(build_config.keys()):\n            if key not in self.field_order + [\"code\", \"_type\", \"get_final_results_only\"]:\n                del build_config[key]\n        if field_value is not None and field_name == \"flow_name\":\n            try:\n                flow_data = self.get_flow(field_value)\n                if not flow_data:\n                    raise ValueError(f\"Flow {field_value} not found.\")\n                graph = Graph.from_payload(flow_data.data[\"data\"])\n                # Get all inputs from the graph\n                inputs = get_flow_inputs(graph)\n                # Add inputs to the build config\n                build_config = self.add_inputs_to_build_config(inputs, build_config)\n            except Exception as e:\n                logger.error(f\"Error getting flow {field_value}: {str(e)}\")\n\n        return build_config\n\n    def add_inputs_to_build_config(self, inputs: List[Vertex], build_config: dotdict):\n        new_fields: list[Input] = []\n        for vertex in inputs:\n            field = Input(\n                display_name=vertex.display_name,\n                name=vertex.id,\n                info=vertex.description,\n                field_type=\"str\",\n                value=None,\n            )\n            new_fields.append(field)\n        logger.debug(new_fields)\n        for field in new_fields:\n            build_config[field.name] = field.to_dict()\n        return build_config\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"multiline\": True,\n            },\n            \"flow_name\": {\n                \"display_name\": \"Flow Name\",\n                \"info\": \"The name of the flow to run.\",\n                \"options\": [],\n                \"real_time_refresh\": True,\n                \"refresh_button\": True,\n            },\n            \"tweaks\": {\n                \"display_name\": \"Tweaks\",\n                \"info\": \"Tweaks to apply to the flow.\",\n            },\n            \"get_final_results_only\": {\n                \"display_name\": \"Get Final Results Only\",\n                \"info\": \"If False, the output will contain all outputs from the flow.\",\n                \"advanced\": True,\n            },\n        }\n\n    async def build(self, flow_name: str, get_final_results_only: bool = True, **kwargs) -> List[Data]:\n        tweaks = {key: {\"input_value\": value} for key, value in kwargs.items()}\n        run_outputs: List[Optional[RunOutputs]] = await self.run_flow(\n            tweaks=tweaks,\n            flow_name=flow_name,\n        )\n        if not run_outputs:\n            return []\n        run_output = run_outputs[0]\n\n        data = []\n        if run_output is not None:\n            for output in run_output.outputs:\n                if output:\n                    data.extend(build_data_from_result_data(output, get_final_results_only))\n\n        self.status = data\n        logger.debug(data)\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "flow_name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [],
          "name": "flow_name",
          "display_name": "Flow Name",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the flow to run.",
          "real_time_refresh": true,
          "refresh_button": true,
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "get_final_results_only": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": true,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "get_final_results_only",
          "display_name": "Get Final Results Only",
          "advanced": true,
          "dynamic": false,
          "info": "If False, the output will contain all outputs from the flow.",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Dynamically Generates a Component from a Flow. The output is a list of data with keys 'result' and 'message'.",
      "base_classes": [
        "Data"
      ],
      "display_name": "Sub Flow",
      "documentation": "",
      "custom_fields": {
        "flow_name": null,
        "get_final_results_only": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "flow_name"
      ],
      "beta": true,
      "edited": false
    },
    "Pass": {
      "template": {
        "_type": "CustomComponent",
        "forwarded_input": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "forwarded_input",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Text",
            "Data"
          ],
          "dynamic": false,
          "info": "This input is forwarded by the component.",
          "load_from_db": false,
          "title_case": false
        },
        "ignored_input": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "ignored_input",
          "display_name": "Ignored Input",
          "advanced": false,
          "input_types": [
            "Text",
            "Data"
          ],
          "dynamic": false,
          "info": "This input is ignored. It's used to control the flow in the graph.",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Union\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Data\n\n\nclass PassComponent(CustomComponent):\n    display_name = \"Pass\"\n    description = \"A pass-through component that forwards the second input while ignoring the first, used for controlling workflow direction.\"\n    field_order = [\"ignored_input\", \"forwarded_input\"]\n    beta = True\n\n    def build_config(self) -> dict:\n        return {\n            \"ignored_input\": {\n                \"display_name\": \"Ignored Input\",\n                \"info\": \"This input is ignored. It's used to control the flow in the graph.\",\n                \"input_types\": [\"Text\", \"Data\"],\n            },\n            \"forwarded_input\": {\n                \"display_name\": \"Input\",\n                \"info\": \"This input is forwarded by the component.\",\n                \"input_types\": [\"Text\", \"Data\"],\n            },\n        }\n\n    def build(self, ignored_input: Text, forwarded_input: Text) -> Union[Text, Data]:\n        # The ignored_input is not used in the logic, it's just there for graph flow control\n        self.status = forwarded_input\n        return forwarded_input\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "A pass-through component that forwards the second input while ignoring the first, used for controlling workflow direction.",
      "base_classes": [
        "Data",
        "object",
        "str",
        "Text"
      ],
      "display_name": "Pass",
      "documentation": "",
      "custom_fields": {
        "ignored_input": null,
        "forwarded_input": null
      },
      "output_types": [
        "Text",
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "ignored_input",
        "forwarded_input"
      ],
      "beta": true,
      "edited": false
    },
    "RunnableExecutor": {
      "template": {
        "_type": "CustomComponent",
        "input_value": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Inputs",
          "advanced": false,
          "dynamic": false,
          "info": "The inputs to pass to the runnable.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "runnable": {
          "type": "Runnable",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "runnable",
          "display_name": "Runnable",
          "advanced": false,
          "input_types": [
            "Chain",
            "AgentExecutor",
            "Agent",
            "Runnable"
          ],
          "dynamic": false,
          "info": "The runnable to execute.",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_core.runnables import Runnable\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\n\n\nclass RunnableExecComponent(CustomComponent):\n    description = \"Execute a runnable. It will try to guess the input and output keys.\"\n    display_name = \"Runnable Executor\"\n    beta: bool = True\n    field_order = [\n        \"input_key\",\n        \"output_key\",\n        \"input_value\",\n        \"runnable\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_key\": {\n                \"display_name\": \"Input Key\",\n                \"info\": \"The key to use for the input.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"The inputs to pass to the runnable.\",\n            },\n            \"runnable\": {\n                \"display_name\": \"Runnable\",\n                \"info\": \"The runnable to execute.\",\n                \"input_types\": [\"Chain\", \"AgentExecutor\", \"Agent\", \"Runnable\"],\n            },\n            \"output_key\": {\n                \"display_name\": \"Output Key\",\n                \"info\": \"The key to use for the output.\",\n                \"advanced\": True,\n            },\n        }\n\n    def get_output(self, result, input_key, output_key):\n        \"\"\"\n        Retrieves the output value from the given result dictionary based on the specified input and output keys.\n\n        Args:\n            result (dict): The result dictionary containing the output value.\n            input_key (str): The key used to retrieve the input value from the result dictionary.\n            output_key (str): The key used to retrieve the output value from the result dictionary.\n\n        Returns:\n            tuple: A tuple containing the output value and the status message.\n\n        \"\"\"\n        possible_output_keys = [\"answer\", \"response\", \"output\", \"result\", \"text\"]\n        status = \"\"\n        result_value = None\n\n        if output_key in result:\n            result_value = result.get(output_key)\n        elif len(result) == 2 and input_key in result:\n            # get the other key from the result dict\n            other_key = [k for k in result if k != input_key][0]\n            if other_key == output_key:\n                result_value = result.get(output_key)\n            else:\n                status += f\"Warning: The output key is not '{output_key}'. The output key is '{other_key}'.\"\n                result_value = result.get(other_key)\n        elif len(result) == 1:\n            result_value = list(result.values())[0]\n        elif any(k in result for k in possible_output_keys):\n            for key in possible_output_keys:\n                if key in result:\n                    result_value = result.get(key)\n                    status += f\"Output key: '{key}'.\"\n                    break\n            if result_value is None:\n                result_value = result\n                status += f\"Warning: The output key is not '{output_key}'.\"\n        else:\n            result_value = result\n            status += f\"Warning: The output key is not '{output_key}'.\"\n\n        return result_value, status\n\n    def get_input_dict(self, runnable, input_key, input_value):\n        \"\"\"\n        Returns a dictionary containing the input key-value pair for the given runnable.\n\n        Args:\n            runnable: The runnable object.\n            input_key: The key for the input value.\n            input_value: The value for the input key.\n\n        Returns:\n            input_dict: A dictionary containing the input key-value pair.\n            status: A status message indicating if the input key is not in the runnable's input keys.\n        \"\"\"\n        input_dict = {}\n        status = \"\"\n        if hasattr(runnable, \"input_keys\"):\n            # Check if input_key is in the runnable's input_keys\n            if input_key in runnable.input_keys:\n                input_dict[input_key] = input_value\n            else:\n                input_dict = {k: input_value for k in runnable.input_keys}\n                status = f\"Warning: The input key is not '{input_key}'. The input key is '{runnable.input_keys}'.\"\n        return input_dict, status\n\n    def build(\n        self,\n        input_value: Text,\n        runnable: Runnable,\n        input_key: str = \"input\",\n        output_key: str = \"output\",\n    ) -> Text:\n        input_dict, status = self.get_input_dict(runnable, input_key, input_value)\n        result = runnable.invoke(input_dict)\n        result_value, _status = self.get_output(result, input_key, output_key)\n        status += _status\n        status += f\"\\n\\nOutput: {result_value}\\n\\nRaw Output: {result}\"\n        self.status = status\n        return result_value\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_key": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "input",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_key",
          "display_name": "Input Key",
          "advanced": true,
          "dynamic": false,
          "info": "The key to use for the input.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "output_key": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "output",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "output_key",
          "display_name": "Output Key",
          "advanced": true,
          "dynamic": false,
          "info": "The key to use for the output.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Execute a runnable. It will try to guess the input and output keys.",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "Runnable Executor",
      "documentation": "",
      "custom_fields": {
        "input_value": null,
        "runnable": null,
        "input_key": null,
        "output_key": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_key",
        "output_key",
        "input_value",
        "runnable"
      ],
      "beta": true,
      "edited": false
    },
    "Notify": {
      "template": {
        "_type": "CustomComponent",
        "data": {
          "type": "Data",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "data",
          "display_name": "Data",
          "advanced": false,
          "dynamic": false,
          "info": "The data to store.",
          "load_from_db": false,
          "title_case": false
        },
        "append": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "append",
          "display_name": "Append",
          "advanced": false,
          "dynamic": false,
          "info": "If True, the record will be appended to the notification.",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Data\n\n\nclass NotifyComponent(CustomComponent):\n    display_name = \"Notify\"\n    description = \"A component to generate a notification to Get Notified component.\"\n    icon = \"Notify\"\n    beta: bool = True\n\n    def build_config(self):\n        return {\n            \"name\": {\"display_name\": \"Name\", \"info\": \"The name of the notification.\"},\n            \"data\": {\"display_name\": \"Data\", \"info\": \"The data to store.\"},\n            \"append\": {\n                \"display_name\": \"Append\",\n                \"info\": \"If True, the record will be appended to the notification.\",\n            },\n        }\n\n    def build(self, name: str, data: Optional[Data] = None, append: bool = False) -> Data:\n        if data and not isinstance(data, Data):\n            if isinstance(data, str):\n                data = Data(text=data)\n            elif isinstance(data, dict):\n                data = Data(data=data)\n            else:\n                data = Data(text=str(data))\n        elif not data:\n            data = Data(text=\"\")\n        if data:\n            if append:\n                self.append_state(name, data)\n            else:\n                self.update_state(name, data)\n        else:\n            self.status = \"No record provided.\"\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "name",
          "display_name": "Name",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the notification.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "A component to generate a notification to Get Notified component.",
      "icon": "Notify",
      "base_classes": [
        "Data"
      ],
      "display_name": "Notify",
      "documentation": "",
      "custom_fields": {
        "name": null,
        "data": null,
        "append": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    },
    "UpdateData": {
      "template": {
        "_type": "CustomComponent",
        "data": {
          "type": "Data",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "data",
          "display_name": "Data",
          "advanced": false,
          "dynamic": false,
          "info": "The record to update.",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.custom import CustomComponent\nfrom langflow.schema import Data\n\n\nclass UpdateDataComponent(CustomComponent):\n    display_name = \"Update Data\"\n    description = \"Update Data with text-based key/value pairs, similar to updating a Python dictionary.\"\n\n    def build_config(self):\n        return {\n            \"data\": {\n                \"display_name\": \"Data\",\n                \"info\": \"The record to update.\",\n            },\n            \"new_data\": {\n                \"display_name\": \"New Data\",\n                \"info\": \"The new data to update the record with.\",\n                \"input_types\": [\"Text\"],\n            },\n        }\n\n    def build(\n        self,\n        data: Data,\n        new_data: dict,\n    ) -> Data:\n        \"\"\"\n        Updates a record with new data.\n\n        Args:\n            record (Data): The record to update.\n            new_data (dict): The new data to update the record with.\n\n        Returns:\n            Data: The updated record.\n        \"\"\"\n        data.data.update(new_data)\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "new_data": {
          "type": "dict",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "new_data",
          "display_name": "New Data",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "The new data to update the record with.",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Update Data with text-based key/value pairs, similar to updating a Python dictionary.",
      "base_classes": [
        "Data"
      ],
      "display_name": "Update Data",
      "documentation": "",
      "custom_fields": {
        "data": null,
        "new_data": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "CreateData": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Any\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.template.field.base import Input\n\n\nclass CreateDataComponent(CustomComponent):\n    display_name = \"Create Data\"\n    description = \"Dynamically create a Data with a specified number of fields.\"\n    field_order = [\"number_of_fields\", \"text_key\"]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"number_of_fields\":\n            default_keys = [\"code\", \"_type\", \"number_of_fields\", \"text_key\"]\n            try:\n                field_value_int = int(field_value)\n            except TypeError:\n                return build_config\n            existing_fields = {}\n            if field_value_int > 15:\n                build_config[\"number_of_fields\"][\"value\"] = 15\n                raise ValueError(\"Number of fields cannot exceed 15. Try using a Component to combine two Data.\")\n            if len(build_config) > len(default_keys) + field_value_int:\n                # back up the existing template fields\n                for key in build_config.copy():\n                    if key not in default_keys:\n                        existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = Input(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        field_type=\"dict\",\n                        input_types=[\"Text\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    def build_config(self):\n        return {\n            \"number_of_fields\": {\n                \"display_name\": \"Number of Fields\",\n                \"info\": \"Number of fields to be added to the record.\",\n                \"real_time_refresh\": True,\n                \"rangeSpec\": RangeSpec(min=1, max=15, step=1, step_type=\"int\"),\n            },\n            \"text_key\": {\n                \"display_name\": \"Text Key\",\n                \"info\": \"Key to be used as text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        number_of_fields: int = 0,\n        text_key: str = \"text\",\n        **kwargs,\n    ) -> Data:\n        data = {}\n        for value_dict in kwargs.values():\n            if isinstance(value_dict, dict):\n                # Check if the value of the value_dict is a Data\n                value_dict = {\n                    key: value.get_text() if isinstance(value, Data) else value for key, value in value_dict.items()\n                }\n                data.update(value_dict)\n        return_data = Data(data=data, text_key=text_key)\n        self.status = return_data\n        return return_data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "number_of_fields": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 0,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "number_of_fields",
          "display_name": "Number of Fields",
          "advanced": false,
          "dynamic": false,
          "info": "Number of fields to be added to the record.",
          "real_time_refresh": true,
          "load_from_db": false,
          "title_case": false
        },
        "text_key": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "text",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "text_key",
          "display_name": "Text Key",
          "advanced": true,
          "dynamic": false,
          "info": "Key to be used as text.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Dynamically create a Data with a specified number of fields.",
      "base_classes": [
        "Data"
      ],
      "display_name": "Create Data",
      "documentation": "",
      "custom_fields": {
        "number_of_fields": null,
        "text_key": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "number_of_fields",
        "text_key"
      ],
      "beta": false,
      "edited": false
    },
    "ConditionalRouter": {
      "template": {
        "_type": "Component",
        "case_sensitive": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "case_sensitive",
          "display_name": "Case Sensitive",
          "advanced": true,
          "dynamic": false,
          "info": "If true, the comparison will be case sensitive.",
          "title_case": false,
          "type": "bool"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"equal\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The primary text input for the operation.\",\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True Route\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False Route\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, case_sensitive: bool) -> bool:\n        if not case_sensitive:\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        elif operator == \"not equals\":\n            return input_text != match_text\n        elif operator == \"contains\":\n            return match_text in input_text\n        elif operator == \"starts with\":\n            return input_text.startswith(match_text)\n        elif operator == \"ends with\":\n            return input_text.endswith(match_text)\n        return False\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if result:\n            self.stop(\"false_result\")\n            response = self.message if self.message else self.input_text\n            self.status = response\n            return response\n        else:\n            self.stop(\"true_result\")\n            return Message()\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if not result:\n            self.stop(\"true_result\")\n            response = self.message if self.message else self.input_text\n            self.status = response\n            return response\n        else:\n            self.stop(\"false_result\")\n            return Message()\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_text": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_text",
          "display_name": "Input Text",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The primary text input for the operation.",
          "title_case": false,
          "type": "str"
        },
        "match_text": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "match_text",
          "display_name": "Match Text",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The text input to compare against.",
          "title_case": false,
          "type": "str"
        },
        "message": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "message",
          "display_name": "Message",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The message to pass through either route.",
          "title_case": false,
          "type": "str"
        },
        "operator": {
          "trace_as_metadata": true,
          "options": [
            "equals",
            "not equals",
            "contains",
            "starts with",
            "ends with"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "equals",
          "name": "operator",
          "display_name": "Operator",
          "advanced": true,
          "dynamic": false,
          "info": "The operator to apply for comparing the texts.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Routes an input message to a corresponding output based on text comparison.",
      "icon": "equal",
      "base_classes": [
        "Message"
      ],
      "display_name": "Conditional Router",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "true_result",
          "display_name": "True Route",
          "method": "true_response",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "false_result",
          "display_name": "False Route",
          "method": "false_response",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_text",
        "match_text",
        "operator",
        "case_sensitive",
        "message"
      ],
      "beta": false,
      "edited": false
    },
    "Listen": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.custom import CustomComponent\nfrom langflow.schema import Data\n\n\nclass ListenComponent(CustomComponent):\n    display_name = \"Listen\"\n    description = \"A component to listen for a notification.\"\n    beta: bool = True\n\n    def build_config(self):\n        return {\n            \"name\": {\n                \"display_name\": \"Name\",\n                \"info\": \"The name of the notification to listen for.\",\n            },\n        }\n\n    def build(self, name: str) -> Data:\n        state = self.get_state(name)\n        self.status = state\n        return state\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "name",
          "display_name": "Name",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the notification to listen for.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "A component to listen for a notification.",
      "base_classes": [
        "Data"
      ],
      "display_name": "Listen",
      "documentation": "",
      "custom_fields": {
        "name": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    }
  },
  "textsplitters": {
    "RecursiveCharacterTextSplitter": {
      "template": {
        "_type": "Component",
        "data_input": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "data_input",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Document",
            "Data"
          ],
          "dynamic": false,
          "info": "The texts to split.",
          "title_case": false,
          "type": "other"
        },
        "chunk_overlap": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 200,
          "name": "chunk_overlap",
          "display_name": "Chunk Overlap",
          "advanced": false,
          "dynamic": false,
          "info": "The amount of overlap between chunks.",
          "title_case": false,
          "type": "int"
        },
        "chunk_size": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 1000,
          "name": "chunk_size",
          "display_name": "Chunk Size",
          "advanced": false,
          "dynamic": false,
          "info": "The maximum length of each chunk.",
          "title_case": false,
          "type": "int"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain_text_splitters import RecursiveCharacterTextSplitter\n\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom langflow.schema import Data\nfrom langflow.template.field.base import Output\nfrom langflow.utils.util import build_loader_repr_from_data, unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(Component):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text into chunks of a specified length.\"\n    documentation: str = \"https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"split_data\"),\n    ]\n\n    def split_data(self) -> list[Data]:\n        \"\"\"\n        Split text into chunks of a specified length.\n\n        Args:\n            separators (list[str] | None): The characters to split on.\n            chunk_size (int): The maximum length of each chunk.\n            chunk_overlap (int): The amount of overlap between chunks.\n\n        Returns:\n            list[str]: The chunks of text.\n        \"\"\"\n\n        if self.separators == \"\":\n            self.separators: list[str] | None = None\n        elif self.separators:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            self.separators = [unescape_string(x) for x in self.separators]\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if self.chunk_size:\n            self.chunk_size: int = int(self.chunk_size)\n        if self.chunk_overlap:\n            self.chunk_overlap: int = int(self.chunk_overlap)\n        splitter = RecursiveCharacterTextSplitter(\n            separators=self.separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n        documents = []\n        if not isinstance(self.data_input, list):\n            self.data_input: list[Data] = [self.data_input]\n        for _input in self.data_input:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = splitter.split_documents(documents)\n        data = self.to_data(docs)\n        self.repr_value = build_loader_repr_from_data(data)\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "separators": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "separators",
          "display_name": "Separators",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Split text into chunks of a specified length.",
      "base_classes": [
        "Data"
      ],
      "display_name": "Recursive Character Text Splitter",
      "documentation": "https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "display_name": "Data",
          "method": "split_data",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "chunk_size",
        "chunk_overlap",
        "data_input",
        "separators"
      ],
      "beta": false,
      "edited": false
    },
    "CharacterTextSplitter": {
      "template": {
        "_type": "CustomComponent",
        "inputs": {
          "type": "Data",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "inputs",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Document",
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "chunk_overlap": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 200,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "chunk_overlap",
          "display_name": "Chunk Overlap",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "chunk_size": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 1000,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "chunk_size",
          "display_name": "Chunk Size",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Data\nfrom langflow.utils.util import unescape_string\n\n\nclass CharacterTextSplitterComponent(CustomComponent):\n    display_name = \"CharacterTextSplitter\"\n    description = \"Splitting text that looks at characters.\"\n\n    def build_config(self):\n        return {\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Data\"]},\n            \"chunk_overlap\": {\"display_name\": \"Chunk Overlap\", \"default\": 200},\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"default\": 1000},\n            \"separator\": {\"display_name\": \"Separator\", \"default\": \"\\n\"},\n        }\n\n    def build(\n        self,\n        inputs: List[Data],\n        chunk_overlap: int = 200,\n        chunk_size: int = 1000,\n        separator: str = \"\\n\",\n    ) -> List[Data]:\n        # separator may come escaped from the frontend\n        separator = unescape_string(separator)\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = CharacterTextSplitter(\n            chunk_overlap=chunk_overlap,\n            chunk_size=chunk_size,\n            separator=separator,\n        ).split_documents(documents)\n        data = self.to_data(docs)\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "separator": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "\\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "separator",
          "display_name": "Separator",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Splitting text that looks at characters.",
      "base_classes": [
        "Data"
      ],
      "display_name": "CharacterTextSplitter",
      "documentation": "",
      "custom_fields": {
        "inputs": null,
        "chunk_overlap": null,
        "chunk_size": null,
        "separator": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "LanguageRecursiveTextSplitter": {
      "template": {
        "_type": "CustomComponent",
        "inputs": {
          "type": "Data",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "inputs",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Document",
            "Data"
          ],
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "chunk_overlap": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 200,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "chunk_overlap",
          "display_name": "Chunk Overlap",
          "advanced": false,
          "dynamic": false,
          "info": "The amount of overlap between chunks.",
          "load_from_db": false,
          "title_case": false
        },
        "chunk_size": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 1000,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "chunk_size",
          "display_name": "Chunk Size",
          "advanced": false,
          "dynamic": false,
          "info": "The maximum length of each chunk.",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List, Optional\n\nfrom langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Data\n\n\nclass LanguageRecursiveTextSplitterComponent(CustomComponent):\n    display_name: str = \"Language Recursive Text Splitter\"\n    description: str = \"Split text into chunks of a specified length based on language.\"\n    documentation: str = \"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter\"\n\n    def build_config(self):\n        options = [x.value for x in Language]\n        return {\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Data\"]},\n            \"separator_type\": {\n                \"display_name\": \"Separator Type\",\n                \"info\": \"The type of separator to use.\",\n                \"field_type\": \"str\",\n                \"options\": options,\n                \"value\": \"Python\",\n            },\n            \"separators\": {\n                \"display_name\": \"Separators\",\n                \"info\": \"The characters to split on.\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\n                \"display_name\": \"Chunk Size\",\n                \"info\": \"The maximum length of each chunk.\",\n                \"field_type\": \"int\",\n                \"value\": 1000,\n            },\n            \"chunk_overlap\": {\n                \"display_name\": \"Chunk Overlap\",\n                \"info\": \"The amount of overlap between chunks.\",\n                \"field_type\": \"int\",\n                \"value\": 200,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        inputs: List[Data],\n        chunk_size: Optional[int] = 1000,\n        chunk_overlap: Optional[int] = 200,\n        separator_type: str = \"Python\",\n    ) -> list[Data]:\n        \"\"\"\n        Split text into chunks of a specified length.\n\n        Args:\n            separators (list[str]): The characters to split on.\n            chunk_size (int): The maximum length of each chunk.\n            chunk_overlap (int): The amount of overlap between chunks.\n            length_function (function): The function to use to calculate the length of the text.\n\n        Returns:\n            list[str]: The chunks of text.\n        \"\"\"\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if isinstance(chunk_size, str):\n            chunk_size = int(chunk_size)\n        if isinstance(chunk_overlap, str):\n            chunk_overlap = int(chunk_overlap)\n\n        splitter = RecursiveCharacterTextSplitter.from_language(\n            language=Language(separator_type),\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_overlap,\n        )\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = splitter.split_documents(documents)\n        data = self.to_data(docs)\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "separator_type": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "value": "Python",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [
            "cpp",
            "go",
            "java",
            "kotlin",
            "js",
            "ts",
            "php",
            "proto",
            "python",
            "rst",
            "ruby",
            "rust",
            "scala",
            "swift",
            "markdown",
            "latex",
            "html",
            "sol",
            "csharp",
            "cobol",
            "c",
            "lua",
            "perl",
            "haskell",
            "elixir"
          ],
          "name": "separator_type",
          "display_name": "Separator Type",
          "advanced": false,
          "dynamic": false,
          "info": "The type of separator to use.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Split text into chunks of a specified length based on language.",
      "base_classes": [
        "Data"
      ],
      "display_name": "Language Recursive Text Splitter",
      "documentation": "https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter",
      "custom_fields": {
        "inputs": null,
        "chunk_size": null,
        "chunk_overlap": null,
        "separator_type": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    }
  },
  "prompts": {
    "Prompt": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(frontend_template=frontend_node, raw_template=current_build_config[\"template\"])\n        return frontend_node\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "template": {
          "trace_as_input": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "template",
          "display_name": "Template",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "prompt"
        }
      },
      "description": "Create a prompt template with dynamic variables.",
      "icon": "prompts",
      "base_classes": [
        "Message"
      ],
      "display_name": "Prompt",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "prompt",
          "display_name": "Prompt Message",
          "method": "build_prompt",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "template"
      ],
      "beta": false,
      "edited": false
    }
  },
  "chains": {
    "ConversationChain": {
      "template": {
        "_type": "CustomComponent",
        "input_value": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input Value",
          "advanced": false,
          "dynamic": false,
          "info": "The input value to pass to the chain.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "memory": {
          "type": "BaseMemory",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "memory",
          "display_name": "Memory",
          "advanced": false,
          "dynamic": false,
          "info": "Memory to load context from. If none is provided, a ConversationBufferMemory will be used.",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain.chains import ConversationChain\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseMemory, LanguageModel, Text\n\n\nclass ConversationChainComponent(CustomComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\n                \"display_name\": \"Memory\",\n                \"info\": \"Memory to load context from. If none is provided, a ConversationBufferMemory will be used.\",\n            },\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"The input value to pass to the chain.\",\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        llm: LanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Text:\n        if memory is None:\n            chain = ConversationChain(llm=llm)\n        else:\n            chain = ConversationChain(llm=llm, memory=memory)\n        result = chain.invoke({\"input\": input_value})\n        if isinstance(result, dict):\n            result = result.get(chain.output_key, \"\")  # type: ignore\n\n        elif isinstance(result, str):\n            result = result\n        else:\n            result = result.get(\"response\")\n        self.status = result\n        return str(result)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Chain to have a conversation and load context from memory.",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "ConversationChain",
      "documentation": "",
      "custom_fields": {
        "input_value": null,
        "llm": null,
        "memory": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "LLMCheckerChain": {
      "template": {
        "_type": "CustomComponent",
        "input_value": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input Value",
          "advanced": false,
          "dynamic": false,
          "info": "The input value to pass to the chain.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langchain.chains import LLMCheckerChain\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import LanguageModel, Text\n\n\nclass LLMCheckerChainComponent(CustomComponent):\n    display_name = \"LLMCheckerChain\"\n    description = \"\"\n    documentation = \"https://python.langchain.com/docs/modules/chains/additional/llm_checker\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"The input value to pass to the chain.\",\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        llm: LanguageModel,\n    ) -> Text:\n        chain = LLMCheckerChain.from_llm(llm=llm)\n        response = chain.invoke({chain.input_key: input_value})\n        result = response.get(chain.output_key, \"\")\n        result_str = str(result)\n        self.status = result_str\n        return result_str\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "LLMCheckerChain",
      "documentation": "https://python.langchain.com/docs/modules/chains/additional/llm_checker",
      "custom_fields": {
        "input_value": null,
        "llm": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "LLMChain": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "memory": {
          "type": "BaseMemory",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "memory",
          "display_name": "Memory",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "template": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "template",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain.chains.llm import LLMChain\nfrom langchain_core.prompts import PromptTemplate\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseMemory, LanguageModel, Text\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n        }\n\n    def build(\n        self,\n        template: Text,\n        llm: LanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Text:\n        prompt = PromptTemplate.from_template(template)\n        runnable = LLMChain(prompt=prompt, llm=llm, memory=memory)\n        result_dict = runnable.invoke({})\n        output_key = runnable.output_key\n        result = result_dict[output_key]\n        self.status = result\n        return result\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Chain to run queries against LLMs",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "LLMChain",
      "documentation": "",
      "custom_fields": {
        "template": null,
        "llm": null,
        "memory": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "SQLGenerator": {
      "template": {
        "_type": "CustomComponent",
        "db": {
          "type": "SQLDatabase",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "db",
          "display_name": "Database",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input Value",
          "advanced": false,
          "dynamic": false,
          "info": "The input value to pass to the chain.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "prompt": {
          "type": "Text",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "prompt",
          "display_name": "Prompt",
          "advanced": false,
          "dynamic": false,
          "info": "The prompt must contain `{question}`.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain.chains import create_sql_query_chain\nfrom langchain_community.utilities.sql_database import SQLDatabase\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import Runnable\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import LanguageModel, Text\n\n\nclass SQLGeneratorComponent(CustomComponent):\n    display_name = \"Natural Language to SQL\"\n    description = \"Generate SQL from natural language.\"\n\n    def build_config(self):\n        return {\n            \"db\": {\"display_name\": \"Database\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"prompt\": {\n                \"display_name\": \"Prompt\",\n                \"info\": \"The prompt must contain `{question}`.\",\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"info\": \"The number of results per select statement to return. If 0, no limit.\",\n            },\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"The input value to pass to the chain.\",\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        db: SQLDatabase,\n        llm: LanguageModel,\n        top_k: int = 5,\n        prompt: Optional[Text] = None,\n    ) -> Text:\n        if prompt:\n            prompt_template = PromptTemplate.from_template(template=prompt)\n        else:\n            prompt_template = None\n\n        if top_k < 1:\n            raise ValueError(\"Top K must be greater than 0.\")\n\n        if not prompt_template:\n            sql_query_chain = create_sql_query_chain(llm=llm, db=db, k=top_k)\n        else:\n            # Check if {question} is in the prompt\n            if \"{question}\" not in prompt_template.template or \"question\" not in prompt_template.input_variables:\n                raise ValueError(\"Prompt must contain `{question}` to be used with Natural Language to SQL.\")\n            sql_query_chain = create_sql_query_chain(llm=llm, db=db, prompt=prompt_template, k=top_k)\n        query_writer: Runnable = sql_query_chain | {\"query\": lambda x: x.replace(\"SQLQuery:\", \"\").strip()}\n        response = query_writer.invoke({\"question\": input_value})\n        query = response.get(\"query\")\n        self.status = query\n        return query\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "top_k": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": 5,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "top_k",
          "display_name": "Top K",
          "advanced": false,
          "dynamic": false,
          "info": "The number of results per select statement to return. If 0, no limit.",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Generate SQL from natural language.",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "Natural Language to SQL",
      "documentation": "",
      "custom_fields": {
        "input_value": null,
        "db": null,
        "llm": null,
        "top_k": null,
        "prompt": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "RetrievalQAWithSourcesChain": {
      "template": {
        "_type": "CustomComponent",
        "input_value": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input Value",
          "advanced": false,
          "dynamic": false,
          "info": "The input value to pass to the chain.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "memory": {
          "type": "BaseMemory",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "memory",
          "display_name": "Memory",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "retriever": {
          "type": "BaseRetriever",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "retriever",
          "display_name": "Retriever",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "chain_type": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [
            "Stuff",
            "Map Reduce",
            "Refine",
            "Map Rerank"
          ],
          "name": "chain_type",
          "display_name": "Chain Type",
          "advanced": false,
          "dynamic": false,
          "info": "The type of chain to use to combined Documents.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain.chains import RetrievalQAWithSourcesChain\nfrom langchain_core.documents import Document\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseMemory, BaseRetriever, LanguageModel, Text\n\n\nclass RetrievalQAWithSourcesChainComponent(CustomComponent):\n    display_name = \"RetrievalQAWithSourcesChain\"\n    description = \"Question-answering with sources over an index.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"chain_type\": {\n                \"display_name\": \"Chain Type\",\n                \"options\": [\"Stuff\", \"Map Reduce\", \"Refine\", \"Map Rerank\"],\n                \"info\": \"The type of chain to use to combined Documents.\",\n            },\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"return_source_documents\": {\"display_name\": \"Return Source Documents\"},\n            \"retriever\": {\"display_name\": \"Retriever\"},\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"The input value to pass to the chain.\",\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        retriever: BaseRetriever,\n        llm: LanguageModel,\n        chain_type: str,\n        memory: Optional[BaseMemory] = None,\n        return_source_documents: Optional[bool] = True,\n    ) -> Text:\n        chain_type = chain_type.lower().replace(\" \", \"_\")\n        runnable = RetrievalQAWithSourcesChain.from_chain_type(\n            llm=llm,\n            chain_type=chain_type,\n            memory=memory,\n            return_source_documents=return_source_documents,\n            retriever=retriever,\n        )\n        if isinstance(input_value, Document):\n            input_value = input_value.page_content\n        self.status = runnable\n        input_key = runnable.input_keys[0]\n        result = runnable.invoke({input_key: input_value})\n        result = result.content if hasattr(result, \"content\") else result\n        # Result is a dict with keys \"query\",  \"result\" and \"source_documents\"\n        # for now we just return the result\n        data = self.to_data(result.get(\"source_documents\"))\n        references_str = \"\"\n        if return_source_documents:\n            references_str = self.create_references_from_data(data)\n        result_str = str(result.get(\"answer\", \"\"))\n        final_result = \"\\n\".join([result_str, references_str])\n        self.status = final_result\n        return final_result\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "return_source_documents": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": true,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "return_source_documents",
          "display_name": "Return Source Documents",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Question-answering with sources over an index.",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "RetrievalQAWithSourcesChain",
      "documentation": "",
      "custom_fields": {
        "input_value": null,
        "retriever": null,
        "llm": null,
        "chain_type": null,
        "memory": null,
        "return_source_documents": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "RetrievalQA": {
      "template": {
        "_type": "CustomComponent",
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "memory": {
          "type": "BaseMemory",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "memory",
          "display_name": "Memory",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "retriever": {
          "type": "BaseRetriever",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "retriever",
          "display_name": "Retriever",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "chain_type": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [
            "Stuff",
            "Map Reduce",
            "Refine",
            "Map Rerank"
          ],
          "name": "chain_type",
          "display_name": "Chain Type",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain.chains.retrieval_qa.base import RetrievalQA\nfrom langchain_core.documents import Document\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseMemory, BaseRetriever, LanguageModel, Text\nfrom langflow.schema import Data\n\n\nclass RetrievalQAComponent(CustomComponent):\n    display_name = \"Retrieval QA\"\n    description = \"Chain for question-answering against an index.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"chain_type\": {\"display_name\": \"Chain Type\", \"options\": [\"Stuff\", \"Map Reduce\", \"Refine\", \"Map Rerank\"]},\n            \"retriever\": {\"display_name\": \"Retriever\"},\n            \"memory\": {\"display_name\": \"Memory\", \"required\": False},\n            \"input_key\": {\"display_name\": \"Input Key\", \"advanced\": True},\n            \"output_key\": {\"display_name\": \"Output Key\", \"advanced\": True},\n            \"return_source_documents\": {\"display_name\": \"Return Source Documents\"},\n            \"input_value\": {\n                \"display_name\": \"Input\",\n                \"input_types\": [\"Data\", \"Document\"],\n            },\n        }\n\n    def build(\n        self,\n        llm: LanguageModel,\n        chain_type: str,\n        retriever: BaseRetriever,\n        input_value: str = \"\",\n        memory: Optional[BaseMemory] = None,\n        input_key: str = \"query\",\n        output_key: str = \"result\",\n        return_source_documents: bool = True,\n    ) -> Text:\n        chain_type = chain_type.lower().replace(\" \", \"_\")\n        runnable = RetrievalQA.from_chain_type(\n            llm=llm,\n            chain_type=chain_type,\n            retriever=retriever,\n            memory=memory,\n            input_key=input_key,\n            output_key=output_key,\n            return_source_documents=return_source_documents,\n        )\n        if isinstance(input_value, Document):\n            input_value = input_value.page_content\n        if isinstance(input_value, Data):\n            input_value = input_value.get_text()\n        self.status = runnable\n        result = runnable.invoke({input_key: input_value})\n        result = result.content if hasattr(result, \"content\") else result\n        # Result is a dict with keys \"query\",  \"result\" and \"source_documents\"\n        # for now we just return the result\n        data = self.to_data(result.get(\"source_documents\"))\n        references_str = \"\"\n        if return_source_documents:\n            references_str = self.create_references_from_data(data)\n        result_str = result.get(\"result\", \"\")\n\n        final_result = \"\\n\".join([str(result_str), references_str])\n        self.status = final_result\n        return final_result  # OK\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_key": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "query",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_key",
          "display_name": "Input Key",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "input_value": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input",
          "advanced": false,
          "input_types": [
            "Data",
            "Document"
          ],
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "output_key": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "result",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "output_key",
          "display_name": "Output Key",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "return_source_documents": {
          "type": "bool",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": true,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "return_source_documents",
          "display_name": "Return Source Documents",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Chain for question-answering against an index.",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "Retrieval QA",
      "documentation": "",
      "custom_fields": {
        "llm": null,
        "chain_type": null,
        "retriever": null,
        "input_value": null,
        "memory": null,
        "input_key": null,
        "output_key": null,
        "return_source_documents": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "LLMMathChain": {
      "template": {
        "_type": "CustomComponent",
        "input_value": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input Value",
          "advanced": false,
          "dynamic": false,
          "info": "The input value to pass to the chain.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "llm": {
          "type": "LanguageModel",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm",
          "display_name": "LLM",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "llm_chain": {
          "type": "LLMChain",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "llm_chain",
          "display_name": "LLM Chain",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "memory": {
          "type": "BaseMemory",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "memory",
          "display_name": "Memory",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain.chains import LLMChain, LLMMathChain\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseMemory, LanguageModel, Text\n\n\nclass LLMMathChainComponent(CustomComponent):\n    display_name = \"LLMMathChain\"\n    description = \"Chain that interprets a prompt and executes python code to do math.\"\n    documentation = \"https://python.langchain.com/docs/modules/chains/additional/llm_math\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"llm_chain\": {\"display_name\": \"LLM Chain\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"input_key\": {\"display_name\": \"Input Key\"},\n            \"output_key\": {\"display_name\": \"Output Key\"},\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"The input value to pass to the chain.\",\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        llm: LanguageModel,\n        llm_chain: LLMChain,\n        input_key: str = \"question\",\n        output_key: str = \"answer\",\n        memory: Optional[BaseMemory] = None,\n    ) -> Text:\n        chain = LLMMathChain(\n            llm=llm,\n            llm_chain=llm_chain,\n            input_key=input_key,\n            output_key=output_key,\n            memory=memory,\n        )\n        response = chain.invoke({input_key: input_value})\n        result = response.get(output_key)\n        result_str = str(result)\n        self.status = result_str\n        return result_str\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_key": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "question",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_key",
          "display_name": "Input Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "output_key": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "value": "answer",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "output_key",
          "display_name": "Output Key",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Chain that interprets a prompt and executes python code to do math.",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "LLMMathChain",
      "documentation": "https://python.langchain.com/docs/modules/chains/additional/llm_math",
      "custom_fields": {
        "input_value": null,
        "llm": null,
        "llm_chain": null,
        "input_key": null,
        "output_key": null,
        "memory": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    }
  },
  "data": {
    "APIRequest": {
      "template": {
        "_type": "Component",
        "query_params": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "query_params",
          "display_name": "Query Parameters",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "The query parameters to append to the URL.",
          "title_case": false,
          "type": "other"
        },
        "body": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "body",
          "display_name": "Body",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.",
          "title_case": false,
          "type": "NestedDict"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "import asyncio\nimport json\nfrom typing import Any, List, Optional\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport httpx\nfrom loguru import logger\n\nfrom langflow.base.curl.parse import parse_context\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, DropdownInput, IntInput, MessageTextInput, NestedDictInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = (\n        \"This component allows you to make HTTP requests to one or more URLs. \"\n        \"You can provide headers and body as either dictionaries or Data objects. \"\n        \"Additionally, you can append query parameters to the URLs.\\n\\n\"\n        \"**Note:** Check advanced options for more settings.\"\n    )\n    icon = \"Globe\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            is_list=True,\n            info=\"Enter one or more URLs, separated by commas.\",\n        ),\n        MessageTextInput(\n            name=\"curl\",\n            display_name=\"Curl\",\n            info=\"Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.\",\n            advanced=False,\n            refresh_button=True,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\"],\n            value=\"GET\",\n            info=\"The HTTP method to use (GET, POST, PATCH, PUT).\",\n        ),\n        NestedDictInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request as a dictionary. This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        NestedDictInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=5,\n            info=\"The timeout to use for the request.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"make_requests\"),\n    ]\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        try:\n            parsed = parse_context(curl)\n            build_config[\"urls\"][\"value\"] = [parsed.url]\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n            build_config[\"headers\"][\"value\"] = dict(parsed.headers)\n\n            if parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    build_config[\"body\"][\"value\"] = json_data\n                except json.JSONDecodeError as e:\n                    logger.error(f\"Error decoding JSON data: {e}\")\n            else:\n                build_config[\"body\"][\"value\"] = {}\n        except Exception as exc:\n            logger.error(f\"Error parsing curl: {exc}\")\n            raise ValueError(f\"Error parsing curl: {exc}\")\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"curl\" and field_value:\n            build_config = self.parse_curl(field_value, build_config)\n        return build_config\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: Optional[dict] = None,\n        body: Optional[dict] = None,\n        timeout: int = 5,\n    ) -> Data:\n        method = method.upper()\n        if method not in [\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"]:\n            raise ValueError(f\"Unsupported method: {method}\")\n\n        data = body if body else None\n        payload = json.dumps(data) if data else None\n        try:\n            response = await client.request(method, url, headers=headers, content=payload, timeout=timeout)\n            try:\n                result = response.json()\n            except Exception:\n                result = response.text\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": response.status_code,\n                    \"result\": result,\n                },\n            )\n        except httpx.TimeoutException:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 408,\n                    \"error\": \"Request timed out\",\n                },\n            )\n        except Exception as exc:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    async def make_requests(self) -> List[Data]:\n        method = self.method\n        urls = [url.strip() for url in self.urls if url.strip()]\n        curl = self.curl\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        query_params = self.query_params.data if self.query_params else {}\n\n        if curl:\n            self._build_config = self.parse_curl(curl, dotdict())\n\n        if isinstance(headers, Data):\n            headers = headers.data\n\n        if isinstance(body, Data):\n            body = body.data\n\n        bodies = [body] * len(urls)\n\n        urls = [self.add_query_params(url, query_params) for url in urls]\n\n        async with httpx.AsyncClient() as client:\n            results = await asyncio.gather(\n                *[self.make_request(client, method, u, headers, rec, timeout) for u, rec in zip(urls, bodies)]\n            )\n        self.status = results\n        return results\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "curl": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "curl",
          "display_name": "Curl",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
          "refresh_button": true,
          "title_case": false,
          "type": "str"
        },
        "headers": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": {},
          "name": "headers",
          "display_name": "Headers",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "The headers to send with the request as a dictionary. This is populated when using the CURL field.",
          "title_case": false,
          "type": "NestedDict"
        },
        "method": {
          "trace_as_metadata": true,
          "options": [
            "GET",
            "POST",
            "PATCH",
            "PUT"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "GET",
          "name": "method",
          "display_name": "Method",
          "advanced": false,
          "dynamic": false,
          "info": "The HTTP method to use (GET, POST, PATCH, PUT).",
          "title_case": false,
          "type": "str"
        },
        "timeout": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 5,
          "name": "timeout",
          "display_name": "Timeout",
          "advanced": false,
          "dynamic": false,
          "info": "The timeout to use for the request.",
          "title_case": false,
          "type": "int"
        },
        "urls": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "urls",
          "display_name": "URLs",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Enter one or more URLs, separated by commas.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "This component allows you to make HTTP requests to one or more URLs. You can provide headers and body as either dictionaries or Data objects. Additionally, you can append query parameters to the URLs.\n\n**Note:** Check advanced options for more settings.",
      "icon": "Globe",
      "base_classes": [
        "Data"
      ],
      "display_name": "API Request",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "display_name": "Data",
          "method": "make_requests",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "urls",
        "curl",
        "method",
        "headers",
        "body",
        "query_params",
        "timeout"
      ],
      "beta": false,
      "edited": false
    },
    "Webhook": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "import json\n\nfrom langflow.custom import Component\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema import Data\n\n\nclass WebhookComponent(Component):\n    display_name = \"Webhook Input\"\n    description = \"Defines a webhook input for the flow.\"\n\n    inputs = [\n        MultilineInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"Use this field to quickly test the webhook component by providing a JSON payload.\",\n        )\n    ]\n    outputs = [\n        Output(display_name=\"Data\", name=\"output_data\", method=\"build_data\"),\n    ]\n\n    def build_data(self) -> Data:\n        message: str | Data = \"\"\n        if not self.data:\n            self.status = \"No data provided.\"\n            return Data(data={})\n        try:\n            body = json.loads(self.data or \"{}\")\n        except json.JSONDecodeError:\n            body = {\"payload\": self.data}\n            message = f\"Invalid JSON payload. Please check the format.\\n\\n{self.data}\"\n        data = Data(data=body)\n        if not message:\n            message = data\n        self.status = message\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "data": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "data",
          "display_name": "Data",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Use this field to quickly test the webhook component by providing a JSON payload.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Defines a webhook input for the flow.",
      "base_classes": [
        "Data"
      ],
      "display_name": "Webhook Input",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "output_data",
          "display_name": "Data",
          "method": "build_data",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "data"
      ],
      "beta": false,
      "edited": false
    },
    "URL": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "import re\n\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\n\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\n\nclass URLComponent(Component):\n    display_name = \"URL\"\n    description = \"Fetch content from one or more URLs.\"\n    icon = \"layout-template\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            info=\"Enter one or more URLs, separated by commas.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n    ]\n\n    def ensure_url(self, string: str) -> str:\n        \"\"\"\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\n        Raises an error if the string is not a valid URL.\n\n        Parameters:\n            string (str): The string to be checked and possibly modified.\n\n        Returns:\n            str: The modified string that is ensured to be a URL.\n\n        Raises:\n            ValueError: If the string is not a valid URL.\n        \"\"\"\n        if not string.startswith((\"http://\", \"https://\")):\n            string = \"http://\" + string\n\n        # Basic URL validation regex\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\"  # optional protocol\n            r\"(www\\.)?\"  # optional www\n            r\"([a-zA-Z0-9.-]+)\"  # domain\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\n            r\"(:\\d+)?\"  # optional port\n            r\"(\\/[^\\s]*)?$\",  # optional path\n            re.IGNORECASE,\n        )\n\n        if not url_regex.match(string):\n            raise ValueError(f\"Invalid URL: {string}\")\n\n        return string\n\n    def fetch_content(self) -> list[Data]:\n        urls = [self.ensure_url(url.strip()) for url in self.urls if url.strip()]\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\n        docs = loader.load()\n        data = [Data(text=doc.page_content, **doc.metadata) for doc in docs]\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "urls": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "urls",
          "display_name": "URLs",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Enter one or more URLs, separated by commas.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Fetch content from one or more URLs.",
      "icon": "layout-template",
      "base_classes": [
        "Data"
      ],
      "display_name": "URL",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "display_name": "Data",
          "method": "fetch_content",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "urls"
      ],
      "beta": false,
      "edited": false
    },
    "File": {
      "template": {
        "_type": "Component",
        "path": {
          "trace_as_metadata": true,
          "file_path": "",
          "fileTypes": [
            "txt",
            "md",
            "mdx",
            "csv",
            "json",
            "yaml",
            "yml",
            "xml",
            "html",
            "htm",
            "pdf",
            "docx",
            "py",
            "sh",
            "sql",
            "js",
            "ts",
            "tsx"
          ],
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "path",
          "display_name": "Path",
          "advanced": false,
          "dynamic": false,
          "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx",
          "title_case": false,
          "type": "file"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from pathlib import Path\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, FileInput, Output\nfrom langflow.schema import Data\n\n\nclass FileComponent(Component):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"Path\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_file\"),\n    ]\n\n    def load_file(self) -> Data:\n        if not self.path:\n            raise ValueError(\"Please, upload a file to use this component.\")\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n\n        data = parse_text_file_to_data(resolved_path, silent_errors)\n        self.status = data if data else \"No data\"\n        return data or Data()\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "silent_errors": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "silent_errors",
          "display_name": "Silent Errors",
          "advanced": true,
          "dynamic": false,
          "info": "If true, errors will not raise an exception.",
          "title_case": false,
          "type": "bool"
        }
      },
      "description": "A generic file loader.",
      "icon": "file-text",
      "base_classes": [
        "Data"
      ],
      "display_name": "File",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "display_name": "Data",
          "method": "load_file",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "path",
        "silent_errors"
      ],
      "beta": false,
      "edited": false
    },
    "Directory": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List, Optional\n\nfrom langflow.base.data.utils import parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, IntInput, MessageTextInput\nfrom langflow.schema import Data\nfrom langflow.template import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    icon = \"folder\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from.\",\n        ),\n        MessageTextInput(\n            name=\"types\",\n            display_name=\"Types\",\n            info=\"File types to load. Leave empty to load all types.\",\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_directory\"),\n    ]\n\n    def load_directory(self) -> List[Optional[Data]]:\n        path = self.path\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n        file_paths = retrieve_file_paths(resolved_path, load_hidden, recursive, depth)\n        loaded_data = []\n\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors, max_concurrency)\n        else:\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors) for file_path in file_paths]\n        loaded_data = list(filter(None, loaded_data))\n        self.status = loaded_data\n        return loaded_data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "depth": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 0,
          "name": "depth",
          "display_name": "Depth",
          "advanced": false,
          "dynamic": false,
          "info": "Depth to search for files.",
          "title_case": false,
          "type": "int"
        },
        "load_hidden": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "load_hidden",
          "display_name": "Load Hidden",
          "advanced": true,
          "dynamic": false,
          "info": "If true, hidden files will be loaded.",
          "title_case": false,
          "type": "bool"
        },
        "max_concurrency": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 2,
          "name": "max_concurrency",
          "display_name": "Max Concurrency",
          "advanced": true,
          "dynamic": false,
          "info": "Maximum concurrency for loading files.",
          "title_case": false,
          "type": "int"
        },
        "path": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "path",
          "display_name": "Path",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Path to the directory to load files from.",
          "title_case": false,
          "type": "str"
        },
        "recursive": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "recursive",
          "display_name": "Recursive",
          "advanced": true,
          "dynamic": false,
          "info": "If true, the search will be recursive.",
          "title_case": false,
          "type": "bool"
        },
        "silent_errors": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "silent_errors",
          "display_name": "Silent Errors",
          "advanced": true,
          "dynamic": false,
          "info": "If true, errors will not raise an exception.",
          "title_case": false,
          "type": "bool"
        },
        "types": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "types",
          "display_name": "Types",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "File types to load. Leave empty to load all types.",
          "title_case": false,
          "type": "str"
        },
        "use_multithreading": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": false,
          "name": "use_multithreading",
          "display_name": "Use Multithreading",
          "advanced": true,
          "dynamic": false,
          "info": "If true, multithreading will be used.",
          "title_case": false,
          "type": "bool"
        }
      },
      "description": "Recursively load files from a directory.",
      "icon": "folder",
      "base_classes": [
        "Data"
      ],
      "display_name": "Directory",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "display_name": "Data",
          "method": "load_directory",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "path",
        "types",
        "depth",
        "max_concurrency",
        "load_hidden",
        "recursive",
        "silent_errors",
        "use_multithreading"
      ],
      "beta": false,
      "edited": false
    }
  },
  "outputs": {
    "TextOutput": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Text",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Text to be passed as output.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Display a text output in the Playground.",
      "icon": "type",
      "base_classes": [
        "Message"
      ],
      "display_name": "Text Output",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value"
      ],
      "beta": false,
      "edited": false
    },
    "ChatOutput": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "data_template": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "{text}",
          "name": "data_template",
          "display_name": "Data Template",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
          "title_case": false,
          "type": "str"
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Text",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Message to be passed as output.",
          "title_case": false,
          "type": "str"
        },
        "sender": {
          "trace_as_metadata": true,
          "options": [
            "Machine",
            "User"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Machine",
          "name": "sender",
          "display_name": "Sender Type",
          "advanced": true,
          "dynamic": false,
          "info": "Type of sender.",
          "title_case": false,
          "type": "str"
        },
        "sender_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "AI",
          "name": "sender_name",
          "display_name": "Sender Name",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Name of the sender.",
          "title_case": false,
          "type": "str"
        },
        "session_id": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "session_id",
          "display_name": "Session ID",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Session ID for the message.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Display a chat message in the Playground.",
      "icon": "ChatOutput",
      "base_classes": [
        "Message"
      ],
      "display_name": "Chat Output",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "message",
          "display_name": "Message",
          "method": "message_response",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "sender",
        "sender_name",
        "session_id",
        "data_template"
      ],
      "beta": false,
      "edited": false
    }
  },
  "helpers": {
    "CombineText": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "delimiter": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": " ",
          "name": "delimiter",
          "display_name": "Delimiter",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
          "title_case": false,
          "type": "str"
        },
        "text1": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "text1",
          "display_name": "First Text",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The first text input to concatenate.",
          "title_case": false,
          "type": "str"
        },
        "text2": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "text2",
          "display_name": "Second Text",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The second text input to concatenate.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
      "icon": "merge",
      "base_classes": [
        "Message"
      ],
      "display_name": "Combine Text",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "combined_text",
          "display_name": "Combined Text",
          "method": "combine_texts",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "text1",
        "text2",
        "delimiter"
      ],
      "beta": false,
      "edited": false
    },
    "ParseData": {
      "template": {
        "_type": "Component",
        "data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "data",
          "display_name": "Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "The data to convert to text.",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "sep": {
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "\n",
          "name": "sep",
          "display_name": "Separator",
          "advanced": true,
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        },
        "template": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "{text}",
          "name": "template",
          "display_name": "Template",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Convert Data into plain text following a specified template.",
      "icon": "braces",
      "base_classes": [
        "Message"
      ],
      "display_name": "Parse Data",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text",
          "display_name": "Text",
          "method": "parse_data",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "data",
        "template",
        "sep"
      ],
      "beta": false,
      "edited": false
    },
    "StoreMessage": {
      "template": {
        "_type": "CustomComponent",
        "message": {
          "type": "Message",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "message",
          "display_name": "Message",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.custom import CustomComponent\nfrom langflow.memory import get_messages, store_message\nfrom langflow.schema.message import Message\n\n\nclass StoreMessageComponent(CustomComponent):\n    display_name = \"Store Message\"\n    description = \"Stores a chat message.\"\n\n    def build_config(self):\n        return {\n            \"message\": {\"display_name\": \"Message\"},\n        }\n\n    def build(\n        self,\n        message: Message,\n    ) -> Message:\n        store_message(message, flow_id=self.graph.flow_id)\n        self.status = get_messages()\n\n        return message\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Stores a chat message.",
      "base_classes": [
        "Data",
        "Message"
      ],
      "display_name": "Store Message",
      "documentation": "",
      "custom_fields": {
        "message": null
      },
      "output_types": [
        "Message"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "message",
          "hidden": null,
          "display_name": "Message",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    },
    "Memory": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import get_messages\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages.\"\n    icon = \"message-square-more\"\n\n    inputs = [\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\", \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"Session ID of the chat history.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chat History\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        messages = get_messages(\n            sender=sender,\n            sender_name=sender_name,\n            session_id=session_id,\n            limit=n_messages,\n            order=order,\n        )\n        self.status = messages\n        return messages\n\n    def retrieve_messages_as_text(self) -> Message:\n        messages_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = messages_text\n        return Message(text=messages_text)\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "n_messages": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 100,
          "name": "n_messages",
          "display_name": "Number of Messages",
          "advanced": true,
          "dynamic": false,
          "info": "Number of messages to retrieve.",
          "title_case": false,
          "type": "int"
        },
        "order": {
          "trace_as_metadata": true,
          "options": [
            "Ascending",
            "Descending"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Ascending",
          "name": "order",
          "display_name": "Order",
          "advanced": true,
          "dynamic": false,
          "info": "Order of the messages.",
          "title_case": false,
          "type": "str"
        },
        "sender": {
          "trace_as_metadata": true,
          "options": [
            "Machine",
            "User",
            "Machine and User"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Machine and User",
          "name": "sender",
          "display_name": "Sender Type",
          "advanced": true,
          "dynamic": false,
          "info": "Type of sender.",
          "title_case": false,
          "type": "str"
        },
        "sender_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "sender_name",
          "display_name": "Sender Name",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Name of the sender.",
          "title_case": false,
          "type": "str"
        },
        "session_id": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "session_id",
          "display_name": "Session ID",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Session ID of the chat history.",
          "title_case": false,
          "type": "str"
        },
        "template": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "{sender_name}: {text}",
          "name": "template",
          "display_name": "Template",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Retrieves stored chat messages.",
      "icon": "message-square-more",
      "base_classes": [
        "Data",
        "Message"
      ],
      "display_name": "Chat Memory",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "messages",
          "display_name": "Chat History",
          "method": "retrieve_messages",
          "value": "__UNDEFINED__",
          "cache": true
        },
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "messages_text",
          "display_name": "Messages (Text)",
          "method": "retrieve_messages_as_text",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "sender",
        "sender_name",
        "n_messages",
        "session_id",
        "order",
        "template"
      ],
      "beta": false,
      "edited": false
    },
    "SplitText": {
      "template": {
        "_type": "Component",
        "data_inputs": {
          "trace_as_metadata": true,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "data_inputs",
          "display_name": "Data Inputs",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "The data to split.",
          "title_case": false,
          "type": "other"
        },
        "chunk_overlap": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 200,
          "name": "chunk_overlap",
          "display_name": "Chunk Overlap",
          "advanced": false,
          "dynamic": false,
          "info": "Number of characters to overlap between chunks.",
          "title_case": false,
          "type": "int"
        },
        "chunk_size": {
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": 1000,
          "name": "chunk_size",
          "display_name": "Chunk Size",
          "advanced": false,
          "dynamic": false,
          "info": "The maximum number of characters in each chunk.",
          "title_case": false,
          "type": "int"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        data = []\n        for doc in docs:\n            data.append(Data(text=doc.page_content, data=doc.metadata))\n        return data\n\n    def split_text(self) -> List[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = []\n        for _input in self.data_inputs:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "separator": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "\n",
          "name": "separator",
          "display_name": "Separator",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "The character to split on. Defaults to newline.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Split text into chunks based on specified criteria.",
      "icon": "scissors-line-dashed",
      "base_classes": [
        "Data"
      ],
      "display_name": "Split Text",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "chunks",
          "display_name": "Chunks",
          "method": "split_text",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "data_inputs",
        "chunk_overlap",
        "chunk_size",
        "separator"
      ],
      "beta": false,
      "edited": false
    },
    "MergeData": {
      "template": {
        "_type": "CustomComponent",
        "data": {
          "type": "Data",
          "required": true,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "data",
          "display_name": "Data",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.custom import CustomComponent\nfrom langflow.schema import Data\n\n\nclass MergeDataComponent(CustomComponent):\n    display_name = \"Merge Data\"\n    description = \"Combines multiple data sources into a single unified Data object.\"\n    beta: bool = True\n\n    field_config = {\n        \"data\": {\"display_name\": \"Data\"},\n    }\n\n    def build(self, data: list[Data]) -> Data:\n        if not data:\n            return Data()\n        if len(data) == 1:\n            return data[0]\n        merged_data = Data()\n        for value in data:\n            if merged_data is None:\n                merged_data = value\n            else:\n                merged_data += value\n        self.status = merged_data\n        return merged_data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Combines multiple data sources into a single unified Data object.",
      "base_classes": [
        "Data"
      ],
      "display_name": "Merge Data",
      "documentation": "",
      "custom_fields": {
        "data": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "data"
      ],
      "beta": true,
      "edited": false
    },
    "CustomComponent": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        data = Data(value=self.input_value)\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "Hello, World!",
          "name": "input_value",
          "display_name": "Input Value",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Use as a template to create your own component.",
      "icon": "custom_components",
      "base_classes": [],
      "display_name": "Custom Component",
      "documentation": "http://docs.langflow.org/components/custom",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [],
          "name": "output",
          "display_name": "Output",
          "method": "build_output",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value"
      ],
      "beta": false,
      "edited": false
    },
    "FilterData": {
      "template": {
        "_type": "Component",
        "data": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "data",
          "display_name": "Data",
          "advanced": false,
          "input_types": [
            "Data"
          ],
          "dynamic": false,
          "info": "Data object to filter.",
          "title_case": false,
          "type": "other"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import List\n\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, MessageTextInput, Output\nfrom langflow.schema import Data\n\n\nclass FilterDataComponent(Component):\n    display_name = \"Filter Data\"\n    description = \"Filters a Data object based on a list of keys.\"\n    icon = \"filter\"\n    beta = True\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"Data object to filter.\",\n        ),\n        MessageTextInput(\n            name=\"filter_criteria\",\n            display_name=\"Filter Criteria\",\n            info=\"List of keys to filter by.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def filter_data(self) -> Data:\n        filter_criteria: List[str] = self.filter_criteria\n        data = self.data.data if isinstance(self.data, Data) else {}\n\n        # Filter the data\n        filtered = {key: value for key, value in data.items() if key in filter_criteria}\n\n        # Create a new Data object with the filtered data\n        filtered_data = Data(data=filtered)\n        self.status = filtered_data\n        return filtered_data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "filter_criteria": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "filter_criteria",
          "display_name": "Filter Criteria",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "List of keys to filter by.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Filters a Data object based on a list of keys.",
      "icon": "filter",
      "base_classes": [
        "Data"
      ],
      "display_name": "Filter Data",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "filtered_data",
          "display_name": "Filtered Data",
          "method": "filter_data",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "data",
        "filter_criteria"
      ],
      "beta": true,
      "edited": false
    },
    "IDGenerator": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "import uuid\nfrom typing import Any, Optional\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema.dotdict import dotdict\n\n\nclass UUIDGeneratorComponent(CustomComponent):\n    display_name = \"ID Generator\"\n    description = \"Generates a unique ID.\"\n\n    def update_build_config(  # type: ignore\n        self, build_config: dotdict, field_value: Any, field_name: Optional[str] = None\n    ):\n        if field_name == \"unique_id\":\n            build_config[field_name][\"value\"] = str(uuid.uuid4())\n        return build_config\n\n    def build_config(self):\n        return {\n            \"unique_id\": {\n                \"display_name\": \"Value\",\n                \"refresh_button\": True,\n            }\n        }\n\n    def build(self, unique_id: str) -> str:\n        return unique_id\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "unique_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "unique_id",
          "display_name": "Value",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "refresh_button": true,
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Generates a unique ID.",
      "base_classes": [
        "object",
        "str",
        "Text"
      ],
      "display_name": "ID Generator",
      "documentation": "",
      "custom_fields": {
        "unique_id": null
      },
      "output_types": [
        "Text"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Text"
          ],
          "selected": "Text",
          "name": "text",
          "hidden": null,
          "display_name": "Text",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": false,
      "edited": false
    }
  },
  "memories": {
    "CassandraMessageReader": {
      "template": {
        "_type": "CustomComponent",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional, cast\n\nfrom langchain_community.chat_message_histories import CassandraChatMessageHistory\n\nfrom langflow.base.memory.memory import BaseMemoryComponent\nfrom langflow.schema.data import Data\n\n\nclass CassandraMessageReaderComponent(BaseMemoryComponent):\n    display_name = \"Cassandra Message Reader\"\n    description = \"Retrieves stored chat messages from a Cassandra table on Astra DB.\"\n\n    def build_config(self):\n        return {\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"database_id\": {\n                \"display_name\": \"Database ID\",\n                \"info\": \"The Astra database ID.\",\n            },\n            \"table_name\": {\n                \"display_name\": \"Table Name\",\n                \"info\": \"The name of the table where messages are stored.\",\n            },\n            \"token\": {\n                \"display_name\": \"Token\",\n                \"info\": \"Authentication token for accessing Cassandra on Astra DB.\",\n                \"password\": True,\n            },\n            \"keyspace\": {\n                \"display_name\": \"Keyspace\",\n                \"info\": \"Optional key space within Astra DB. The keyspace should already be created.\",\n                \"input_types\": [\"Text\"],\n                \"advanced\": True,\n            },\n        }\n\n    def get_messages(self, **kwargs) -> list[Data]:\n        \"\"\"\n        Retrieves messages from the CassandraChatMessageHistory memory.\n\n        Args:\n            memory (CassandraChatMessageHistory): The CassandraChatMessageHistory instance to retrieve messages from.\n\n        Returns:\n            list[Data]: A list of Data objects representing the search results.\n        \"\"\"\n        memory: CassandraChatMessageHistory = cast(CassandraChatMessageHistory, kwargs.get(\"memory\"))\n        if not memory:\n            raise ValueError(\"CassandraChatMessageHistory instance is required.\")\n\n        # Get messages from the memory\n        messages = memory.messages\n        results = [Data.from_lc_message(message) for message in messages]\n\n        return list(results)\n\n    def build(\n        self,\n        session_id: str,\n        table_name: str,\n        token: str,\n        database_id: str,\n        keyspace: Optional[str] = None,\n    ) -> list[Data]:\n        try:\n            import cassio\n        except ImportError:\n            raise ImportError(\n                \"Could not import cassio integration package. \" \"Please install it with `pip install cassio`.\"\n            )\n\n        cassio.init(token=token, database_id=database_id)\n        memory = CassandraChatMessageHistory(\n            session_id=session_id,\n            table_name=table_name,\n            keyspace=keyspace,\n        )\n\n        data = self.get_messages(memory=memory)\n        self.status = data\n\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "database_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "database_id",
          "display_name": "Database ID",
          "advanced": false,
          "dynamic": false,
          "info": "The Astra database ID.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "keyspace": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "keyspace",
          "display_name": "Keyspace",
          "advanced": true,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Optional key space within Astra DB. The keyspace should already be created.",
          "load_from_db": false,
          "title_case": false
        },
        "session_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "session_id",
          "display_name": "Session ID",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Session ID of the chat history.",
          "load_from_db": false,
          "title_case": false
        },
        "table_name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "table_name",
          "display_name": "Table Name",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the table where messages are stored.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "token": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "token",
          "display_name": "Token",
          "advanced": false,
          "dynamic": false,
          "info": "Authentication token for accessing Cassandra on Astra DB.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Retrieves stored chat messages from a Cassandra table on Astra DB.",
      "icon": "history",
      "base_classes": [
        "Data"
      ],
      "display_name": "Cassandra Message Reader",
      "documentation": "",
      "custom_fields": {
        "session_id": null,
        "table_name": null,
        "token": null,
        "database_id": null,
        "keyspace": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    },
    "CassandraMessageWriter": {
      "template": {
        "_type": "CustomComponent",
        "input_value": {
          "type": "Data",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input Data",
          "advanced": false,
          "dynamic": false,
          "info": "Data to write to Cassandra.",
          "load_from_db": false,
          "title_case": false
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain_community.chat_message_histories import CassandraChatMessageHistory\nfrom langchain_core.messages import BaseMessage\n\nfrom langflow.base.memory.memory import BaseMemoryComponent\nfrom langflow.schema.data import Data\n\n\nclass CassandraMessageWriterComponent(BaseMemoryComponent):\n    display_name = \"Cassandra Message Writer\"\n    description = \"Writes a message to a Cassandra table on Astra DB.\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Input Data\",\n                \"info\": \"Data to write to Cassandra.\",\n            },\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"database_id\": {\n                \"display_name\": \"Database ID\",\n                \"info\": \"The Astra database ID.\",\n            },\n            \"table_name\": {\n                \"display_name\": \"Table Name\",\n                \"info\": \"The name of the table where messages will be stored.\",\n            },\n            \"token\": {\n                \"display_name\": \"Token\",\n                \"info\": \"Authentication token for accessing Cassandra on Astra DB.\",\n                \"password\": True,\n            },\n            \"keyspace\": {\n                \"display_name\": \"Keyspace\",\n                \"info\": \"Optional key space within Astra DB. The keyspace should already be created.\",\n                \"input_types\": [\"Text\"],\n                \"advanced\": True,\n            },\n            \"ttl_seconds\": {\n                \"display_name\": \"TTL Seconds\",\n                \"info\": \"Optional time-to-live for the messages.\",\n                \"input_types\": [\"Number\"],\n                \"advanced\": True,\n            },\n        }\n\n    def add_message(\n        self,\n        sender: str,\n        sender_name: str,\n        text: str,\n        session_id: str,\n        metadata: Optional[dict] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Adds a message to the CassandraChatMessageHistory memory.\n\n        Args:\n            sender (str): The type of the message sender. Typically \"ai\" or \"human\".\n            sender_name (str): The name of the message sender.\n            text (str): The content of the message.\n            session_id (str): The session ID associated with the message.\n            metadata (dict | None, optional): Additional metadata for the message. Defaults to None.\n            **kwargs: Additional keyword arguments, including:\n                memory (CassandraChatMessageHistory | None): The memory instance to add the message to.\n\n\n        Raises:\n            ValueError: If the CassandraChatMessageHistory instance is not provided.\n\n        \"\"\"\n        memory: CassandraChatMessageHistory | None = kwargs.pop(\"memory\", None)\n        if memory is None:\n            raise ValueError(\"CassandraChatMessageHistory instance is required.\")\n\n        text_list = [\n            BaseMessage(\n                content=text,\n                sender=sender,\n                sender_name=sender_name,\n                metadata=metadata,\n                session_id=session_id,\n            )\n        ]\n\n        memory.add_messages(text_list)\n\n    def build(\n        self,\n        input_value: Data,\n        session_id: str,\n        table_name: str,\n        token: str,\n        database_id: str,\n        keyspace: Optional[str] = None,\n        ttl_seconds: Optional[int] = None,\n    ) -> Data:\n        try:\n            import cassio\n        except ImportError:\n            raise ImportError(\n                \"Could not import cassio integration package. \" \"Please install it with `pip install cassio`.\"\n            )\n\n        cassio.init(token=token, database_id=database_id)\n        memory = CassandraChatMessageHistory(\n            session_id=session_id,\n            table_name=table_name,\n            keyspace=keyspace,\n            ttl_seconds=ttl_seconds,\n        )\n\n        self.add_message(**input_value.data, memory=memory)\n        self.status = f\"Added message to Cassandra memory for session {session_id}\"\n\n        return input_value\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "database_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "database_id",
          "display_name": "Database ID",
          "advanced": false,
          "dynamic": false,
          "info": "The Astra database ID.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "keyspace": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "keyspace",
          "display_name": "Keyspace",
          "advanced": true,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Optional key space within Astra DB. The keyspace should already be created.",
          "load_from_db": false,
          "title_case": false
        },
        "session_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "session_id",
          "display_name": "Session ID",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Session ID of the chat history.",
          "load_from_db": false,
          "title_case": false
        },
        "table_name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "table_name",
          "display_name": "Table Name",
          "advanced": false,
          "dynamic": false,
          "info": "The name of the table where messages will be stored.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "token": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "token",
          "display_name": "Token",
          "advanced": false,
          "dynamic": false,
          "info": "Authentication token for accessing Cassandra on Astra DB.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "ttl_seconds": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "ttl_seconds",
          "display_name": "TTL Seconds",
          "advanced": true,
          "input_types": [
            "Number"
          ],
          "dynamic": false,
          "info": "Optional time-to-live for the messages.",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Writes a message to a Cassandra table on Astra DB.",
      "icon": "history",
      "base_classes": [
        "Data"
      ],
      "display_name": "Cassandra Message Writer",
      "documentation": "",
      "custom_fields": {
        "input_value": null,
        "session_id": null,
        "table_name": null,
        "token": null,
        "database_id": null,
        "keyspace": null,
        "ttl_seconds": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    },
    "ZepMessageReader": {
      "template": {
        "_type": "CustomComponent",
        "api_key": {
          "type": "Text",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "api_key",
          "display_name": "Zep API Key",
          "advanced": false,
          "dynamic": false,
          "info": "API Key for the Zep instance.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "query": {
          "type": "Text",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "query",
          "display_name": "Query",
          "advanced": false,
          "dynamic": false,
          "info": "Query to search for in the chat history.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "session_id": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "session_id",
          "display_name": "Session ID",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Session ID of the chat history.",
          "load_from_db": false,
          "title_case": false
        },
        "url": {
          "type": "Text",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "url",
          "display_name": "Zep URL",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "URL of the Zep instance.",
          "load_from_db": false,
          "title_case": false
        },
        "api_base_path": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "value": "api/v1",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [
            "api/v1",
            "api/v2"
          ],
          "name": "api_base_path",
          "display_name": "API Base Path",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional, cast\n\nfrom langchain_community.chat_message_histories.zep import SearchScope, SearchType, ZepChatMessageHistory\n\nfrom langflow.base.memory.memory import BaseMemoryComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Data\n\n\nclass ZepMessageReaderComponent(BaseMemoryComponent):\n    display_name = \"Zep Message Reader\"\n    description = \"Retrieves stored chat messages from Zep.\"\n\n    def build_config(self):\n        return {\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"url\": {\n                \"display_name\": \"Zep URL\",\n                \"info\": \"URL of the Zep instance.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"api_key\": {\n                \"display_name\": \"Zep API Key\",\n                \"info\": \"API Key for the Zep instance.\",\n                \"password\": True,\n            },\n            \"query\": {\n                \"display_name\": \"Query\",\n                \"info\": \"Query to search for in the chat history.\",\n            },\n            \"metadata\": {\n                \"display_name\": \"Metadata\",\n                \"info\": \"Optional metadata to attach to the message.\",\n                \"advanced\": True,\n            },\n            \"search_scope\": {\n                \"options\": [\"Messages\", \"Summary\"],\n                \"display_name\": \"Search Scope\",\n                \"info\": \"Scope of the search.\",\n                \"advanced\": True,\n            },\n            \"search_type\": {\n                \"options\": [\"Similarity\", \"MMR\"],\n                \"display_name\": \"Search Type\",\n                \"info\": \"Type of search.\",\n                \"advanced\": True,\n            },\n            \"limit\": {\n                \"display_name\": \"Limit\",\n                \"info\": \"Limit of search results.\",\n                \"advanced\": True,\n            },\n            \"api_base_path\": {\n                \"display_name\": \"API Base Path\",\n                \"options\": [\"api/v1\", \"api/v2\"],\n            },\n        }\n\n    def get_messages(self, **kwargs) -> list[Data]:\n        \"\"\"\n        Retrieves messages from the ZepChatMessageHistory memory.\n\n        If a query is provided, the search method is used to search for messages in the memory, otherwise all messages are returned.\n\n        Args:\n            memory (ZepChatMessageHistory): The ZepChatMessageHistory instance to retrieve messages from.\n            query (str, optional): The query string to search for messages. Defaults to None.\n            metadata (dict, optional): Additional metadata to filter the search results. Defaults to None.\n            search_scope (str, optional): The scope of the search. Can be 'messages' or 'summary'. Defaults to 'messages'.\n            search_type (str, optional): The type of search. Can be 'similarity' or 'exact'. Defaults to 'similarity'.\n            limit (int, optional): The maximum number of search results to return. Defaults to None.\n\n        Returns:\n            list[Data]: A list of Data objects representing the search results.\n        \"\"\"\n        memory: ZepChatMessageHistory = cast(ZepChatMessageHistory, kwargs.get(\"memory\"))\n        if not memory:\n            raise ValueError(\"ZepChatMessageHistory instance is required.\")\n        query = kwargs.get(\"query\")\n        search_scope = kwargs.get(\"search_scope\", SearchScope.messages).lower()\n        search_type = kwargs.get(\"search_type\", SearchType.similarity).lower()\n        limit = kwargs.get(\"limit\")\n\n        if query:\n            memory_search_results = memory.search(\n                query,\n                search_scope=search_scope,\n                search_type=search_type,\n                limit=limit,\n            )\n            # Get the messages from the search results if the search scope is messages\n            result_dicts = []\n            for result in memory_search_results:\n                result_dict = {}\n                if search_scope == SearchScope.messages:\n                    result_dict[\"text\"] = result.message\n                else:\n                    result_dict[\"text\"] = result.summary\n                result_dict[\"metadata\"] = result.metadata\n                result_dict[\"score\"] = result.score\n                result_dicts.append(result_dict)\n            results = [Data(data=result_dict) for result_dict in result_dicts]\n        else:\n            messages = memory.messages\n            results = [Data.from_lc_message(message) for message in messages]\n        return results\n\n    def build(\n        self,\n        session_id: Text,\n        api_base_path: str = \"api/v1\",\n        url: Optional[Text] = None,\n        api_key: Optional[Text] = None,\n        query: Optional[Text] = None,\n        search_scope: str = SearchScope.messages,\n        search_type: str = SearchType.similarity,\n        limit: Optional[int] = None,\n    ) -> list[Data]:\n        try:\n            # Monkeypatch API_BASE_PATH to\n            # avoid 404\n            # This is a workaround for the local Zep instance\n            # cloud Zep works with v2\n            import zep_python.zep_client\n            from zep_python import ZepClient\n            from zep_python.langchain import ZepChatMessageHistory\n\n            zep_python.zep_client.API_BASE_PATH = api_base_path\n        except ImportError:\n            raise ImportError(\n                \"Could not import zep-python package. \" \"Please install it with `pip install zep-python`.\"\n            )\n        if url == \"\":\n            url = None\n\n        zep_client = ZepClient(api_url=url, api_key=api_key)\n        memory = ZepChatMessageHistory(session_id=session_id, zep_client=zep_client)\n        data = self.get_messages(\n            memory=memory,\n            query=query,\n            search_scope=search_scope,\n            search_type=search_type,\n            limit=limit,\n        )\n        self.status = data\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "limit": {
          "type": "int",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "limit",
          "display_name": "Limit",
          "advanced": true,
          "dynamic": false,
          "info": "Limit of search results.",
          "load_from_db": false,
          "title_case": false
        },
        "search_scope": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "value": "SearchScope.messages",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [
            "Messages",
            "Summary"
          ],
          "name": "search_scope",
          "display_name": "Search Scope",
          "advanced": true,
          "dynamic": false,
          "info": "Scope of the search.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "search_type": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "value": "SearchType.similarity",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [
            "Similarity",
            "MMR"
          ],
          "name": "search_type",
          "display_name": "Search Type",
          "advanced": true,
          "dynamic": false,
          "info": "Type of search.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Retrieves stored chat messages from Zep.",
      "icon": "history",
      "base_classes": [
        "Data"
      ],
      "display_name": "Zep Message Reader",
      "documentation": "",
      "custom_fields": {
        "session_id": null,
        "api_base_path": null,
        "url": null,
        "api_key": null,
        "query": null,
        "search_scope": null,
        "search_type": null,
        "limit": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    },
    "ZepMessageWriter": {
      "template": {
        "_type": "CustomComponent",
        "api_key": {
          "type": "Text",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "api_key",
          "display_name": "Zep API Key",
          "advanced": false,
          "dynamic": false,
          "info": "API Key for the Zep instance.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "input_value": {
          "type": "Data",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input Data",
          "advanced": false,
          "dynamic": false,
          "info": "Data to write to Zep.",
          "load_from_db": false,
          "title_case": false
        },
        "session_id": {
          "type": "Text",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "session_id",
          "display_name": "Session ID",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Session ID of the chat history.",
          "load_from_db": false,
          "title_case": false
        },
        "url": {
          "type": "Text",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "url",
          "display_name": "Zep URL",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "URL of the Zep instance.",
          "load_from_db": false,
          "title_case": false
        },
        "api_base_path": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": true,
          "show": true,
          "multiline": false,
          "value": "api/v1",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "options": [
            "api/v1",
            "api/v2"
          ],
          "name": "api_base_path",
          "display_name": "API Base Path",
          "advanced": false,
          "dynamic": false,
          "info": "",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import TYPE_CHECKING, Optional\n\nfrom langflow.base.memory.memory import BaseMemoryComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Data\n\nif TYPE_CHECKING:\n    from zep_python.langchain import ZepChatMessageHistory\n\n\nclass ZepMessageWriterComponent(BaseMemoryComponent):\n    display_name = \"Zep Message Writer\"\n    description = \"Writes a message to Zep.\"\n\n    def build_config(self):\n        return {\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"url\": {\n                \"display_name\": \"Zep URL\",\n                \"info\": \"URL of the Zep instance.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"api_key\": {\n                \"display_name\": \"Zep API Key\",\n                \"info\": \"API Key for the Zep instance.\",\n                \"password\": True,\n            },\n            \"limit\": {\n                \"display_name\": \"Limit\",\n                \"info\": \"Limit of search results.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\n                \"display_name\": \"Input Data\",\n                \"info\": \"Data to write to Zep.\",\n            },\n            \"api_base_path\": {\n                \"display_name\": \"API Base Path\",\n                \"options\": [\"api/v1\", \"api/v2\"],\n            },\n        }\n\n    def add_message(\n        self, sender: Text, sender_name: Text, text: Text, session_id: Text, metadata: dict | None = None, **kwargs\n    ):\n        \"\"\"\n        Adds a message to the ZepChatMessageHistory memory.\n\n        Args:\n            sender (Text): The type of the message sender. Valid values are \"Machine\" or \"User\".\n            sender_name (Text): The name of the message sender.\n            text (Text): The content of the message.\n            session_id (Text): The session ID associated with the message.\n            metadata (dict | None, optional): Additional metadata for the message. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Raises:\n            ValueError: If the ZepChatMessageHistory instance is not provided.\n\n        \"\"\"\n        memory: ZepChatMessageHistory | None = kwargs.pop(\"memory\", None)\n        if memory is None:\n            raise ValueError(\"ZepChatMessageHistory instance is required.\")\n        if metadata is None:\n            metadata = {}\n        metadata[\"sender_name\"] = sender_name\n        metadata.update(kwargs)\n        if sender == \"Machine\":\n            memory.add_ai_message(text, metadata=metadata)\n        elif sender == \"User\":\n            memory.add_user_message(text, metadata=metadata)\n        else:\n            raise ValueError(f\"Invalid sender type: {sender}\")\n\n    def build(\n        self,\n        input_value: Data,\n        session_id: Text,\n        api_base_path: str = \"api/v1\",\n        url: Optional[Text] = None,\n        api_key: Optional[Text] = None,\n    ) -> Data:\n        try:\n            # Monkeypatch API_BASE_PATH to\n            # avoid 404\n            # This is a workaround for the local Zep instance\n            # cloud Zep works with v2\n            import zep_python.zep_client\n            from zep_python import ZepClient\n            from zep_python.langchain import ZepChatMessageHistory\n\n            zep_python.zep_client.API_BASE_PATH = api_base_path\n        except ImportError:\n            raise ImportError(\n                \"Could not import zep-python package. \" \"Please install it with `pip install zep-python`.\"\n            )\n        if url == \"\":\n            url = None\n\n        zep_client = ZepClient(api_url=url, api_key=api_key)\n        memory = ZepChatMessageHistory(session_id=session_id, zep_client=zep_client)\n        self.add_message(**input_value.data, memory=memory)\n        self.status = f\"Added message to Zep memory for session {session_id}\"\n        return input_value\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        }
      },
      "description": "Writes a message to Zep.",
      "icon": "history",
      "base_classes": [
        "Data"
      ],
      "display_name": "Zep Message Writer",
      "documentation": "",
      "custom_fields": {
        "input_value": null,
        "session_id": null,
        "api_base_path": null,
        "url": null,
        "api_key": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    },
    "AstraDBMessageReader": {
      "template": {
        "_type": "CustomComponent",
        "api_endpoint": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "api_endpoint",
          "display_name": "Astra DB API Endpoint",
          "advanced": false,
          "dynamic": false,
          "info": "API Endpoint for the Astra DB instance.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional, cast\n\nfrom langflow.base.memory.memory import BaseMemoryComponent\nfrom langflow.schema import Data\n\n\nclass AstraDBMessageReaderComponent(BaseMemoryComponent):\n    display_name = \"Astra DB Message Reader\"\n    description = \"Retrieves stored chat messages from Astra DB.\"\n\n    def build_config(self):\n        return {\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"collection_name\": {\n                \"display_name\": \"Collection Name\",\n                \"info\": \"Collection name for Astra DB.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"token\": {\n                \"display_name\": \"Astra DB Application Token\",\n                \"info\": \"Token for the Astra DB instance.\",\n                \"password\": True,\n            },\n            \"api_endpoint\": {\n                \"display_name\": \"Astra DB API Endpoint\",\n                \"info\": \"API Endpoint for the Astra DB instance.\",\n                \"password\": True,\n            },\n            \"namespace\": {\n                \"display_name\": \"Namespace\",\n                \"info\": \"Namespace for the Astra DB instance.\",\n                \"input_types\": [\"Text\"],\n                \"advanced\": True,\n            },\n        }\n\n    def get_messages(self, **kwargs) -> list[Data]:\n        \"\"\"\n        Retrieves messages from the AstraDBChatMessageHistory memory.\n\n        Args:\n            memory (AstraDBChatMessageHistory): The AstraDBChatMessageHistory instance to retrieve messages from.\n\n        Returns:\n            list[Data]: A list of Data objects representing the search results.\n        \"\"\"\n        try:\n            from langchain_astradb.chat_message_histories import AstraDBChatMessageHistory\n        except ImportError:\n            raise ImportError(\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n\n        memory: AstraDBChatMessageHistory = cast(AstraDBChatMessageHistory, kwargs.get(\"memory\"))\n        if not memory:\n            raise ValueError(\"AstraDBChatMessageHistory instance is required.\")\n\n        # Get messages from the memory\n        messages = memory.messages\n        results = [Data.from_lc_message(message) for message in messages]\n\n        return list(results)\n\n    def build(\n        self,\n        session_id: str,\n        collection_name: str,\n        token: str,\n        api_endpoint: str,\n        namespace: Optional[str] = None,\n    ) -> list[Data]:\n        try:\n            from langchain_astradb.chat_message_histories import AstraDBChatMessageHistory\n        except ImportError:\n            raise ImportError(\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n\n        memory = AstraDBChatMessageHistory(\n            session_id=session_id,\n            collection_name=collection_name,\n            token=token,\n            api_endpoint=api_endpoint,\n            namespace=namespace,\n        )\n\n        data = self.get_messages(memory=memory)\n        self.status = data\n\n        return data\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "collection_name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "collection_name",
          "display_name": "Collection Name",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Collection name for Astra DB.",
          "load_from_db": false,
          "title_case": false
        },
        "namespace": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "namespace",
          "display_name": "Namespace",
          "advanced": true,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Namespace for the Astra DB instance.",
          "load_from_db": false,
          "title_case": false
        },
        "session_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "session_id",
          "display_name": "Session ID",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Session ID of the chat history.",
          "load_from_db": false,
          "title_case": false
        },
        "token": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "token",
          "display_name": "Astra DB Application Token",
          "advanced": false,
          "dynamic": false,
          "info": "Token for the Astra DB instance.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Retrieves stored chat messages from Astra DB.",
      "icon": "history",
      "base_classes": [
        "Data"
      ],
      "display_name": "Astra DB Message Reader",
      "documentation": "",
      "custom_fields": {
        "session_id": null,
        "collection_name": null,
        "token": null,
        "api_endpoint": null,
        "namespace": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    },
    "AstraDBMessageWriter": {
      "template": {
        "_type": "CustomComponent",
        "input_value": {
          "type": "Data",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "input_value",
          "display_name": "Input Data",
          "advanced": false,
          "dynamic": false,
          "info": "Data to write to Astra DB.",
          "load_from_db": false,
          "title_case": false
        },
        "api_endpoint": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "api_endpoint",
          "display_name": "Astra DB API Endpoint",
          "advanced": false,
          "dynamic": false,
          "info": "API Endpoint for the Astra DB instance.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from typing import Optional\n\nfrom langchain_core.messages import BaseMessage\n\nfrom langflow.base.memory.memory import BaseMemoryComponent\nfrom langflow.schema import Data\n\n\nclass AstraDBMessageWriterComponent(BaseMemoryComponent):\n    display_name = \"Astra DB Message Writer\"\n    description = \"Writes a message to Astra DB.\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Input Data\",\n                \"info\": \"Data to write to Astra DB.\",\n            },\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"collection_name\": {\n                \"display_name\": \"Collection Name\",\n                \"info\": \"Collection name for Astra DB.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"token\": {\n                \"display_name\": \"Astra DB Application Token\",\n                \"info\": \"Token for the Astra DB instance.\",\n                \"password\": True,\n            },\n            \"api_endpoint\": {\n                \"display_name\": \"Astra DB API Endpoint\",\n                \"info\": \"API Endpoint for the Astra DB instance.\",\n                \"password\": True,\n            },\n            \"namespace\": {\n                \"display_name\": \"Namespace\",\n                \"info\": \"Namespace for the Astra DB instance.\",\n                \"input_types\": [\"Text\"],\n                \"advanced\": True,\n            },\n        }\n\n    def add_message(\n        self,\n        sender: str,\n        sender_name: str,\n        text: str,\n        session_id: str,\n        metadata: Optional[dict] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Adds a message to the AstraDBChatMessageHistory memory.\n\n        Args:\n            sender (str): The type of the message sender. Typically \"ai\" or \"human\".\n            sender_name (str): The name of the message sender.\n            text (str): The content of the message.\n            session_id (str): The session ID associated with the message.\n            metadata (dict | None, optional): Additional metadata for the message. Defaults to None.\n            **kwargs: Additional keyword arguments, including:\n                memory (AstraDBChatMessageHistory | None): The memory instance to add the message to.\n\n\n        Raises:\n            ValueError: If the AstraDBChatMessageHistory instance is not provided.\n\n        \"\"\"\n        try:\n            from langchain_astradb.chat_message_histories import AstraDBChatMessageHistory\n        except ImportError:\n            raise ImportError(\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n\n        memory: AstraDBChatMessageHistory | None = kwargs.pop(\"memory\", None)\n        if memory is None:\n            raise ValueError(\"AstraDBChatMessageHistory instance is required.\")\n\n        text_list = [\n            BaseMessage(\n                content=text,\n                sender=sender,\n                sender_name=sender_name,\n                metadata=metadata,\n                session_id=session_id,\n                type=sender,\n            )\n        ]\n\n        memory.add_messages(text_list)\n\n    def build(\n        self,\n        input_value: Data,\n        session_id: str,\n        collection_name: str,\n        token: str,\n        api_endpoint: str,\n        namespace: Optional[str] = None,\n    ) -> Data:\n        try:\n            from langchain_astradb.chat_message_histories import AstraDBChatMessageHistory\n        except ImportError:\n            raise ImportError(\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n\n        memory = AstraDBChatMessageHistory(\n            session_id=session_id,\n            collection_name=collection_name,\n            token=token,\n            api_endpoint=api_endpoint,\n            namespace=namespace,\n        )\n\n        self.add_message(**input_value.data, memory=memory)\n        self.status = f\"Added message to Astra DB memory for session {session_id}\"\n\n        return input_value\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "collection_name": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "collection_name",
          "display_name": "Collection Name",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Collection name for Astra DB.",
          "load_from_db": false,
          "title_case": false
        },
        "namespace": {
          "type": "str",
          "required": false,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "namespace",
          "display_name": "Namespace",
          "advanced": true,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Namespace for the Astra DB instance.",
          "load_from_db": false,
          "title_case": false
        },
        "session_id": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "session_id",
          "display_name": "Session ID",
          "advanced": false,
          "input_types": [
            "Text"
          ],
          "dynamic": false,
          "info": "Session ID of the chat history.",
          "load_from_db": false,
          "title_case": false
        },
        "token": {
          "type": "str",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": false,
          "fileTypes": [],
          "file_path": "",
          "password": true,
          "name": "token",
          "display_name": "Astra DB Application Token",
          "advanced": false,
          "dynamic": false,
          "info": "Token for the Astra DB instance.",
          "load_from_db": false,
          "title_case": false,
          "input_types": [
            "Text"
          ]
        }
      },
      "description": "Writes a message to Astra DB.",
      "icon": "history",
      "base_classes": [
        "Data"
      ],
      "display_name": "Astra DB Message Writer",
      "documentation": "",
      "custom_fields": {
        "input_value": null,
        "session_id": null,
        "collection_name": null,
        "token": null,
        "api_endpoint": null,
        "namespace": null
      },
      "output_types": [
        "Data"
      ],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Data"
          ],
          "selected": "Data",
          "name": "data",
          "hidden": null,
          "display_name": "Data",
          "method": null,
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [],
      "beta": true,
      "edited": false
    }
  },
  "inputs": {
    "TextInput": {
      "template": {
        "_type": "Component",
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Text",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Text to be passed as input.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Get text inputs from the Playground.",
      "icon": "type",
      "base_classes": [
        "Message"
      ],
      "display_name": "Text Input",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "text",
          "display_name": "Text",
          "method": "text_response",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value"
      ],
      "beta": false,
      "edited": false
    },
    "ChatInput": {
      "template": {
        "_type": "Component",
        "files": {
          "trace_as_metadata": true,
          "file_path": "",
          "fileTypes": [
            "txt",
            "md",
            "mdx",
            "csv",
            "json",
            "yaml",
            "yml",
            "xml",
            "html",
            "htm",
            "pdf",
            "docx",
            "py",
            "sh",
            "sql",
            "js",
            "ts",
            "tsx",
            "jpg",
            "jpeg",
            "png",
            "bmp",
            "image"
          ],
          "list": true,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "files",
          "display_name": "Files",
          "advanced": true,
          "dynamic": false,
          "info": "Files to be sent with the message.",
          "title_case": false,
          "type": "file"
        },
        "code": {
          "type": "code",
          "required": true,
          "placeholder": "",
          "list": false,
          "show": true,
          "multiline": true,
          "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n",
          "fileTypes": [],
          "file_path": "",
          "password": false,
          "name": "code",
          "advanced": true,
          "dynamic": true,
          "info": "",
          "load_from_db": false,
          "title_case": false
        },
        "input_value": {
          "trace_as_input": true,
          "multiline": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "input_value",
          "display_name": "Text",
          "advanced": false,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Message to be passed as input.",
          "title_case": false,
          "type": "str"
        },
        "sender": {
          "trace_as_metadata": true,
          "options": [
            "Machine",
            "User"
          ],
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "User",
          "name": "sender",
          "display_name": "Sender Type",
          "advanced": true,
          "dynamic": false,
          "info": "Type of sender.",
          "title_case": false,
          "type": "str"
        },
        "sender_name": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "User",
          "name": "sender_name",
          "display_name": "Sender Name",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Name of the sender.",
          "title_case": false,
          "type": "str"
        },
        "session_id": {
          "trace_as_input": true,
          "trace_as_metadata": true,
          "load_from_db": false,
          "list": false,
          "required": false,
          "placeholder": "",
          "show": true,
          "value": "",
          "name": "session_id",
          "display_name": "Session ID",
          "advanced": true,
          "input_types": [
            "Message"
          ],
          "dynamic": false,
          "info": "Session ID for the message.",
          "title_case": false,
          "type": "str"
        }
      },
      "description": "Get chat inputs from the Playground.",
      "icon": "ChatInput",
      "base_classes": [
        "Message"
      ],
      "display_name": "Chat Input",
      "documentation": "",
      "custom_fields": {},
      "output_types": [],
      "pinned": false,
      "conditional_paths": [],
      "frozen": false,
      "outputs": [
        {
          "types": [
            "Message"
          ],
          "selected": "Message",
          "name": "message",
          "display_name": "Message",
          "method": "message_response",
          "value": "__UNDEFINED__",
          "cache": true
        }
      ],
      "field_order": [
        "input_value",
        "sender",
        "sender_name",
        "session_id",
        "files"
      ],
      "beta": false,
      "edited": false
    }
  }
}