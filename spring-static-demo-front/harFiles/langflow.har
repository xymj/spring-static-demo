{
  "log": {
    "version": "1.2",
    "creator": {
      "name": "Playwright",
      "version": "1.42.0"
    },
    "browser": {
      "name": "chromium",
      "version": "123.0.6312.4"
    },
    "entries": [
      {
        "startedDateTime": "2024-02-28T14:32:30.858Z",
        "time": 0.77,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/version",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "19"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:30 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"version\":\"0.6.7\"}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.77
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:30.859Z",
        "time": 0.894,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/auto_login",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "227"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:30 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            },
            {
              "name": "set-cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc; Path=/; SameSite=none; Secure"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"access_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc\",\"refresh_token\":null,\"token_type\":\"bearer\"}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.894
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:30.937Z",
        "time": 0.944,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/users/whoami",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "253"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:30 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"id\":\"0389fb29-daa6-408c-b8cb-b8ff8d17343a\",\"username\":\"langflow\",\"profile_image\":null,\"is_active\":true,\"is_superuser\":true,\"create_at\":\"2024-02-28T14:31:41.362911\",\"updated_at\":\"2024-02-28T14:32:30.864882\",\"last_login_at\":\"2024-02-28T14:32:30.863748\"}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.944
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:30.976Z",
        "time": 0.697,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/version",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "19"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:30 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"version\":\"0.6.7\"}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.697
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:30.976Z",
        "time": 2.771,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/all",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "633593"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:30 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"chains\":{\"ConversationalRetrievalChain\":{\"template\":{\"callbacks\":{\"type\":\"Callbacks\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"condense_question_llm\":{\"type\":\"BaseLanguageModel\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"condense_question_llm\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"condense_question_prompt\":{\"type\":\"BasePromptTemplate\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":{\"name\":null,\"input_variables\":[\"chat_history\",\"question\"],\"input_types\":{},\"output_parser\":null,\"partial_variables\":{},\"metadata\":null,\"tags\":null,\"template\":\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:\",\"template_format\":\"f-string\",\"validate_template\":false},\"fileTypes\":[],\"password\":false,\"name\":\"condense_question_prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"llm\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory\":{\"type\":\"BaseChatMemory\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"retriever\":{\"type\":\"BaseRetriever\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"retriever\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chain_type\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"stuff\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"stuff\",\"map_reduce\",\"map_rerank\",\"refine\"],\"name\":\"chain_type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"combine_docs_chain_kwargs\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"combine_docs_chain_kwargs\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"return_source_documents\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_source_documents\",\"display_name\":\"Return source documents\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"verbose\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"password\":false,\"name\":\"verbose\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"ConversationalRetrievalChain\"},\"description\":\"Convenience method to load chain from LLM and retriever.\",\"base_classes\":[\"BaseConversationalRetrievalChain\",\"Runnable\",\"Chain\",\"Generic\",\"Text\",\"RunnableSerializable\",\"Serializable\",\"object\",\"ConversationalRetrievalChain\",\"Callable\"],\"display_name\":\"ConversationalRetrievalChain\",\"documentation\":\"https://python.langchain.com/docs/modules/chains/popular/chat_vector_db\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false,\"output_type\":\"Chain\"},\"LLMCheckerChain\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Union\\n\\nfrom langchain.chains import LLMCheckerChain\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, Chain\\n\\n\\nclass LLMCheckerChainComponent(CustomComponent):\\n    display_name = \\\"LLMCheckerChain\\\"\\n    description = \\\"\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/chains/additional/llm_checker\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        llm: BaseLanguageModel,\\n    ) -> Union[Chain, Callable]:\\n        return LLMCheckerChain.from_llm(llm=llm)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"Chain\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"Callable\"],\"display_name\":\"LLMCheckerChain\",\"documentation\":\"https://python.langchain.com/docs/modules/chains/additional/llm_checker\",\"custom_fields\":{\"llm\":null},\"output_types\":[\"Chain\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"LLMMathChain\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"llm_chain\":{\"type\":\"LLMChain\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm_chain\",\"display_name\":\"LLM Chain\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory\":{\"type\":\"BaseMemory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"display_name\":\"Memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Optional, Union\\n\\nfrom langchain.chains import LLMChain, LLMMathChain\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, BaseMemory, Chain\\n\\n\\nclass LLMMathChainComponent(CustomComponent):\\n    display_name = \\\"LLMMathChain\\\"\\n    description = \\\"Chain that interprets a prompt and executes python code to do math.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/chains/additional/llm_math\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"llm_chain\\\": {\\\"display_name\\\": \\\"LLM Chain\\\"},\\n            \\\"memory\\\": {\\\"display_name\\\": \\\"Memory\\\"},\\n            \\\"input_key\\\": {\\\"display_name\\\": \\\"Input Key\\\"},\\n            \\\"output_key\\\": {\\\"display_name\\\": \\\"Output Key\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        llm: BaseLanguageModel,\\n        llm_chain: LLMChain,\\n        input_key: str = \\\"question\\\",\\n        output_key: str = \\\"answer\\\",\\n        memory: Optional[BaseMemory] = None,\\n    ) -> Union[LLMMathChain, Callable, Chain]:\\n        return LLMMathChain(llm=llm, llm_chain=llm_chain, input_key=input_key, output_key=output_key, memory=memory)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"input_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"question\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"display_name\":\"Input Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"output_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"answer\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"output_key\",\"display_name\":\"Output Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Chain that interprets a prompt and executes python code to do math.\",\"base_classes\":[\"LLMMathChain\",\"Runnable\",\"Chain\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"Callable\"],\"display_name\":\"LLMMathChain\",\"documentation\":\"https://python.langchain.com/docs/modules/chains/additional/llm_math\",\"custom_fields\":{\"llm\":null,\"llm_chain\":null,\"input_key\":null,\"output_key\":null,\"memory\":null},\"output_types\":[\"LLMMathChain\",\"Callable\",\"Chain\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"RetrievalQA\":{\"template\":{\"combine_documents_chain\":{\"type\":\"BaseCombineDocumentsChain\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"combine_documents_chain\",\"display_name\":\"Combine Documents Chain\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory\":{\"type\":\"BaseMemory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"display_name\":\"Memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"retriever\":{\"type\":\"BaseRetriever\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"retriever\",\"display_name\":\"Retriever\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Optional, Union\\n\\nfrom langchain.chains.combine_documents.base import BaseCombineDocumentsChain\\nfrom langchain.chains.retrieval_qa.base import BaseRetrievalQA, RetrievalQA\\nfrom langchain_core.documents import Document\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseMemory, BaseRetriever, Text\\n\\n\\nclass RetrievalQAComponent(CustomComponent):\\n    display_name = \\\"Retrieval QA\\\"\\n    description = \\\"Chain for question-answering against an index.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"combine_documents_chain\\\": {\\\"display_name\\\": \\\"Combine Documents Chain\\\"},\\n            \\\"retriever\\\": {\\\"display_name\\\": \\\"Retriever\\\"},\\n            \\\"memory\\\": {\\\"display_name\\\": \\\"Memory\\\", \\\"required\\\": False},\\n            \\\"input_key\\\": {\\\"display_name\\\": \\\"Input Key\\\", \\\"advanced\\\": True},\\n            \\\"output_key\\\": {\\\"display_name\\\": \\\"Output Key\\\", \\\"advanced\\\": True},\\n            \\\"return_source_documents\\\": {\\\"display_name\\\": \\\"Return Source Documents\\\"},\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\", \\\"input_types\\\": [\\\"Text\\\", \\\"Document\\\"]},\\n        }\\n\\n    def build(\\n        self,\\n        combine_documents_chain: BaseCombineDocumentsChain,\\n        retriever: BaseRetriever,\\n        inputs: str = \\\"\\\",\\n        memory: Optional[BaseMemory] = None,\\n        input_key: str = \\\"query\\\",\\n        output_key: str = \\\"result\\\",\\n        return_source_documents: bool = True,\\n    ) -> Union[BaseRetrievalQA, Callable, Text]:\\n        runnable = RetrievalQA(\\n            combine_documents_chain=combine_documents_chain,\\n            retriever=retriever,\\n            memory=memory,\\n            input_key=input_key,\\n            output_key=output_key,\\n            return_source_documents=return_source_documents,\\n        )\\n        if isinstance(inputs, Document):\\n            inputs = inputs.page_content\\n        self.status = runnable\\n        result = runnable.invoke({input_key: inputs})\\n        result = result.content if hasattr(result, \\\"content\\\") else result\\n        # Result is a dict with keys \\\"query\\\",  \\\"result\\\" and \\\"source_documents\\\"\\n        # for now we just return the result\\n        records = self.to_records(result.get(\\\"source_documents\\\"))\\n        references_str = \\\"\\\"\\n        if return_source_documents:\\n            references_str = self.create_references_from_records(records)\\n        result_str = result.get(\\\"result\\\")\\n        final_result = \\\"\\\\n\\\".join([result_str, references_str])\\n        self.status = final_result\\n        return final_result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"input_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"query\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"display_name\":\"Input Key\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"input_types\":[\"Text\",\"Document\",\"Text\"],\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"output_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"result\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"output_key\",\"display_name\":\"Output Key\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_source_documents\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_source_documents\",\"display_name\":\"Return Source Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Chain for question-answering against an index.\",\"base_classes\":[\"Runnable\",\"Chain\",\"BaseRetrievalQA\",\"Generic\",\"Text\",\"RunnableSerializable\",\"Serializable\",\"object\",\"Callable\"],\"display_name\":\"Retrieval QA\",\"documentation\":\"\",\"custom_fields\":{\"combine_documents_chain\":null,\"retriever\":null,\"inputs\":null,\"memory\":null,\"input_key\":null,\"output_key\":null,\"return_source_documents\":null},\"output_types\":[\"BaseRetrievalQA\",\"Callable\",\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"RetrievalQAWithSourcesChain\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory\":{\"type\":\"BaseMemory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"display_name\":\"Memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"retriever\":{\"type\":\"BaseRetriever\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"retriever\",\"display_name\":\"Retriever\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chain_type\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"stuff\",\"map_reduce\",\"map_rerank\",\"refine\"],\"name\":\"chain_type\",\"display_name\":\"Chain Type\",\"advanced\":false,\"dynamic\":false,\"info\":\"The type of chain to use to combined Documents.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.chains import RetrievalQAWithSourcesChain\\nfrom langchain_core.documents import Document\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, BaseMemory, BaseRetriever, Text\\n\\n\\nclass RetrievalQAWithSourcesChainComponent(CustomComponent):\\n    display_name = \\\"RetrievalQAWithSourcesChain\\\"\\n    description = \\\"Question-answering with sources over an index.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"chain_type\\\": {\\n                \\\"display_name\\\": \\\"Chain Type\\\",\\n                \\\"options\\\": [\\\"stuff\\\", \\\"map_reduce\\\", \\\"map_rerank\\\", \\\"refine\\\"],\\n                \\\"info\\\": \\\"The type of chain to use to combined Documents.\\\",\\n            },\\n            \\\"memory\\\": {\\\"display_name\\\": \\\"Memory\\\"},\\n            \\\"return_source_documents\\\": {\\\"display_name\\\": \\\"Return Source Documents\\\"},\\n            \\\"retriever\\\": {\\\"display_name\\\": \\\"Retriever\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        inputs: str,\\n        retriever: BaseRetriever,\\n        llm: BaseLanguageModel,\\n        chain_type: str,\\n        memory: Optional[BaseMemory] = None,\\n        return_source_documents: Optional[bool] = True,\\n    ) -> Text:\\n        runnable = RetrievalQAWithSourcesChain.from_chain_type(\\n            llm=llm,\\n            chain_type=chain_type,\\n            memory=memory,\\n            return_source_documents=return_source_documents,\\n            retriever=retriever,\\n        )\\n        if isinstance(inputs, Document):\\n            inputs = inputs.page_content\\n        self.status = runnable\\n        input_key = runnable.input_keys[0]\\n        result = runnable.invoke({input_key: inputs})\\n        result = result.content if hasattr(result, \\\"content\\\") else result\\n        # Result is a dict with keys \\\"query\\\",  \\\"result\\\" and \\\"source_documents\\\"\\n        # for now we just return the result\\n        records = self.to_records(result.get(\\\"source_documents\\\"))\\n        references_str = \\\"\\\"\\n        if return_source_documents:\\n            references_str = self.create_references_from_records(records)\\n        result_str = result.get(\\\"answer\\\")\\n        final_result = \\\"\\\\n\\\".join([result_str, references_str])\\n        self.status = final_result\\n        return final_result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_source_documents\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_source_documents\",\"display_name\":\"Return Source Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Question-answering with sources over an index.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"RetrievalQAWithSourcesChain\",\"documentation\":\"\",\"custom_fields\":{\"inputs\":null,\"retriever\":null,\"llm\":null,\"chain_type\":null,\"memory\":null,\"return_source_documents\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"SQLDatabaseChain\":{\"template\":{\"db\":{\"type\":\"SQLDatabase\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"db\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"llm\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"prompt\":{\"type\":\"BasePromptTemplate\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"SQLDatabaseChain\"},\"description\":\"Create a SQLDatabaseChain from an LLM and a database connection.\",\"base_classes\":[\"Runnable\",\"Chain\",\"Generic\",\"Text\",\"RunnableSerializable\",\"Serializable\",\"object\",\"SQLDatabaseChain\",\"Callable\"],\"display_name\":\"SQLDatabaseChain\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false,\"output_type\":\"Chain\"},\"CombineDocsChain\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chain_type\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"stuff\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"stuff\",\"map_reduce\",\"map_rerank\",\"refine\"],\"name\":\"chain_type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"load_qa_chain\"},\"description\":\"Load question answering chain.\",\"base_classes\":[\"function\",\"BaseCombineDocumentsChain\"],\"display_name\":\"CombineDocsChain\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false,\"output_type\":\"Chain\"},\"SeriesCharacterChain\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"character\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"character\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"series\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"series\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"SeriesCharacterChain\"},\"description\":\"SeriesCharacterChain is a chain you can use to have a conversation with a character from a series.\",\"base_classes\":[\"Chain\",\"BaseCustomChain\",\"ConversationChain\",\"function\",\"SeriesCharacterChain\",\"LLMChain\"],\"display_name\":\"SeriesCharacterChain\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false,\"output_type\":\"Chain\"},\"MidJourneyPromptChain\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory\":{\"type\":\"BaseChatMemory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"MidJourneyPromptChain\"},\"description\":\"MidJourneyPromptChain is a chain you can use to generate new MidJourney prompts.\",\"base_classes\":[\"Chain\",\"BaseCustomChain\",\"MidJourneyPromptChain\",\"ConversationChain\",\"LLMChain\"],\"display_name\":\"MidJourneyPromptChain\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false,\"output_type\":\"Chain\"},\"TimeTravelGuideChain\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory\":{\"type\":\"BaseChatMemory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"TimeTravelGuideChain\"},\"description\":\"Time travel guide chain.\",\"base_classes\":[\"Chain\",\"BaseCustomChain\",\"ConversationChain\",\"TimeTravelGuideChain\",\"LLMChain\"],\"display_name\":\"TimeTravelGuideChain\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false,\"output_type\":\"Chain\"},\"LLMChain\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory\":{\"type\":\"BaseMemory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"display_name\":\"Memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"prompt\":{\"type\":\"BasePromptTemplate\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"prompt\",\"display_name\":\"Prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.chains import LLMChain\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import (\\n    BaseLanguageModel,\\n    BaseMemory,\\n    BasePromptTemplate,\\n    Text,\\n)\\n\\n\\nclass LLMChainComponent(CustomComponent):\\n    display_name = \\\"LLMChain\\\"\\n    description = \\\"Chain to run queries against LLMs\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"prompt\\\": {\\\"display_name\\\": \\\"Prompt\\\"},\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"memory\\\": {\\\"display_name\\\": \\\"Memory\\\"},\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        prompt: BasePromptTemplate,\\n        llm: BaseLanguageModel,\\n        memory: Optional[BaseMemory] = None,\\n    ) -> Text:\\n        runnable = LLMChain(prompt=prompt, llm=llm, memory=memory)\\n        result_dict = runnable.invoke({})\\n        output_key = runnable.output_key\\n        result = result_dict[output_key]\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Chain to run queries against LLMs\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"LLMChain\",\"documentation\":\"\",\"custom_fields\":{\"prompt\":null,\"llm\":null,\"memory\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"SQLGenerator\":{\"template\":{\"db\":{\"type\":\"SQLDatabase\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"db\",\"display_name\":\"Database\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"inputs\":{\"type\":\"Text\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"prompt\":{\"type\":\"PromptTemplate\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"prompt\",\"display_name\":\"Prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"The prompt must contain `{question}`.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.chains import create_sql_query_chain\\nfrom langchain_community.utilities.sql_database import SQLDatabase\\nfrom langchain_core.prompts import PromptTemplate\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, Text\\n\\n\\nclass SQLGeneratorComponent(CustomComponent):\\n    display_name = \\\"Natural Language to SQL\\\"\\n    description = \\\"Generate SQL from natural language.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"db\\\": {\\\"display_name\\\": \\\"Database\\\"},\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"prompt\\\": {\\n                \\\"display_name\\\": \\\"Prompt\\\",\\n                \\\"info\\\": \\\"The prompt must contain `{question}`.\\\",\\n            },\\n            \\\"top_k\\\": {\\n                \\\"display_name\\\": \\\"Top K\\\",\\n                \\\"info\\\": \\\"The number of results per select statement to return. If 0, no limit.\\\",\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        inputs: Text,\\n        db: SQLDatabase,\\n        llm: BaseLanguageModel,\\n        top_k: int = 5,\\n        prompt: Optional[PromptTemplate] = None,\\n    ) -> Text:\\n        if top_k > 0:\\n            kwargs = {\\n                \\\"k\\\": top_k,\\n            }\\n        if not prompt:\\n            sql_query_chain = create_sql_query_chain(llm=llm, db=db, **kwargs)\\n        else:\\n            template = prompt.template if hasattr(prompt, \\\"template\\\") else prompt\\n            # Check if {question} is in the prompt\\n            if \\\"{question}\\\" not in template or \\\"question\\\" not in template.input_variables:\\n                raise ValueError(\\\"Prompt must contain `{question}` to be used with Natural Language to SQL.\\\")\\n            sql_query_chain = create_sql_query_chain(llm=llm, db=db, prompt=prompt, **kwargs)\\n        query_writer = sql_query_chain | {\\\"query\\\": lambda x: x.replace(\\\"SQLQuery:\\\", \\\"\\\").strip()}\\n        response = query_writer.invoke({\\\"question\\\": inputs})\\n        query = response.get(\\\"query\\\")\\n        self.status = query\\n        return query\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":5,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":false,\"dynamic\":false,\"info\":\"The number of results per select statement to return. If 0, no limit.\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate SQL from natural language.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"Natural Language to SQL\",\"documentation\":\"\",\"custom_fields\":{\"inputs\":null,\"db\":null,\"llm\":null,\"top_k\":null,\"prompt\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"ConversationChain\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory\":{\"type\":\"BaseMemory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"display_name\":\"Memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"Memory to load context from. If none is provided, a ConversationBufferMemory will be used.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Optional, Union\\n\\nfrom langchain.chains import ConversationChain\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, BaseMemory, Chain, Text\\n\\n\\nclass ConversationChainComponent(CustomComponent):\\n    display_name = \\\"ConversationChain\\\"\\n    description = \\\"Chain to have a conversation and load context from memory.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"prompt\\\": {\\\"display_name\\\": \\\"Prompt\\\"},\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"memory\\\": {\\n                \\\"display_name\\\": \\\"Memory\\\",\\n                \\\"info\\\": \\\"Memory to load context from. If none is provided, a ConversationBufferMemory will be used.\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        inputs: str,\\n        llm: BaseLanguageModel,\\n        memory: Optional[BaseMemory] = None,\\n    ) -> Union[Chain, Callable, Text]:\\n        if memory is None:\\n            chain = ConversationChain(llm=llm)\\n        else:\\n            chain = ConversationChain(llm=llm, memory=memory)\\n        result = chain.invoke(inputs)\\n        # result is an AIMessage which is a subclass of BaseMessage\\n        # We need to check if it is a string or a BaseMessage\\n        if hasattr(result, \\\"content\\\") and isinstance(result.content, str):\\n            self.status = \\\"is message\\\"\\n            result = result.content\\n        elif isinstance(result, str):\\n            self.status = \\\"is_string\\\"\\n            result = result\\n        else:\\n            # is dict\\n            result = result.get(\\\"response\\\")\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Chain to have a conversation and load context from memory.\",\"base_classes\":[\"Runnable\",\"Chain\",\"Generic\",\"Text\",\"RunnableSerializable\",\"Serializable\",\"object\",\"Callable\"],\"display_name\":\"ConversationChain\",\"documentation\":\"\",\"custom_fields\":{\"inputs\":null,\"llm\":null,\"memory\":null},\"output_types\":[\"Chain\",\"Callable\",\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"agents\":{\"ZeroShotAgent\":{\"template\":{\"callback_manager\":{\"type\":\"BaseCallbackManager\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"callback_manager\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"llm\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"output_parser\":{\"type\":\"AgentOutputParser\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"output_parser\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tools\":{\"type\":\"BaseTool\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"tools\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"format_instructions\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":true,\"value\":\"Use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\",\"fileTypes\":[],\"password\":false,\"name\":\"format_instructions\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"input_variables\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"input_variables\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"Answer the following questions as best you can. You have access to the following tools:\",\"fileTypes\":[],\"password\":false,\"name\":\"prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"suffix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"Begin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}\",\"fileTypes\":[],\"password\":false,\"name\":\"suffix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"ZeroShotAgent\"},\"description\":\"Construct an agent from an LLM and tools.\",\"base_classes\":[\"ZeroShotAgent\",\"Callable\",\"BaseSingleActionAgent\",\"Agent\"],\"display_name\":\"ZeroShotAgent\",\"documentation\":\"https://python.langchain.com/docs/modules/agents/how_to/custom_mrkl_agent\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"JsonAgent\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"toolkit\":{\"type\":\"JsonToolkit\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"toolkit\",\"display_name\":\"Toolkit\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langchain.agents import AgentExecutor, create_json_agent\\nfrom langflow.field_typing import (\\n    BaseLanguageModel,\\n)\\nfrom langchain_community.agent_toolkits.json.toolkit import JsonToolkit\\n\\n\\nclass JsonAgentComponent(CustomComponent):\\n    display_name = \\\"JsonAgent\\\"\\n    description = \\\"Construct a json agent from an LLM and tools.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"toolkit\\\": {\\\"display_name\\\": \\\"Toolkit\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        llm: BaseLanguageModel,\\n        toolkit: JsonToolkit,\\n    ) -> AgentExecutor:\\n        return create_json_agent(llm=llm, toolkit=toolkit)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Construct a json agent from an LLM and tools.\",\"base_classes\":[\"Runnable\",\"Chain\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"AgentExecutor\",\"object\"],\"display_name\":\"JsonAgent\",\"documentation\":\"\",\"custom_fields\":{\"llm\":null,\"toolkit\":null},\"output_types\":[\"AgentExecutor\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"CSVAgent\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".csv\"],\"file_path\":\"\",\"password\":false,\"name\":\"path\",\"display_name\":\"Path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, AgentExecutor\\nfrom langchain_experimental.agents.agent_toolkits.csv.base import create_csv_agent\\n\\n\\nclass CSVAgentComponent(CustomComponent):\\n    display_name = \\\"CSVAgent\\\"\\n    description = \\\"Construct a CSV agent from a CSV and tools.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/agents/toolkits/csv\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\", \\\"type\\\": BaseLanguageModel},\\n            \\\"path\\\": {\\\"display_name\\\": \\\"Path\\\", \\\"field_type\\\": \\\"file\\\", \\\"suffixes\\\": [\\\".csv\\\"], \\\"file_types\\\": [\\\".csv\\\"]},\\n        }\\n\\n    def build(\\n        self,\\n        llm: BaseLanguageModel,\\n        path: str,\\n    ) -> AgentExecutor:\\n        # Instantiate and return the CSV agent class with the provided llm and path\\n        return create_csv_agent(llm=llm, path=path)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Construct a CSV agent from a CSV and tools.\",\"base_classes\":[\"Runnable\",\"Chain\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"AgentExecutor\",\"object\"],\"display_name\":\"CSVAgent\",\"documentation\":\"https://python.langchain.com/docs/modules/agents/toolkits/csv\",\"custom_fields\":{\"llm\":null,\"path\":null},\"output_types\":[\"AgentExecutor\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"VectorStoreAgent\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"vector_store_toolkit\":{\"type\":\"VectorStoreToolkit\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vector_store_toolkit\",\"display_name\":\"Vector Store Info\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langchain.agents import AgentExecutor, create_vectorstore_agent\\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreToolkit\\nfrom typing import Union, Callable\\nfrom langflow.field_typing import BaseLanguageModel\\n\\n\\nclass VectorStoreAgentComponent(CustomComponent):\\n    display_name = \\\"VectorStoreAgent\\\"\\n    description = \\\"Construct an agent from a Vector Store.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"vector_store_toolkit\\\": {\\\"display_name\\\": \\\"Vector Store Info\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        llm: BaseLanguageModel,\\n        vector_store_toolkit: VectorStoreToolkit,\\n    ) -> Union[AgentExecutor, Callable]:\\n        return create_vectorstore_agent(llm=llm, toolkit=vector_store_toolkit)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Construct an agent from a Vector Store.\",\"base_classes\":[\"Runnable\",\"Chain\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"AgentExecutor\",\"object\",\"Callable\"],\"display_name\":\"VectorStoreAgent\",\"documentation\":\"\",\"custom_fields\":{\"llm\":null,\"vector_store_toolkit\":null},\"output_types\":[\"AgentExecutor\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"VectorStoreRouterAgent\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"vectorstoreroutertoolkit\":{\"type\":\"VectorStoreRouterToolkit\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vectorstoreroutertoolkit\",\"display_name\":\"Vector Store Router Toolkit\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langchain_core.language_models.base import BaseLanguageModel\\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreRouterToolkit\\nfrom langchain.agents import create_vectorstore_router_agent\\nfrom typing import Callable\\n\\n\\nclass VectorStoreRouterAgentComponent(CustomComponent):\\n    display_name = \\\"VectorStoreRouterAgent\\\"\\n    description = \\\"Construct an agent from a Vector Store Router.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"vectorstoreroutertoolkit\\\": {\\\"display_name\\\": \\\"Vector Store Router Toolkit\\\"},\\n        }\\n\\n    def build(self, llm: BaseLanguageModel, vectorstoreroutertoolkit: VectorStoreRouterToolkit) -> Callable:\\n        return create_vectorstore_router_agent(llm=llm, toolkit=vectorstoreroutertoolkit)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Construct an agent from a Vector Store Router.\",\"base_classes\":[\"Callable\"],\"display_name\":\"VectorStoreRouterAgent\",\"documentation\":\"\",\"custom_fields\":{\"llm\":null,\"vectorstoreroutertoolkit\":null},\"output_types\":[\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"SQLAgent\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom typing import Union, Callable\\nfrom langchain.agents import AgentExecutor\\nfrom langflow.field_typing import BaseLanguageModel\\nfrom langchain_community.agent_toolkits.sql.base import create_sql_agent\\nfrom langchain.sql_database import SQLDatabase\\nfrom langchain_community.agent_toolkits import SQLDatabaseToolkit\\n\\n\\nclass SQLAgentComponent(CustomComponent):\\n    display_name = \\\"SQLAgent\\\"\\n    description = \\\"Construct an SQL agent from an LLM and tools.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"database_uri\\\": {\\\"display_name\\\": \\\"Database URI\\\"},\\n            \\\"verbose\\\": {\\\"display_name\\\": \\\"Verbose\\\", \\\"value\\\": False, \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        llm: BaseLanguageModel,\\n        database_uri: str,\\n        verbose: bool = False,\\n    ) -> Union[AgentExecutor, Callable]:\\n        db = SQLDatabase.from_uri(database_uri)\\n        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\\n        return create_sql_agent(llm=llm, toolkit=toolkit)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"database_uri\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"database_uri\",\"display_name\":\"Database URI\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"verbose\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"verbose\",\"display_name\":\"Verbose\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Construct an SQL agent from an LLM and tools.\",\"base_classes\":[\"Runnable\",\"Chain\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"AgentExecutor\",\"object\",\"Callable\"],\"display_name\":\"SQLAgent\",\"documentation\":\"\",\"custom_fields\":{\"llm\":null,\"database_uri\":null,\"verbose\":null},\"output_types\":[\"AgentExecutor\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"OpenAIConversationalAgent\":{\"template\":{\"memory\":{\"type\":\"BaseMemory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"display_name\":\"Memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"system_message\":{\"type\":\"SystemMessagePromptTemplate\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"system_message\",\"display_name\":\"System Message\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tools\":{\"type\":\"Tool\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tools\",\"display_name\":\"Tools\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional\\n\\nfrom langchain.agents.agent import AgentExecutor\\nfrom langchain.agents.agent_toolkits.conversational_retrieval.openai_functions import _get_default_system_message\\nfrom langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\\nfrom langchain.memory.token_buffer import ConversationTokenBufferMemory\\nfrom langchain.prompts import SystemMessagePromptTemplate\\nfrom langchain.prompts.chat import MessagesPlaceholder\\nfrom langchain.schema.memory import BaseMemory\\nfrom langchain.tools import Tool\\nfrom langchain_community.chat_models import ChatOpenAI\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing.range_spec import RangeSpec\\n\\n\\nclass ConversationalAgent(CustomComponent):\\n    display_name: str = \\\"OpenAI Conversational Agent\\\"\\n    description: str = \\\"Conversational Agent that can use OpenAI's function calling API\\\"\\n\\n    def build_config(self):\\n        openai_function_models = [\\n            \\\"gpt-4-turbo-preview\\\",\\n            \\\"gpt-4-0125-preview\\\",\\n            \\\"gpt-4-1106-preview\\\",\\n            \\\"gpt-4-vision-preview\\\",\\n            \\\"gpt-3.5-turbo-0125\\\",\\n            \\\"gpt-3.5-turbo-1106\\\",\\n        ]\\n        return {\\n            \\\"tools\\\": {\\\"display_name\\\": \\\"Tools\\\"},\\n            \\\"memory\\\": {\\\"display_name\\\": \\\"Memory\\\"},\\n            \\\"system_message\\\": {\\\"display_name\\\": \\\"System Message\\\"},\\n            \\\"max_token_limit\\\": {\\\"display_name\\\": \\\"Max Token Limit\\\"},\\n            \\\"model_name\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"options\\\": openai_function_models,\\n                \\\"value\\\": openai_function_models[0],\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"value\\\": 0.2,\\n                \\\"range_spec\\\": RangeSpec(min=0, max=2, step=0.1),\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        model_name: str,\\n        openai_api_key: str,\\n        tools: List[Tool],\\n        openai_api_base: Optional[str] = None,\\n        memory: Optional[BaseMemory] = None,\\n        system_message: Optional[SystemMessagePromptTemplate] = None,\\n        max_token_limit: int = 2000,\\n        temperature: float = 0.9,\\n    ) -> AgentExecutor:\\n        llm = ChatOpenAI(\\n            model=model_name,\\n            api_key=openai_api_key,\\n            base_url=openai_api_base,\\n            max_tokens=max_token_limit,\\n            temperature=temperature,\\n        )\\n        if not memory:\\n            memory_key = \\\"chat_history\\\"\\n            memory = ConversationTokenBufferMemory(\\n                memory_key=memory_key,\\n                return_messages=True,\\n                output_key=\\\"output\\\",\\n                llm=llm,\\n                max_token_limit=max_token_limit,\\n            )\\n        else:\\n            memory_key = memory.memory_key  # type: ignore\\n\\n        _system_message = system_message or _get_default_system_message()\\n        prompt = OpenAIFunctionsAgent.create_prompt(\\n            system_message=_system_message,  # type: ignore\\n            extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)],\\n        )\\n        agent = OpenAIFunctionsAgent(\\n            llm=llm,\\n            tools=tools,\\n            prompt=prompt,  # type: ignore\\n        )\\n        return AgentExecutor(\\n            agent=agent,\\n            tools=tools,  # type: ignore\\n            memory=memory,\\n            verbose=True,\\n            return_intermediate_steps=True,\\n            handle_parsing_errors=True,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"max_token_limit\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":2000,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_token_limit\",\"display_name\":\"Max Token Limit\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"gpt-4-turbo-preview\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"gpt-4-turbo-preview\",\"gpt-4-0125-preview\",\"gpt-4-1106-preview\",\"gpt-4-vision-preview\",\"gpt-3.5-turbo-0125\",\"gpt-3.5-turbo-1106\"],\"name\":\"model_name\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_api_base\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"openai_api_base\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"openai_api_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.2,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":0.0,\"max\":2.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Conversational Agent that can use OpenAI's function calling API\",\"base_classes\":[\"Runnable\",\"Chain\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"AgentExecutor\",\"object\"],\"display_name\":\"OpenAI Conversational Agent\",\"documentation\":\"\",\"custom_fields\":{\"model_name\":null,\"openai_api_key\":null,\"tools\":null,\"openai_api_base\":null,\"memory\":null,\"system_message\":null,\"max_token_limit\":null,\"temperature\":null},\"output_types\":[\"AgentExecutor\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"AgentInitializer\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"Language Model\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory\":{\"type\":\"BaseChatMemory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"memory\",\"display_name\":\"Memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tools\":{\"type\":\"Tool\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tools\",\"display_name\":\"Tools\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"agent\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"zero-shot-react-description\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"zero-shot-react-description\",\"react-docstore\",\"self-ask-with-search\",\"conversational-react-description\",\"chat-zero-shot-react-description\",\"chat-conversational-react-description\",\"structured-chat-zero-shot-react-description\",\"openai-functions\",\"openai-multi-functions\",\"JsonAgent\",\"CSVAgent\",\"VectorStoreAgent\",\"VectorStoreRouterAgent\",\"SQLAgent\"],\"name\":\"agent\",\"display_name\":\"Agent Type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, List, Optional, Union\\n\\nfrom langchain.agents import AgentExecutor, AgentType, initialize_agent, types\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseChatMemory, BaseLanguageModel, Tool\\n\\n\\nclass AgentInitializerComponent(CustomComponent):\\n    display_name: str = \\\"Agent Initializer\\\"\\n    description: str = \\\"Initialize a Langchain Agent.\\\"\\n    documentation: str = \\\"https://python.langchain.com/docs/modules/agents/agent_types/\\\"\\n\\n    def build_config(self):\\n        agents = list(types.AGENT_TO_CLASS.keys())\\n        # field_type and required are optional\\n        return {\\n            \\\"agent\\\": {\\\"options\\\": agents, \\\"value\\\": agents[0], \\\"display_name\\\": \\\"Agent Type\\\"},\\n            \\\"max_iterations\\\": {\\\"display_name\\\": \\\"Max Iterations\\\", \\\"value\\\": 10},\\n            \\\"memory\\\": {\\\"display_name\\\": \\\"Memory\\\"},\\n            \\\"tools\\\": {\\\"display_name\\\": \\\"Tools\\\"},\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"Language Model\\\"},\\n            \\\"code\\\": {\\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        agent: str,\\n        llm: BaseLanguageModel,\\n        tools: List[Tool],\\n        max_iterations: int,\\n        memory: Optional[BaseChatMemory] = None,\\n    ) -> Union[AgentExecutor, Callable]:\\n        agent = AgentType(agent)\\n        if memory:\\n            return initialize_agent(\\n                tools=tools,\\n                llm=llm,\\n                agent=agent,\\n                memory=memory,\\n                return_intermediate_steps=True,\\n                handle_parsing_errors=True,\\n                max_iterations=max_iterations,\\n            )\\n        return initialize_agent(\\n            tools=tools,\\n            llm=llm,\\n            agent=agent,\\n            return_intermediate_steps=True,\\n            handle_parsing_errors=True,\\n            max_iterations=max_iterations,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":true,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"max_iterations\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_iterations\",\"display_name\":\"Max Iterations\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Initialize a Langchain Agent.\",\"base_classes\":[\"Runnable\",\"Chain\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"AgentExecutor\",\"object\",\"Callable\"],\"display_name\":\"Agent Initializer\",\"documentation\":\"https://python.langchain.com/docs/modules/agents/agent_types/\",\"custom_fields\":{\"agent\":null,\"llm\":null,\"tools\":null,\"max_iterations\":null,\"memory\":null},\"output_types\":[\"AgentExecutor\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"memories\":{\"ConversationBufferMemory\":{\"template\":{\"chat_memory\":{\"type\":\"BaseChatMessageHistory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"chat_memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"ai_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"AI\",\"fileTypes\":[],\"password\":false,\"name\":\"ai_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"human_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"Human\",\"fileTypes\":[],\"password\":false,\"name\":\"human_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"input_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Input when more than one variable is available.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"memory_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"chat_history\",\"fileTypes\":[],\"password\":false,\"name\":\"memory_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"output_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"output_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_messages\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_messages\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"ConversationBufferMemory\"},\"description\":\"Buffer for storing conversation memory.\",\"base_classes\":[\"BaseMemory\",\"BaseChatMemory\",\"ConversationBufferMemory\",\"Serializable\"],\"display_name\":\"ConversationBufferMemory\",\"documentation\":\"https://python.langchain.com/docs/modules/memory/how_to/buffer\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":true,\"beta\":false},\"ConversationBufferWindowMemory\":{\"template\":{\"chat_memory\":{\"type\":\"BaseChatMessageHistory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"chat_memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"ai_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"AI\",\"fileTypes\":[],\"password\":false,\"name\":\"ai_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"human_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"Human\",\"fileTypes\":[],\"password\":false,\"name\":\"human_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"input_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Input when more than one variable is available.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10,\"fileTypes\":[],\"password\":false,\"name\":\"k\",\"display_name\":\"Memory Size\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"chat_history\",\"fileTypes\":[],\"password\":false,\"name\":\"memory_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"output_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"output_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_messages\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_messages\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"ConversationBufferWindowMemory\"},\"description\":\"Buffer for storing conversation memory inside a limited size window.\",\"base_classes\":[\"ConversationBufferWindowMemory\",\"BaseMemory\",\"BaseChatMemory\",\"Serializable\"],\"display_name\":\"ConversationBufferWindowMemory\",\"documentation\":\"https://python.langchain.com/docs/modules/memory/how_to/buffer_window\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":true,\"beta\":false},\"ConversationEntityMemory\":{\"template\":{\"chat_memory\":{\"type\":\"BaseChatMessageHistory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"chat_memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"entity_extraction_prompt\":{\"type\":\"BasePromptTemplate\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"entity_extraction_prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"entity_store\":{\"type\":\"BaseEntityStore\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"entity_store\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"entity_summarization_prompt\":{\"type\":\"BasePromptTemplate\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"entity_summarization_prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"llm\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"ai_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"AI\",\"fileTypes\":[],\"password\":false,\"name\":\"ai_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"chat_history_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"history\",\"fileTypes\":[],\"password\":false,\"name\":\"chat_history_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"entity_cache\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"entity_cache\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"human_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"Human\",\"fileTypes\":[],\"password\":false,\"name\":\"human_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"input_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Input when more than one variable is available.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10,\"fileTypes\":[],\"password\":false,\"name\":\"k\",\"display_name\":\"Memory Size\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"output_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"output_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_messages\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_messages\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"ConversationEntityMemory\"},\"description\":\"Entity extractor & summarizer memory.\",\"base_classes\":[\"ConversationEntityMemory\",\"BaseMemory\",\"BaseChatMemory\",\"Serializable\"],\"display_name\":\"ConversationEntityMemory\",\"documentation\":\"https://python.langchain.com/docs/modules/memory/integrations/entity_memory_with_sqlite\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":true,\"beta\":false},\"ConversationKGMemory\":{\"template\":{\"chat_memory\":{\"type\":\"BaseChatMessageHistory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"chat_memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"entity_extraction_prompt\":{\"type\":\"BasePromptTemplate\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"entity_extraction_prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"kg\":{\"type\":\"NetworkxEntityGraph\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"kg\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"knowledge_extraction_prompt\":{\"type\":\"BasePromptTemplate\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"knowledge_extraction_prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"llm\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"summary_message_cls\":{\"type\":\"Type[langchain_core.messages.base.BaseMessage]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"summary_message_cls\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"ai_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"AI\",\"fileTypes\":[],\"password\":false,\"name\":\"ai_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"human_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"Human\",\"fileTypes\":[],\"password\":false,\"name\":\"human_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"input_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Input when more than one variable is available.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10,\"fileTypes\":[],\"password\":false,\"name\":\"k\",\"display_name\":\"Memory Size\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"memory_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"chat_history\",\"fileTypes\":[],\"password\":false,\"name\":\"memory_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"output_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"output_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_messages\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_messages\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"ConversationKGMemory\"},\"description\":\"Knowledge graph conversation memory.\",\"base_classes\":[\"BaseChatMemory\",\"BaseMemory\",\"ConversationKGMemory\",\"Serializable\"],\"display_name\":\"ConversationKGMemory\",\"documentation\":\"https://python.langchain.com/docs/modules/memory/how_to/kg\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":true,\"beta\":false},\"ConversationSummaryMemory\":{\"template\":{\"chat_memory\":{\"type\":\"BaseChatMessageHistory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"chat_memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"llm\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"prompt\":{\"type\":\"BasePromptTemplate\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"summary_message_cls\":{\"type\":\"Type[langchain_core.messages.base.BaseMessage]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"summary_message_cls\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"ai_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"AI\",\"fileTypes\":[],\"password\":false,\"name\":\"ai_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"buffer\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"password\":false,\"name\":\"buffer\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"human_prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"Human\",\"fileTypes\":[],\"password\":false,\"name\":\"human_prefix\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"input_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Input when more than one variable is available.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"memory_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"chat_history\",\"fileTypes\":[],\"password\":false,\"name\":\"memory_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"output_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"output_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_messages\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_messages\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"ConversationSummaryMemory\"},\"description\":\"Conversation summarizer to chat memory.\",\"base_classes\":[\"BaseChatMemory\",\"Serializable\",\"ConversationSummaryMemory\",\"BaseMemory\",\"SummarizerMixin\"],\"display_name\":\"ConversationSummaryMemory\",\"documentation\":\"https://python.langchain.com/docs/modules/memory/how_to/summary\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":true,\"beta\":false},\"MongoDBChatMessageHistory\":{\"template\":{\"collection_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"message_store\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"collection_name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"connection_string\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"connection_string\",\"advanced\":false,\"dynamic\":false,\"info\":\"MongoDB connection string (e.g mongodb://mongo_user:password123@mongo:27017)\",\"title_case\":false,\"input_types\":[\"Text\"]},\"database_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"chat_history\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"database_name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"session_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"session_id\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"MongoDBChatMessageHistory\"},\"description\":\"Memory store with MongoDB\",\"base_classes\":[\"BaseChatMessageHistory\",\"MongoDBChatMessageHistory\"],\"display_name\":\"MongoDBChatMessageHistory\",\"documentation\":\"https://python.langchain.com/docs/modules/memory/integrations/mongodb_chat_message_history\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":true,\"beta\":false},\"MotorheadMemory\":{\"template\":{\"chat_memory\":{\"type\":\"BaseChatMessageHistory\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"chat_memory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"api_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"api_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"client_id\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"client_id\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"context\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"context\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"input_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Input when more than one variable is available.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"memory_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"chat_history\",\"fileTypes\":[],\"password\":false,\"name\":\"memory_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"output_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"output_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_messages\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_messages\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"session_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"session_id\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"timeout\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"timeout\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"https://api.getmetal.io/v1/motorhead\",\"fileTypes\":[],\"password\":false,\"name\":\"url\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"MotorheadMemory\"},\"description\":\"Chat message memory backed by Motorhead service.\",\"base_classes\":[\"MotorheadMemory\",\"BaseChatMemory\",\"BaseMemory\",\"Serializable\"],\"display_name\":\"MotorheadMemory\",\"documentation\":\"https://python.langchain.com/docs/integrations/memory/motorhead_memory\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":true,\"beta\":false},\"PostgresChatMessageHistory\":{\"template\":{\"connection_string\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"postgresql://postgres:mypassword@localhost/chat_history\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"connection_string\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"session_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"session_id\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"table_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"message_store\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"table_name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"PostgresChatMessageHistory\"},\"description\":\"Memory store with Postgres\",\"base_classes\":[\"BaseChatMessageHistory\",\"PostgresChatMessageHistory\"],\"display_name\":\"PostgresChatMessageHistory\",\"documentation\":\"https://python.langchain.com/docs/modules/memory/integrations/postgres_chat_message_history\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":true,\"beta\":false},\"VectorStoreRetrieverMemory\":{\"template\":{\"retriever\":{\"type\":\"VectorStoreRetriever\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"retriever\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"exclude_input_keys\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"exclude_input_keys\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"input_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The variable to be used as Chat Input when more than one variable is available.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"memory_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"chat_history\",\"fileTypes\":[],\"password\":false,\"name\":\"memory_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_docs\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"return_docs\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"return_messages\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_messages\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"VectorStoreRetrieverMemory\"},\"description\":\"VectorStoreRetriever-backed memory.\",\"base_classes\":[\"BaseMemory\",\"VectorStoreRetrieverMemory\",\"Serializable\"],\"display_name\":\"VectorStoreRetrieverMemory\",\"documentation\":\"https://python.langchain.com/docs/modules/memory/how_to/vectorstore_retriever_memory\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":true,\"beta\":false}},\"tools\":{\"Calculator\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"Calculator\"},\"description\":\"Useful for when you need to answer questions about math.\",\"base_classes\":[\"BaseTool\",\"Tool\"],\"display_name\":\"Calculator\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"Search\":{\"template\":{\"aiosession\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"aiosession\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"serpapi_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"serpapi_api_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"Search\"},\"description\":\"A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\",\"base_classes\":[\"BaseTool\",\"Tool\"],\"display_name\":\"Search\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"Tool\":{\"template\":{\"func\":{\"type\":\"Callable\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"func\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"description\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"description\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_direct\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_direct\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"Tool\"},\"description\":\"Converts a chain, agent or function into a tool.\",\"base_classes\":[\"BaseTool\",\"Tool\"],\"display_name\":\"Tool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"PythonFunctionTool\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"\\ndef python_function(text: str) -> str:\\n    \\\"\\\"\\\"This is a default python function that returns the input text\\\"\\\"\\\"\\n    return text\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"description\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"description\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"return_direct\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_direct\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"PythonFunctionTool\"},\"description\":\"Python function to be executed.\",\"base_classes\":[\"BaseTool\",\"Tool\"],\"display_name\":\"PythonFunctionTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"PythonFunction\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"\\ndef python_function(text: str) -> str:\\n    \\\"\\\"\\\"This is a default python function that returns the input text\\\"\\\"\\\"\\n    return text\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"PythonFunction\"},\"description\":\"Python function to be executed.\",\"base_classes\":[\"Callable\"],\"display_name\":\"PythonFunction\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"JsonSpec\":{\"template\":{\"path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".json\",\".yaml\",\".yml\"],\"file_path\":\"\",\"password\":false,\"name\":\"path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"max_value_length\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_value_length\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"JsonSpec\"},\"description\":\"\",\"base_classes\":[\"JsonSpec\",\"BaseTool\",\"Tool\"],\"display_name\":\"JsonSpec\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"BingSearchRun\":{\"template\":{\"api_wrapper\":{\"type\":\"BingSearchAPIWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"BingSearchRun\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"BingSearchRun\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\"],\"display_name\":\"BingSearchRun\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"GoogleSearchResults\":{\"template\":{\"api_wrapper\":{\"type\":\"GoogleSearchAPIWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"num_results\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":4,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_results\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"GoogleSearchResults\"},\"description\":\"\",\"base_classes\":[\"GoogleSearchResults\",\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\"],\"display_name\":\"GoogleSearchResults\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"GoogleSearchRun\":{\"template\":{\"api_wrapper\":{\"type\":\"GoogleSearchAPIWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"GoogleSearchRun\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"GoogleSearchRun\",\"Serializable\",\"object\"],\"display_name\":\"GoogleSearchRun\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"GoogleSerperRun\":{\"template\":{\"api_wrapper\":{\"type\":\"GoogleSerperAPIWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"GoogleSerperRun\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"GoogleSerperRun\",\"object\"],\"display_name\":\"GoogleSerperRun\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"InfoSQLDatabaseTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"db\":{\"type\":\"SQLDatabase\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"db\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"InfoSQLDatabaseTool\"},\"description\":\"\",\"base_classes\":[\"InfoSQLDatabaseTool\",\"Runnable\",\"BaseSQLDatabaseTool\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\"],\"display_name\":\"InfoSQLDatabaseTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"JsonGetValueTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"spec\":{\"type\":\"JsonSpec\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"spec\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"JsonGetValueTool\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\",\"JsonGetValueTool\"],\"display_name\":\"JsonGetValueTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"JsonListKeysTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"spec\":{\"type\":\"JsonSpec\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"spec\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"JsonListKeysTool\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\",\"JsonListKeysTool\"],\"display_name\":\"JsonListKeysTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"ListSQLDatabaseTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"db\":{\"type\":\"SQLDatabase\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"db\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"ListSQLDatabaseTool\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"BaseSQLDatabaseTool\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\",\"ListSQLDatabaseTool\"],\"display_name\":\"ListSQLDatabaseTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"QuerySQLDataBaseTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"db\":{\"type\":\"SQLDatabase\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"db\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"QuerySQLDataBaseTool\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"BaseSQLDatabaseTool\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"QuerySQLDataBaseTool\",\"Serializable\",\"object\"],\"display_name\":\"QuerySQLDataBaseTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"RequestsDeleteTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"requests_wrapper\":{\"type\":\"GenericRequestsWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"requests_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"RequestsDeleteTool\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\",\"RequestsDeleteTool\",\"BaseRequestsTool\"],\"display_name\":\"RequestsDeleteTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"RequestsGetTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"requests_wrapper\":{\"type\":\"GenericRequestsWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"requests_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"RequestsGetTool\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\",\"RequestsGetTool\",\"BaseRequestsTool\"],\"display_name\":\"RequestsGetTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"RequestsPatchTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"requests_wrapper\":{\"type\":\"GenericRequestsWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"requests_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"RequestsPatchTool\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"RequestsPatchTool\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\",\"BaseRequestsTool\"],\"display_name\":\"RequestsPatchTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"RequestsPostTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"requests_wrapper\":{\"type\":\"GenericRequestsWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"requests_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"RequestsPostTool\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"RequestsPostTool\",\"object\",\"BaseRequestsTool\"],\"display_name\":\"RequestsPostTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"RequestsPutTool\":{\"template\":{\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"requests_wrapper\":{\"type\":\"GenericRequestsWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"requests_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"RequestsPutTool\"},\"description\":\"\",\"base_classes\":[\"RequestsPutTool\",\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\",\"BaseRequestsTool\"],\"display_name\":\"RequestsPutTool\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"WikipediaQueryRun\":{\"template\":{\"api_wrapper\":{\"type\":\"WikipediaAPIWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"WikipediaQueryRun\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"WikipediaQueryRun\",\"Serializable\",\"object\"],\"display_name\":\"WikipediaQueryRun\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"WolframAlphaQueryRun\":{\"template\":{\"api_wrapper\":{\"type\":\"WolframAlphaAPIWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"args_schema\":{\"type\":\"Type[pydantic.v1.main.BaseModel]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"args_schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"callbacks\":{\"type\":\"langchain_core.callbacks.base.BaseCallbackHandler\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"callbacks\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_tool_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_tool_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"handle_validation_error\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"handle_validation_error\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"WolframAlphaQueryRun\"},\"description\":\"\",\"base_classes\":[\"Runnable\",\"WolframAlphaQueryRun\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\"],\"display_name\":\"WolframAlphaQueryRun\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false}},\"toolkits\":{\"JsonToolkit\":{\"template\":{\"spec\":{\"type\":\"JsonSpec\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"spec\",\"display_name\":\"Spec\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langchain_community.tools.json.tool import JsonSpec\\nfrom langchain_community.agent_toolkits.json.toolkit import JsonToolkit\\n\\n\\nclass JsonToolkitComponent(CustomComponent):\\n    display_name = \\\"JsonToolkit\\\"\\n    description = \\\"Toolkit for interacting with a JSON spec.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"spec\\\": {\\\"display_name\\\": \\\"Spec\\\", \\\"type\\\": JsonSpec},\\n        }\\n\\n    def build(self, spec: JsonSpec) -> JsonToolkit:\\n        return JsonToolkit(spec=spec)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Toolkit for interacting with a JSON spec.\",\"base_classes\":[\"BaseToolkit\",\"JsonToolkit\"],\"display_name\":\"JsonToolkit\",\"documentation\":\"\",\"custom_fields\":{\"spec\":null},\"output_types\":[\"JsonToolkit\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"OpenAPIToolkit\":{\"template\":{\"json_agent\":{\"type\":\"AgentExecutor\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"json_agent\",\"display_name\":\"JSON Agent\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"requests_wrapper\":{\"type\":\"TextRequestsWrapper\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"requests_wrapper\",\"display_name\":\"Text Requests Wrapper\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langchain_community.agent_toolkits.openapi.toolkit import BaseToolkit, OpenAPIToolkit\\nfrom langchain_community.utilities.requests import TextRequestsWrapper\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import AgentExecutor\\n\\n\\nclass OpenAPIToolkitComponent(CustomComponent):\\n    display_name = \\\"OpenAPIToolkit\\\"\\n    description = \\\"Toolkit for interacting with an OpenAPI API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"json_agent\\\": {\\\"display_name\\\": \\\"JSON Agent\\\"},\\n            \\\"requests_wrapper\\\": {\\\"display_name\\\": \\\"Text Requests Wrapper\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        json_agent: AgentExecutor,\\n        requests_wrapper: TextRequestsWrapper,\\n    ) -> BaseToolkit:\\n        return OpenAPIToolkit(json_agent=json_agent, requests_wrapper=requests_wrapper)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Toolkit for interacting with an OpenAPI API.\",\"base_classes\":[\"BaseToolkit\"],\"display_name\":\"OpenAPIToolkit\",\"documentation\":\"\",\"custom_fields\":{\"json_agent\":null,\"requests_wrapper\":null},\"output_types\":[\"BaseToolkit\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"VectorStoreInfo\":{\"template\":{\"vectorstore\":{\"type\":\"VectorStore\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vectorstore\",\"display_name\":\"VectorStore\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Union\\n\\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreInfo\\nfrom langchain_community.vectorstores import VectorStore\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass VectorStoreInfoComponent(CustomComponent):\\n    display_name = \\\"VectorStoreInfo\\\"\\n    description = \\\"Information about a VectorStore\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"vectorstore\\\": {\\\"display_name\\\": \\\"VectorStore\\\"},\\n            \\\"description\\\": {\\\"display_name\\\": \\\"Description\\\", \\\"multiline\\\": True},\\n            \\\"name\\\": {\\\"display_name\\\": \\\"Name\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        vectorstore: VectorStore,\\n        description: str,\\n        name: str,\\n    ) -> Union[VectorStoreInfo, Callable]:\\n        return VectorStoreInfo(vectorstore=vectorstore, description=description, name=name)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"description\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"description\",\"display_name\":\"Description\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"name\",\"display_name\":\"Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Information about a VectorStore\",\"base_classes\":[\"Callable\",\"VectorStoreInfo\"],\"display_name\":\"VectorStoreInfo\",\"documentation\":\"\",\"custom_fields\":{\"vectorstore\":null,\"description\":null,\"name\":null},\"output_types\":[\"VectorStoreInfo\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"VectorStoreRouterToolkit\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"vectorstores\":{\"type\":\"VectorStoreInfo\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vectorstores\",\"display_name\":\"Vector Stores\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom typing import List, Union\\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreRouterToolkit\\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreInfo\\nfrom langflow.field_typing import BaseLanguageModel, Tool\\n\\n\\nclass VectorStoreRouterToolkitComponent(CustomComponent):\\n    display_name = \\\"VectorStoreRouterToolkit\\\"\\n    description = \\\"Toolkit for routing between Vector Stores.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"vectorstores\\\": {\\\"display_name\\\": \\\"Vector Stores\\\"},\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n        }\\n\\n    def build(\\n        self, vectorstores: List[VectorStoreInfo], llm: BaseLanguageModel\\n    ) -> Union[Tool, VectorStoreRouterToolkit]:\\n        print(\\\"vectorstores\\\", vectorstores)\\n        print(\\\"llm\\\", llm)\\n        return VectorStoreRouterToolkit(vectorstores=vectorstores, llm=llm)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Toolkit for routing between Vector Stores.\",\"base_classes\":[\"Runnable\",\"BaseToolkit\",\"Generic\",\"VectorStoreRouterToolkit\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\"],\"display_name\":\"VectorStoreRouterToolkit\",\"documentation\":\"\",\"custom_fields\":{\"vectorstores\":null,\"llm\":null},\"output_types\":[\"Tool\",\"VectorStoreRouterToolkit\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"VectorStoreToolkit\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"vectorstore_info\":{\"type\":\"VectorStoreInfo\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vectorstore_info\",\"display_name\":\"Vector Store Info\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreToolkit\\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreInfo\\nfrom langflow.field_typing import (\\n    BaseLanguageModel,\\n)\\nfrom langflow.field_typing import (\\n    Tool,\\n)\\nfrom typing import Union\\n\\n\\nclass VectorStoreToolkitComponent(CustomComponent):\\n    display_name = \\\"VectorStoreToolkit\\\"\\n    description = \\\"Toolkit for interacting with a Vector Store.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"vectorstore_info\\\": {\\\"display_name\\\": \\\"Vector Store Info\\\"},\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        vectorstore_info: VectorStoreInfo,\\n        llm: BaseLanguageModel,\\n    ) -> Union[Tool, VectorStoreToolkit]:\\n        return VectorStoreToolkit(vectorstore_info=vectorstore_info, llm=llm)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Toolkit for interacting with a Vector Store.\",\"base_classes\":[\"Runnable\",\"BaseToolkit\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\",\"VectorStoreToolkit\"],\"display_name\":\"VectorStoreToolkit\",\"documentation\":\"\",\"custom_fields\":{\"vectorstore_info\":null,\"llm\":null},\"output_types\":[\"Tool\",\"VectorStoreToolkit\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"Metaphor\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Union\\n\\nfrom langchain.agents import tool\\nfrom langchain.agents.agent_toolkits.base import BaseToolkit\\nfrom langchain.tools import Tool\\nfrom metaphor_python import Metaphor  # type: ignore\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass MetaphorToolkit(CustomComponent):\\n    display_name: str = \\\"Metaphor\\\"\\n    description: str = \\\"Metaphor Toolkit\\\"\\n    documentation = \\\"https://python.langchain.com/docs/integrations/tools/metaphor_search\\\"\\n    beta: bool = True\\n    # api key should be password = True\\n    field_config = {\\n        \\\"metaphor_api_key\\\": {\\\"display_name\\\": \\\"Metaphor API Key\\\", \\\"password\\\": True},\\n        \\\"code\\\": {\\\"advanced\\\": True},\\n    }\\n\\n    def build(\\n        self,\\n        metaphor_api_key: str,\\n        use_autoprompt: bool = True,\\n        search_num_results: int = 5,\\n        similar_num_results: int = 5,\\n    ) -> Union[Tool, BaseToolkit]:\\n        # If documents, then we need to create a Vectara instance using .from_documents\\n        client = Metaphor(api_key=metaphor_api_key)\\n\\n        @tool\\n        def search(query: str):\\n            \\\"\\\"\\\"Call search engine with a query.\\\"\\\"\\\"\\n            return client.search(query, use_autoprompt=use_autoprompt, num_results=search_num_results)\\n\\n        @tool\\n        def get_contents(ids: List[str]):\\n            \\\"\\\"\\\"Get contents of a webpage.\\n\\n            The ids passed in should be a list of ids as fetched from `search`.\\n            \\\"\\\"\\\"\\n            return client.get_contents(ids)\\n\\n        @tool\\n        def find_similar(url: str):\\n            \\\"\\\"\\\"Get search results similar to a given URL.\\n\\n            The url passed in should be a URL returned from `search`\\n            \\\"\\\"\\\"\\n            return client.find_similar(url, num_results=similar_num_results)\\n\\n        return [search, get_contents, find_similar]  # type: ignore\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":true,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"metaphor_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"metaphor_api_key\",\"display_name\":\"Metaphor API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"search_num_results\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":5,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"search_num_results\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"similar_num_results\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":5,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"similar_num_results\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"use_autoprompt\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"use_autoprompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Metaphor Toolkit\",\"base_classes\":[\"Runnable\",\"BaseToolkit\",\"Generic\",\"BaseTool\",\"RunnableSerializable\",\"Tool\",\"Serializable\",\"object\"],\"display_name\":\"Metaphor\",\"documentation\":\"https://python.langchain.com/docs/integrations/tools/metaphor_search\",\"custom_fields\":{\"metaphor_api_key\":null,\"use_autoprompt\":null,\"search_num_results\":null,\"similar_num_results\":null},\"output_types\":[\"Tool\",\"BaseToolkit\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"wrappers\":{\"TextRequestsWrapper\":{\"template\":{\"aiosession\":{\"type\":\"ClientSession\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"aiosession\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"auth\":{\"type\":\"Any\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"auth\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"headers\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"{\\\"Authorization\\\": \\\"Bearer <token>\\\"}\",\"fileTypes\":[],\"password\":false,\"name\":\"headers\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"response_content_type\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":false,\"multiline\":false,\"value\":\"text\",\"fileTypes\":[],\"password\":false,\"name\":\"response_content_type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"TextRequestsWrapper\"},\"description\":\"Lightweight wrapper around requests library, with async support.\",\"base_classes\":[\"TextRequestsWrapper\",\"GenericRequestsWrapper\"],\"display_name\":\"TextRequestsWrapper\",\"documentation\":\"\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false}},\"embeddings\":{\"OpenAIEmbeddings\":{\"template\":{\"allowed_special\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":[],\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"allowed_special\",\"display_name\":\"Allowed Special\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"chunk_size\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1000,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chunk_size\",\"display_name\":\"Chunk Size\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"client\":{\"type\":\"Any\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"client\",\"display_name\":\"Client\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Any, Callable, Dict, List, Optional, Union\\n\\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import NestedDict\\nfrom pydantic.v1.types import SecretStr\\n\\n\\nclass OpenAIEmbeddingsComponent(CustomComponent):\\n    display_name = \\\"OpenAIEmbeddings\\\"\\n    description = \\\"OpenAI embedding models\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"allowed_special\\\": {\\n                \\\"display_name\\\": \\\"Allowed Special\\\",\\n                \\\"advanced\\\": True,\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"is_list\\\": True,\\n            },\\n            \\\"default_headers\\\": {\\n                \\\"display_name\\\": \\\"Default Headers\\\",\\n                \\\"advanced\\\": True,\\n                \\\"field_type\\\": \\\"dict\\\",\\n            },\\n            \\\"default_query\\\": {\\n                \\\"display_name\\\": \\\"Default Query\\\",\\n                \\\"advanced\\\": True,\\n                \\\"field_type\\\": \\\"NestedDict\\\",\\n            },\\n            \\\"disallowed_special\\\": {\\n                \\\"display_name\\\": \\\"Disallowed Special\\\",\\n                \\\"advanced\\\": True,\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"is_list\\\": True,\\n            },\\n            \\\"chunk_size\\\": {\\\"display_name\\\": \\\"Chunk Size\\\", \\\"advanced\\\": True},\\n            \\\"client\\\": {\\\"display_name\\\": \\\"Client\\\", \\\"advanced\\\": True},\\n            \\\"deployment\\\": {\\\"display_name\\\": \\\"Deployment\\\", \\\"advanced\\\": True},\\n            \\\"embedding_ctx_length\\\": {\\n                \\\"display_name\\\": \\\"Embedding Context Length\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"max_retries\\\": {\\\"display_name\\\": \\\"Max Retries\\\", \\\"advanced\\\": True},\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model\\\",\\n                \\\"advanced\\\": False,\\n                \\\"options\\\": [\\\"text-embedding-3-small\\\", \\\"text-embedding-3-large\\\", \\\"text-embedding-ada-002\\\"],\\n            },\\n            \\\"model_kwargs\\\": {\\\"display_name\\\": \\\"Model Kwargs\\\", \\\"advanced\\\": True},\\n            \\\"openai_api_base\\\": {\\\"display_name\\\": \\\"OpenAI API Base\\\", \\\"password\\\": True, \\\"advanced\\\": True},\\n            \\\"openai_api_key\\\": {\\\"display_name\\\": \\\"OpenAI API Key\\\", \\\"password\\\": True},\\n            \\\"openai_api_type\\\": {\\\"display_name\\\": \\\"OpenAI API Type\\\", \\\"advanced\\\": True, \\\"password\\\": True},\\n            \\\"openai_api_version\\\": {\\n                \\\"display_name\\\": \\\"OpenAI API Version\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"openai_organization\\\": {\\n                \\\"display_name\\\": \\\"OpenAI Organization\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"openai_proxy\\\": {\\\"display_name\\\": \\\"OpenAI Proxy\\\", \\\"advanced\\\": True},\\n            \\\"request_timeout\\\": {\\\"display_name\\\": \\\"Request Timeout\\\", \\\"advanced\\\": True},\\n            \\\"show_progress_bar\\\": {\\n                \\\"display_name\\\": \\\"Show Progress Bar\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"skip_empty\\\": {\\\"display_name\\\": \\\"Skip Empty\\\", \\\"advanced\\\": True},\\n            \\\"tiktoken_model_name\\\": {\\\"display_name\\\": \\\"TikToken Model Name\\\"},\\n            \\\"tikToken_enable\\\": {\\\"display_name\\\": \\\"TikToken Enable\\\", \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        default_headers: Optional[Dict[str, str]] = None,\\n        default_query: Optional[NestedDict] = {},\\n        allowed_special: List[str] = [],\\n        disallowed_special: List[str] = [\\\"all\\\"],\\n        chunk_size: int = 1000,\\n        client: Optional[Any] = None,\\n        deployment: str = \\\"text-embedding-3-small\\\",\\n        embedding_ctx_length: int = 8191,\\n        max_retries: int = 6,\\n        model: str = \\\"text-embedding-3-small\\\",\\n        model_kwargs: NestedDict = {},\\n        openai_api_base: Optional[str] = None,\\n        openai_api_key: Optional[str] = \\\"\\\",\\n        openai_api_type: Optional[str] = None,\\n        openai_api_version: Optional[str] = None,\\n        openai_organization: Optional[str] = None,\\n        openai_proxy: Optional[str] = None,\\n        request_timeout: Optional[float] = None,\\n        show_progress_bar: bool = False,\\n        skip_empty: bool = False,\\n        tiktoken_enable: bool = True,\\n        tiktoken_model_name: Optional[str] = None,\\n    ) -> Union[OpenAIEmbeddings, Callable]:\\n        # This is to avoid errors with Vector Stores (e.g Chroma)\\n        if disallowed_special == [\\\"all\\\"]:\\n            disallowed_special = \\\"all\\\"  # type: ignore\\n\\n        api_key = SecretStr(openai_api_key) if openai_api_key else None\\n\\n        return OpenAIEmbeddings(\\n            tiktoken_enabled=tiktoken_enable,\\n            default_headers=default_headers,\\n            default_query=default_query,\\n            allowed_special=set(allowed_special),\\n            disallowed_special=\\\"all\\\",\\n            chunk_size=chunk_size,\\n            client=client,\\n            deployment=deployment,\\n            embedding_ctx_length=embedding_ctx_length,\\n            max_retries=max_retries,\\n            model=model,\\n            model_kwargs=model_kwargs,\\n            base_url=openai_api_base,\\n            api_key=api_key,\\n            openai_api_type=openai_api_type,\\n            api_version=openai_api_version,\\n            organization=openai_organization,\\n            openai_proxy=openai_proxy,\\n            timeout=request_timeout,\\n            show_progress_bar=show_progress_bar,\\n            skip_empty=skip_empty,\\n            tiktoken_model_name=tiktoken_model_name,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"default_headers\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"default_headers\",\"display_name\":\"Default Headers\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"default_query\":{\"type\":\"NestedDict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"default_query\",\"display_name\":\"Default Query\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"deployment\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"text-embedding-3-small\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"deployment\",\"display_name\":\"Deployment\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"disallowed_special\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":[\"all\"],\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"disallowed_special\",\"display_name\":\"Disallowed Special\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"embedding_ctx_length\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":8191,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding_ctx_length\",\"display_name\":\"Embedding Context Length\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"max_retries\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":6,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_retries\",\"display_name\":\"Max Retries\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"text-embedding-3-small\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"text-embedding-3-small\",\"text-embedding-3-large\",\"text-embedding-ada-002\"],\"name\":\"model\",\"display_name\":\"Model\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_kwargs\":{\"type\":\"NestedDict\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"openai_api_base\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"openai_api_base\",\"display_name\":\"OpenAI API Base\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_api_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"openai_api_key\",\"display_name\":\"OpenAI API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_api_type\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"openai_api_type\",\"display_name\":\"OpenAI API Type\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_api_version\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"openai_api_version\",\"display_name\":\"OpenAI API Version\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_organization\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"openai_organization\",\"display_name\":\"OpenAI Organization\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_proxy\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"openai_proxy\",\"display_name\":\"OpenAI Proxy\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"request_timeout\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"request_timeout\",\"display_name\":\"Request Timeout\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"show_progress_bar\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"show_progress_bar\",\"display_name\":\"Show Progress Bar\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"skip_empty\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"skip_empty\",\"display_name\":\"Skip Empty\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tiktoken_enable\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tiktoken_enable\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"tiktoken_model_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tiktoken_model_name\",\"display_name\":\"TikToken Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"OpenAI embedding models\",\"base_classes\":[\"Embeddings\",\"OpenAIEmbeddings\",\"Callable\"],\"display_name\":\"OpenAIEmbeddings\",\"documentation\":\"\",\"custom_fields\":{\"default_headers\":null,\"default_query\":null,\"allowed_special\":null,\"disallowed_special\":null,\"chunk_size\":null,\"client\":null,\"deployment\":null,\"embedding_ctx_length\":null,\"max_retries\":null,\"model\":null,\"model_kwargs\":null,\"openai_api_base\":null,\"openai_api_key\":null,\"openai_api_type\":null,\"openai_api_version\":null,\"openai_organization\":null,\"openai_proxy\":null,\"request_timeout\":null,\"show_progress_bar\":null,\"skip_empty\":null,\"tiktoken_enable\":null,\"tiktoken_model_name\":null},\"output_types\":[\"OpenAIEmbeddings\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"CohereEmbeddings\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_community.embeddings.cohere import CohereEmbeddings\\nfrom langflow import CustomComponent\\n\\n\\nclass CohereEmbeddingsComponent(CustomComponent):\\n    display_name = \\\"CohereEmbeddings\\\"\\n    description = \\\"Cohere embedding models.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"cohere_api_key\\\": {\\\"display_name\\\": \\\"Cohere API Key\\\", \\\"password\\\": True},\\n            \\\"model\\\": {\\\"display_name\\\": \\\"Model\\\", \\\"default\\\": \\\"embed-english-v2.0\\\", \\\"advanced\\\": True},\\n            \\\"truncate\\\": {\\\"display_name\\\": \\\"Truncate\\\", \\\"advanced\\\": True},\\n            \\\"max_retries\\\": {\\\"display_name\\\": \\\"Max Retries\\\", \\\"advanced\\\": True},\\n            \\\"user_agent\\\": {\\\"display_name\\\": \\\"User Agent\\\", \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        request_timeout: Optional[float] = None,\\n        cohere_api_key: str = \\\"\\\",\\n        max_retries: Optional[int] = None,\\n        model: str = \\\"embed-english-v2.0\\\",\\n        truncate: Optional[str] = None,\\n        user_agent: str = \\\"langchain\\\",\\n    ) -> CohereEmbeddings:\\n        return CohereEmbeddings(  # type: ignore\\n            max_retries=max_retries,\\n            user_agent=user_agent,\\n            request_timeout=request_timeout,\\n            cohere_api_key=cohere_api_key,\\n            model=model,\\n            truncate=truncate,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"cohere_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"cohere_api_key\",\"display_name\":\"Cohere API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_retries\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_retries\",\"display_name\":\"Max Retries\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"embed-english-v2.0\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model\",\"display_name\":\"Model\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"request_timeout\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"request_timeout\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"truncate\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"truncate\",\"display_name\":\"Truncate\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"user_agent\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"langchain\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"user_agent\",\"display_name\":\"User Agent\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Cohere embedding models.\",\"base_classes\":[\"Embeddings\",\"CohereEmbeddings\"],\"display_name\":\"CohereEmbeddings\",\"documentation\":\"\",\"custom_fields\":{\"request_timeout\":null,\"cohere_api_key\":null,\"max_retries\":null,\"model\":null,\"truncate\":null,\"user_agent\":null},\"output_types\":[\"CohereEmbeddings\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"HuggingFaceEmbeddings\":{\"template\":{\"cache_folder\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"cache_folder\",\"display_name\":\"Cache Folder\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom typing import Optional, Dict\\nfrom langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\\n\\n\\nclass HuggingFaceEmbeddingsComponent(CustomComponent):\\n    display_name = \\\"HuggingFaceEmbeddings\\\"\\n    description = \\\"HuggingFace sentence_transformers embedding models.\\\"\\n    documentation = (\\n        \\\"https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/sentence_transformers\\\"\\n    )\\n\\n    def build_config(self):\\n        return {\\n            \\\"cache_folder\\\": {\\\"display_name\\\": \\\"Cache Folder\\\", \\\"advanced\\\": True},\\n            \\\"encode_kwargs\\\": {\\\"display_name\\\": \\\"Encode Kwargs\\\", \\\"advanced\\\": True, \\\"field_type\\\": \\\"dict\\\"},\\n            \\\"model_kwargs\\\": {\\\"display_name\\\": \\\"Model Kwargs\\\", \\\"field_type\\\": \\\"dict\\\", \\\"advanced\\\": True},\\n            \\\"model_name\\\": {\\\"display_name\\\": \\\"Model Name\\\"},\\n            \\\"multi_process\\\": {\\\"display_name\\\": \\\"Multi Process\\\", \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        cache_folder: Optional[str] = None,\\n        encode_kwargs: Optional[Dict] = {},\\n        model_kwargs: Optional[Dict] = {},\\n        model_name: str = \\\"sentence-transformers/all-mpnet-base-v2\\\",\\n        multi_process: bool = False,\\n    ) -> HuggingFaceEmbeddings:\\n        return HuggingFaceEmbeddings(\\n            cache_folder=cache_folder,\\n            encode_kwargs=encode_kwargs,\\n            model_kwargs=model_kwargs,\\n            model_name=model_name,\\n            multi_process=multi_process,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"encode_kwargs\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"encode_kwargs\",\"display_name\":\"Encode Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_kwargs\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"sentence-transformers/all-mpnet-base-v2\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_name\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"multi_process\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"multi_process\",\"display_name\":\"Multi Process\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"HuggingFace sentence_transformers embedding models.\",\"base_classes\":[\"Embeddings\",\"HuggingFaceEmbeddings\"],\"display_name\":\"HuggingFaceEmbeddings\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/sentence_transformers\",\"custom_fields\":{\"cache_folder\":null,\"encode_kwargs\":null,\"model_kwargs\":null,\"model_name\":null,\"multi_process\":null},\"output_types\":[\"HuggingFaceEmbeddings\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"VertexAIEmbeddings\":{\"template\":{\"credentials\":{\"type\":\"file\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".json\"],\"file_path\":\"\",\"password\":false,\"name\":\"credentials\",\"display_name\":\"Credentials\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langchain_community.embeddings import VertexAIEmbeddings\\nfrom typing import Optional, List\\n\\n\\nclass VertexAIEmbeddingsComponent(CustomComponent):\\n    display_name = \\\"VertexAIEmbeddings\\\"\\n    description = \\\"Google Cloud VertexAI embedding models.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"credentials\\\": {\\n                \\\"display_name\\\": \\\"Credentials\\\",\\n                \\\"value\\\": \\\"\\\",\\n                \\\"file_types\\\": [\\\".json\\\"],\\n                \\\"field_type\\\": \\\"file\\\",\\n            },\\n            \\\"instance\\\": {\\n                \\\"display_name\\\": \\\"instance\\\",\\n                \\\"advanced\\\": True,\\n                \\\"field_type\\\": \\\"dict\\\",\\n            },\\n            \\\"location\\\": {\\n                \\\"display_name\\\": \\\"Location\\\",\\n                \\\"value\\\": \\\"us-central1\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"max_output_tokens\\\": {\\\"display_name\\\": \\\"Max Output Tokens\\\", \\\"value\\\": 128},\\n            \\\"max_retries\\\": {\\n                \\\"display_name\\\": \\\"Max Retries\\\",\\n                \\\"value\\\": 6,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"model_name\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"value\\\": \\\"textembedding-gecko\\\",\\n            },\\n            \\\"n\\\": {\\\"display_name\\\": \\\"N\\\", \\\"value\\\": 1, \\\"advanced\\\": True},\\n            \\\"project\\\": {\\\"display_name\\\": \\\"Project\\\", \\\"advanced\\\": True},\\n            \\\"request_parallelism\\\": {\\n                \\\"display_name\\\": \\\"Request Parallelism\\\",\\n                \\\"value\\\": 5,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"stop\\\": {\\\"display_name\\\": \\\"Stop\\\", \\\"advanced\\\": True},\\n            \\\"streaming\\\": {\\n                \\\"display_name\\\": \\\"Streaming\\\",\\n                \\\"value\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"temperature\\\": {\\\"display_name\\\": \\\"Temperature\\\", \\\"value\\\": 0.0},\\n            \\\"top_k\\\": {\\\"display_name\\\": \\\"Top K\\\", \\\"value\\\": 40, \\\"advanced\\\": True},\\n            \\\"top_p\\\": {\\\"display_name\\\": \\\"Top P\\\", \\\"value\\\": 0.95, \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        instance: Optional[str] = None,\\n        credentials: Optional[str] = None,\\n        location: str = \\\"us-central1\\\",\\n        max_output_tokens: int = 128,\\n        max_retries: int = 6,\\n        model_name: str = \\\"textembedding-gecko\\\",\\n        n: int = 1,\\n        project: Optional[str] = None,\\n        request_parallelism: int = 5,\\n        stop: Optional[List[str]] = None,\\n        streaming: bool = False,\\n        temperature: float = 0.0,\\n        top_k: int = 40,\\n        top_p: float = 0.95,\\n    ) -> VertexAIEmbeddings:\\n        return VertexAIEmbeddings(\\n            instance=instance,\\n            credentials=credentials,\\n            location=location,\\n            max_output_tokens=max_output_tokens,\\n            max_retries=max_retries,\\n            model_name=model_name,\\n            n=n,\\n            project=project,\\n            request_parallelism=request_parallelism,\\n            stop=stop,\\n            streaming=streaming,\\n            temperature=temperature,\\n            top_k=top_k,\\n            top_p=top_p,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"instance\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"instance\",\"display_name\":\"instance\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"location\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"us-central1\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"location\",\"display_name\":\"Location\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_output_tokens\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":128,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_output_tokens\",\"display_name\":\"Max Output Tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"max_retries\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":6,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_retries\",\"display_name\":\"Max Retries\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"textembedding-gecko\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_name\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"n\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n\",\"display_name\":\"N\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"project\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"project\",\"display_name\":\"Project\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"request_parallelism\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":5,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"request_parallelism\",\"display_name\":\"Request Parallelism\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"stop\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"stop\",\"display_name\":\"Stop\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"streaming\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"streaming\",\"display_name\":\"Streaming\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"temperature\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":40,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.95,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Google Cloud VertexAI embedding models.\",\"base_classes\":[\"_VertexAICommon\",\"Embeddings\",\"_VertexAIBase\",\"VertexAIEmbeddings\"],\"display_name\":\"VertexAIEmbeddings\",\"documentation\":\"\",\"custom_fields\":{\"instance\":null,\"credentials\":null,\"location\":null,\"max_output_tokens\":null,\"max_retries\":null,\"model_name\":null,\"n\":null,\"project\":null,\"request_parallelism\":null,\"stop\":null,\"streaming\":null,\"temperature\":null,\"top_k\":null,\"top_p\":null},\"output_types\":[\"VertexAIEmbeddings\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"OllamaEmbeddings\":{\"template\":{\"base_url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"http://localhost:11434\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"base_url\",\"display_name\":\"Ollama Base URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langflow import CustomComponent\\nfrom langchain.embeddings.base import Embeddings\\nfrom langchain_community.embeddings import OllamaEmbeddings\\n\\n\\nclass OllamaEmbeddingsComponent(CustomComponent):\\n    \\\"\\\"\\\"\\n    A custom component for implementing an Embeddings Model using Ollama.\\n    \\\"\\\"\\\"\\n\\n    display_name: str = \\\"Ollama Embeddings\\\"\\n    description: str = \\\"Embeddings model from Ollama.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/integrations/text_embedding/ollama\\\"\\n    beta = True\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Ollama Model\\\",\\n            },\\n            \\\"base_url\\\": {\\\"display_name\\\": \\\"Ollama Base URL\\\"},\\n            \\\"temperature\\\": {\\\"display_name\\\": \\\"Model Temperature\\\"},\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        model: str = \\\"llama2\\\",\\n        base_url: str = \\\"http://localhost:11434\\\",\\n        temperature: Optional[float] = None,\\n    ) -> Embeddings:\\n        try:\\n            output = OllamaEmbeddings(model=model, base_url=base_url, temperature=temperature)  # type: ignore\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to Ollama API.\\\") from e\\n        return output\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"llama2\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model\",\"display_name\":\"Ollama Model\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Model Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Embeddings model from Ollama.\",\"base_classes\":[\"Embeddings\"],\"display_name\":\"Ollama Embeddings\",\"documentation\":\"https://python.langchain.com/docs/integrations/text_embedding/ollama\",\"custom_fields\":{\"model\":null,\"base_url\":null,\"temperature\":null},\"output_types\":[\"Embeddings\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"AmazonBedrockEmbeddings\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.embeddings.base import Embeddings\\nfrom langchain_community.embeddings import BedrockEmbeddings\\n\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass AmazonBedrockEmeddingsComponent(CustomComponent):\\n    \\\"\\\"\\\"\\n    A custom component for implementing an Embeddings Model using Amazon Bedrock.\\n    \\\"\\\"\\\"\\n\\n    display_name: str = \\\"Amazon Bedrock Embeddings\\\"\\n    description: str = \\\"Embeddings model from Amazon Bedrock.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/bedrock\\\"\\n    beta = True\\n\\n    def build_config(self):\\n        return {\\n            \\\"model_id\\\": {\\n                \\\"display_name\\\": \\\"Model Id\\\",\\n                \\\"options\\\": [\\\"amazon.titan-embed-text-v1\\\"],\\n            },\\n            \\\"credentials_profile_name\\\": {\\\"display_name\\\": \\\"Credentials Profile Name\\\"},\\n            \\\"endpoint_url\\\": {\\\"display_name\\\": \\\"Bedrock Endpoint URL\\\"},\\n            \\\"region_name\\\": {\\\"display_name\\\": \\\"AWS Region\\\"},\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        model_id: str = \\\"amazon.titan-embed-text-v1\\\",\\n        credentials_profile_name: Optional[str] = None,\\n        endpoint_url: Optional[str] = None,\\n        region_name: Optional[str] = None,\\n    ) -> Embeddings:\\n        try:\\n            output = BedrockEmbeddings(\\n                credentials_profile_name=credentials_profile_name,\\n                model_id=model_id,\\n                endpoint_url=endpoint_url,\\n                region_name=region_name,\\n            )  # type: ignore\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to AmazonBedrock API.\\\") from e\\n        return output\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"credentials_profile_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"credentials_profile_name\",\"display_name\":\"Credentials Profile Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"endpoint_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"endpoint_url\",\"display_name\":\"Bedrock Endpoint URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"amazon.titan-embed-text-v1\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"amazon.titan-embed-text-v1\"],\"name\":\"model_id\",\"display_name\":\"Model Id\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"region_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"region_name\",\"display_name\":\"AWS Region\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Embeddings model from Amazon Bedrock.\",\"base_classes\":[\"Embeddings\"],\"display_name\":\"Amazon Bedrock Embeddings\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/bedrock\",\"custom_fields\":{\"model_id\":null,\"credentials_profile_name\":null,\"endpoint_url\":null,\"region_name\":null},\"output_types\":[\"Embeddings\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"AzureOpenAIEmbeddings\":{\"template\":{\"api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_key\",\"display_name\":\"API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"api_version\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"2023-08-01-preview\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"2022-12-01\",\"2023-03-15-preview\",\"2023-05-15\",\"2023-06-01-preview\",\"2023-07-01-preview\",\"2023-08-01-preview\"],\"name\":\"api_version\",\"display_name\":\"API Version\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"azure_deployment\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"azure_deployment\",\"display_name\":\"Deployment Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"azure_endpoint\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"azure_endpoint\",\"display_name\":\"Azure Endpoint\",\"advanced\":false,\"dynamic\":false,\"info\":\"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langchain.embeddings.base import Embeddings\\nfrom langchain_community.embeddings import AzureOpenAIEmbeddings\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass AzureOpenAIEmbeddingsComponent(CustomComponent):\\n    display_name: str = \\\"AzureOpenAIEmbeddings\\\"\\n    description: str = \\\"Embeddings model from Azure OpenAI.\\\"\\n    documentation: str = \\\"https://python.langchain.com/docs/integrations/text_embedding/azureopenai\\\"\\n    beta = False\\n\\n    API_VERSION_OPTIONS = [\\n        \\\"2022-12-01\\\",\\n        \\\"2023-03-15-preview\\\",\\n        \\\"2023-05-15\\\",\\n        \\\"2023-06-01-preview\\\",\\n        \\\"2023-07-01-preview\\\",\\n        \\\"2023-08-01-preview\\\",\\n    ]\\n\\n    def build_config(self):\\n        return {\\n            \\\"azure_endpoint\\\": {\\n                \\\"display_name\\\": \\\"Azure Endpoint\\\",\\n                \\\"required\\\": True,\\n                \\\"info\\\": \\\"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\\\",\\n            },\\n            \\\"azure_deployment\\\": {\\n                \\\"display_name\\\": \\\"Deployment Name\\\",\\n                \\\"required\\\": True,\\n            },\\n            \\\"api_version\\\": {\\n                \\\"display_name\\\": \\\"API Version\\\",\\n                \\\"options\\\": self.API_VERSION_OPTIONS,\\n                \\\"value\\\": self.API_VERSION_OPTIONS[-1],\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"api_key\\\": {\\n                \\\"display_name\\\": \\\"API Key\\\",\\n                \\\"required\\\": True,\\n                \\\"password\\\": True,\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        azure_endpoint: str,\\n        azure_deployment: str,\\n        api_version: str,\\n        api_key: str,\\n    ) -> Embeddings:\\n        try:\\n            embeddings = AzureOpenAIEmbeddings(\\n                azure_endpoint=azure_endpoint,\\n                azure_deployment=azure_deployment,\\n                api_version=api_version,\\n                api_key=api_key,\\n            )\\n\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to AzureOpenAIEmbeddings API.\\\") from e\\n\\n        return embeddings\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Embeddings model from Azure OpenAI.\",\"base_classes\":[\"Embeddings\"],\"display_name\":\"AzureOpenAIEmbeddings\",\"documentation\":\"https://python.langchain.com/docs/integrations/text_embedding/azureopenai\",\"custom_fields\":{\"azure_endpoint\":null,\"azure_deployment\":null,\"api_version\":null,\"api_key\":null},\"output_types\":[\"Embeddings\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"HuggingFaceInferenceAPIEmbeddings\":{\"template\":{\"api_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_key\",\"display_name\":\"API Key\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"api_url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"http://localhost:8080\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"api_url\",\"display_name\":\"API URL\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"cache_folder\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"cache_folder\",\"display_name\":\"Cache Folder\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Dict, Optional\\n\\nfrom langchain_community.embeddings.huggingface import HuggingFaceInferenceAPIEmbeddings\\nfrom langflow import CustomComponent\\nfrom pydantic.v1.types import SecretStr\\n\\n\\nclass HuggingFaceInferenceAPIEmbeddingsComponent(CustomComponent):\\n    display_name = \\\"HuggingFaceInferenceAPIEmbeddings\\\"\\n    description = \\\"HuggingFace sentence_transformers embedding models, API version.\\\"\\n    documentation = \\\"https://github.com/huggingface/text-embeddings-inference\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"api_key\\\": {\\\"display_name\\\": \\\"API Key\\\", \\\"password\\\": True, \\\"advanced\\\": True},\\n            \\\"api_url\\\": {\\\"display_name\\\": \\\"API URL\\\", \\\"advanced\\\": True},\\n            \\\"model_name\\\": {\\\"display_name\\\": \\\"Model Name\\\"},\\n            \\\"cache_folder\\\": {\\\"display_name\\\": \\\"Cache Folder\\\", \\\"advanced\\\": True},\\n            \\\"encode_kwargs\\\": {\\\"display_name\\\": \\\"Encode Kwargs\\\", \\\"advanced\\\": True, \\\"field_type\\\": \\\"dict\\\"},\\n            \\\"model_kwargs\\\": {\\\"display_name\\\": \\\"Model Kwargs\\\", \\\"field_type\\\": \\\"dict\\\", \\\"advanced\\\": True},\\n            \\\"multi_process\\\": {\\\"display_name\\\": \\\"Multi Process\\\", \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        api_key: Optional[str] = \\\"\\\",\\n        api_url: str = \\\"http://localhost:8080\\\",\\n        model_name: str = \\\"BAAI/bge-large-en-v1.5\\\",\\n        cache_folder: Optional[str] = None,\\n        encode_kwargs: Optional[Dict] = {},\\n        model_kwargs: Optional[Dict] = {},\\n        multi_process: bool = False,\\n    ) -> HuggingFaceInferenceAPIEmbeddings:\\n        if api_key:\\n            secret_api_key = SecretStr(api_key)\\n        else:\\n            raise ValueError(\\\"API Key is required\\\")\\n        return HuggingFaceInferenceAPIEmbeddings(\\n            api_key=secret_api_key,\\n            api_url=api_url,\\n            model_name=model_name,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"encode_kwargs\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"encode_kwargs\",\"display_name\":\"Encode Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_kwargs\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"BAAI/bge-large-en-v1.5\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_name\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"multi_process\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"multi_process\",\"display_name\":\"Multi Process\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"HuggingFace sentence_transformers embedding models, API version.\",\"base_classes\":[\"Embeddings\",\"HuggingFaceInferenceAPIEmbeddings\"],\"display_name\":\"HuggingFaceInferenceAPIEmbeddings\",\"documentation\":\"https://github.com/huggingface/text-embeddings-inference\",\"custom_fields\":{\"api_key\":null,\"api_url\":null,\"model_name\":null,\"cache_folder\":null,\"encode_kwargs\":null,\"model_kwargs\":null,\"multi_process\":null},\"output_types\":[\"HuggingFaceInferenceAPIEmbeddings\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"documentloaders\":{\"AZLyricsLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"web_path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"web_path\",\"display_name\":\"Web Page\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"AZLyricsLoader\"},\"description\":\"Load `AZLyrics` webpages.\",\"base_classes\":[\"Document\"],\"display_name\":\"AZLyricsLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/azlyrics\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"AirbyteJSONLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".json\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"AirbyteJSONLoader\"},\"description\":\"Load local `Airbyte` json files.\",\"base_classes\":[\"Document\"],\"display_name\":\"AirbyteJSONLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/airbyte_json\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"BSHTMLLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".html\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"BSHTMLLoader\"},\"description\":\"Load `HTML` files and parse them with `beautiful soup`.\",\"base_classes\":[\"Document\"],\"display_name\":\"BSHTMLLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/html\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"CSVLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".csv\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CSVLoader\"},\"description\":\"Load a `CSV` file into a list of Documents.\",\"base_classes\":[\"Document\"],\"display_name\":\"CSVLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/csv\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"CoNLLULoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".csv\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CoNLLULoader\"},\"description\":\"Load `CoNLL-U` files.\",\"base_classes\":[\"Document\"],\"display_name\":\"CoNLLULoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/conll-u\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"CollegeConfidentialLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"web_path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"web_path\",\"display_name\":\"Web Page\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CollegeConfidentialLoader\"},\"description\":\"Load `College Confidential` webpages.\",\"base_classes\":[\"Document\"],\"display_name\":\"CollegeConfidentialLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/college_confidential\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"DirectoryLoader\":{\"template\":{\"glob\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"**/*.txt\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"glob\",\"display_name\":\"glob\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"load_hidden\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"False\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"load_hidden\",\"display_name\":\"Load hidden files\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"max_concurrency\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_concurrency\",\"display_name\":\"Max concurrency\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"path\",\"display_name\":\"Local directory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"recursive\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"True\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"recursive\",\"display_name\":\"Recursive\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"silent_errors\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"False\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"silent_errors\",\"display_name\":\"Silent errors\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"use_multithreading\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"True\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"use_multithreading\",\"display_name\":\"Use multithreading\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"DirectoryLoader\"},\"description\":\"Load from a directory.\",\"base_classes\":[\"Document\"],\"display_name\":\"DirectoryLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/file_directory\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"EverNoteLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".xml\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"EverNoteLoader\"},\"description\":\"Load from `EverNote`.\",\"base_classes\":[\"Document\"],\"display_name\":\"EverNoteLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/evernote\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"FacebookChatLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".json\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"FacebookChatLoader\"},\"description\":\"Load `Facebook Chat` messages directory dump.\",\"base_classes\":[\"Document\"],\"display_name\":\"FacebookChatLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/facebook_chat\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"GitLoader\":{\"template\":{\"branch\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"branch\",\"display_name\":\"Branch\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"clone_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"clone_url\",\"display_name\":\"Clone URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"file_filter\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"file_filter\",\"display_name\":\"File extensions (comma-separated)\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"repo_path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"repo_path\",\"display_name\":\"Path to repository\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"GitLoader\"},\"description\":\"Load `Git` repository files.\",\"base_classes\":[\"Document\"],\"display_name\":\"GitLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/git\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"GitbookLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"web_page\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"web_page\",\"display_name\":\"Web Page\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"GitbookLoader\"},\"description\":\"Load `GitBook` data.\",\"base_classes\":[\"Document\"],\"display_name\":\"GitbookLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/gitbook\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"GutenbergLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"web_path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"web_path\",\"display_name\":\"Web Page\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"GutenbergLoader\"},\"description\":\"Load from `Gutenberg.org`.\",\"base_classes\":[\"Document\"],\"display_name\":\"GutenbergLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/gutenberg\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"HNLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"web_path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"web_path\",\"display_name\":\"Web Page\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"HNLoader\"},\"description\":\"Load `Hacker News` data.\",\"base_classes\":[\"Document\"],\"display_name\":\"HNLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/hacker_news\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"IFixitLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"web_path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"web_path\",\"display_name\":\"Web Page\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"IFixitLoader\"},\"description\":\"Load `iFixit` repair guides, device wikis and answers.\",\"base_classes\":[\"Document\"],\"display_name\":\"IFixitLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/ifixit\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"IMSDbLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"web_path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"web_path\",\"display_name\":\"Web Page\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"IMSDbLoader\"},\"description\":\"Load `IMSDb` webpages.\",\"base_classes\":[\"Document\"],\"display_name\":\"IMSDbLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/imsdb\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"NotionDirectoryLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"path\",\"display_name\":\"Local directory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"NotionDirectoryLoader\"},\"description\":\"Load `Notion directory` dump.\",\"base_classes\":[\"Document\"],\"display_name\":\"NotionDirectoryLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/notion\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"PyPDFLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".pdf\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"PyPDFLoader\"},\"description\":\"Load PDF using pypdf into list of documents.\",\"base_classes\":[\"Document\"],\"display_name\":\"PyPDFLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/pdf\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"PyPDFDirectoryLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"path\",\"display_name\":\"Local directory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"PyPDFDirectoryLoader\"},\"description\":\"Load a directory with `PDF` files using `pypdf` and chunks at character level.\",\"base_classes\":[\"Document\"],\"display_name\":\"PyPDFDirectoryLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/pdf\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"ReadTheDocsLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"path\",\"display_name\":\"Local directory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"ReadTheDocsLoader\"},\"description\":\"Load `ReadTheDocs` documentation directory.\",\"base_classes\":[\"Document\"],\"display_name\":\"ReadTheDocsLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/readthedocs_documentation\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"SRTLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".srt\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"SRTLoader\"},\"description\":\"Load `.srt` (subtitle) files.\",\"base_classes\":[\"Document\"],\"display_name\":\"SRTLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/subtitle\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"SlackDirectoryLoader\":{\"template\":{\"zip_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".zip\"],\"file_path\":\"\",\"password\":false,\"name\":\"zip_path\",\"display_name\":\"Path to zip file\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"workspace_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"workspace_url\",\"display_name\":\"Workspace URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"SlackDirectoryLoader\"},\"description\":\"Load from a `Slack` directory dump.\",\"base_classes\":[\"Document\"],\"display_name\":\"SlackDirectoryLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/slack\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"TextLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".txt\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"TextLoader\"},\"description\":\"Load text file.\",\"base_classes\":[\"Document\"],\"display_name\":\"TextLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"UnstructuredEmailLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".eml\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"UnstructuredEmailLoader\"},\"description\":\"Load email files using `Unstructured`.\",\"base_classes\":[\"Document\"],\"display_name\":\"UnstructuredEmailLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/email\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"UnstructuredHTMLLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".html\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"UnstructuredHTMLLoader\"},\"description\":\"Load `HTML` files using `Unstructured`.\",\"base_classes\":[\"Document\"],\"display_name\":\"UnstructuredHTMLLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/html\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"UnstructuredMarkdownLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".md\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"UnstructuredMarkdownLoader\"},\"description\":\"Load `Markdown` files using `Unstructured`.\",\"base_classes\":[\"Document\"],\"display_name\":\"UnstructuredMarkdownLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/markdown\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"UnstructuredPowerPointLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".pptx\",\".ppt\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"UnstructuredPowerPointLoader\"},\"description\":\"Load `Microsoft PowerPoint` files using `Unstructured`.\",\"base_classes\":[\"Document\"],\"display_name\":\"UnstructuredPowerPointLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/microsoft_powerpoint\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"UnstructuredWordDocumentLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[\".docx\",\".doc\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"UnstructuredWordDocumentLoader\"},\"description\":\"Load `Microsoft Word` file using `Unstructured`.\",\"base_classes\":[\"Document\"],\"display_name\":\"UnstructuredWordDocumentLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/microsoft_word\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"WebBaseLoader\":{\"template\":{\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"web_path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"web_path\",\"display_name\":\"Web Page\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"WebBaseLoader\"},\"description\":\"Load HTML pages using `urllib` and parse them with `BeautifulSoup'.\",\"base_classes\":[\"Document\"],\"display_name\":\"WebBaseLoader\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/web_base\",\"custom_fields\":{},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"FileLoader\":{\"template\":{\"file_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".json\",\".txt\",\".csv\",\".jsonl\",\".html\",\".htm\",\".conllu\",\".enex\",\".msg\",\".pdf\",\".srt\",\".eml\",\".md\",\".mdx\",\".pptx\",\".docx\"],\"file_path\":\"\",\"password\":false,\"name\":\"file_path\",\"display_name\":\"File Path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langchain_core.documents import Document\\n\\nfrom langflow import CustomComponent\\nfrom langflow.utils.constants import LOADERS_INFO\\n\\n\\nclass FileLoaderComponent(CustomComponent):\\n    display_name: str = \\\"File Loader\\\"\\n    description: str = \\\"Generic File Loader\\\"\\n    beta = True\\n\\n    def build_config(self):\\n        loader_options = [\\\"Automatic\\\"] + [loader_info[\\\"name\\\"] for loader_info in LOADERS_INFO]\\n\\n        file_types = []\\n        suffixes = []\\n\\n        for loader_info in LOADERS_INFO:\\n            if \\\"allowedTypes\\\" in loader_info:\\n                file_types.extend(loader_info[\\\"allowedTypes\\\"])\\n                suffixes.extend([f\\\".{ext}\\\" for ext in loader_info[\\\"allowedTypes\\\"]])\\n\\n        return {\\n            \\\"file_path\\\": {\\n                \\\"display_name\\\": \\\"File Path\\\",\\n                \\\"required\\\": True,\\n                \\\"field_type\\\": \\\"file\\\",\\n                \\\"file_types\\\": [\\n                    \\\"json\\\",\\n                    \\\"txt\\\",\\n                    \\\"csv\\\",\\n                    \\\"jsonl\\\",\\n                    \\\"html\\\",\\n                    \\\"htm\\\",\\n                    \\\"conllu\\\",\\n                    \\\"enex\\\",\\n                    \\\"msg\\\",\\n                    \\\"pdf\\\",\\n                    \\\"srt\\\",\\n                    \\\"eml\\\",\\n                    \\\"md\\\",\\n                    \\\"mdx\\\",\\n                    \\\"pptx\\\",\\n                    \\\"docx\\\",\\n                ],\\n                \\\"suffixes\\\": [\\n                    \\\".json\\\",\\n                    \\\".txt\\\",\\n                    \\\".csv\\\",\\n                    \\\".jsonl\\\",\\n                    \\\".html\\\",\\n                    \\\".htm\\\",\\n                    \\\".conllu\\\",\\n                    \\\".enex\\\",\\n                    \\\".msg\\\",\\n                    \\\".pdf\\\",\\n                    \\\".srt\\\",\\n                    \\\".eml\\\",\\n                    \\\".md\\\",\\n                    \\\".mdx\\\",\\n                    \\\".pptx\\\",\\n                    \\\".docx\\\",\\n                ],\\n                # \\\"file_types\\\" : file_types,\\n                # \\\"suffixes\\\": suffixes,\\n            },\\n            \\\"loader\\\": {\\n                \\\"display_name\\\": \\\"Loader\\\",\\n                \\\"is_list\\\": True,\\n                \\\"required\\\": True,\\n                \\\"options\\\": loader_options,\\n                \\\"value\\\": \\\"Automatic\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(self, file_path: str, loader: str) -> Document:\\n        file_type = file_path.split(\\\".\\\")[-1]\\n\\n        # Map the loader to the correct loader class\\n        selected_loader_info = None\\n        for loader_info in LOADERS_INFO:\\n            if loader_info[\\\"name\\\"] == loader:\\n                selected_loader_info = loader_info\\n                break\\n\\n        if selected_loader_info is None and loader != \\\"Automatic\\\":\\n            raise ValueError(f\\\"Loader {loader} not found in the loader info list\\\")\\n\\n        if loader == \\\"Automatic\\\":\\n            # Determine the loader based on the file type\\n            default_loader_info = None\\n            for info in LOADERS_INFO:\\n                if \\\"defaultFor\\\" in info and file_type in info[\\\"defaultFor\\\"]:\\n                    default_loader_info = info\\n                    break\\n\\n            if default_loader_info is None:\\n                raise ValueError(f\\\"No default loader found for file type: {file_type}\\\")\\n\\n            selected_loader_info = default_loader_info\\n        if isinstance(selected_loader_info, dict):\\n            loader_import: str = selected_loader_info[\\\"import\\\"]\\n        else:\\n            raise ValueError(f\\\"Loader info for {loader} is not a dict\\\\nLoader info:\\\\n{selected_loader_info}\\\")\\n        module_name, class_name = loader_import.rsplit(\\\".\\\", 1)\\n\\n        try:\\n            # Import the loader class\\n            loader_module = __import__(module_name, fromlist=[class_name])\\n            loader_instance = getattr(loader_module, class_name)\\n        except ImportError as e:\\n            raise ValueError(f\\\"Loader {loader} could not be imported\\\\nLoader info:\\\\n{selected_loader_info}\\\") from e\\n\\n        result = loader_instance(file_path=file_path)\\n        return result.load()\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"loader\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"Automatic\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"Automatic\",\"Airbyte JSON (.jsonl)\",\"JSON (.json)\",\"BeautifulSoup4 HTML (.html, .htm)\",\"CSV (.csv)\",\"CoNLL-U (.conllu)\",\"EverNote (.enex)\",\"Facebook Chat (.json)\",\"Outlook Message (.msg)\",\"PyPDF (.pdf)\",\"Subtitle (.str)\",\"Text (.txt)\",\"Unstructured Email (.eml)\",\"Unstructured HTML (.html, .htm)\",\"Unstructured Markdown (.md)\",\"Unstructured PowerPoint (.pptx)\",\"Unstructured Word (.docx)\"],\"name\":\"loader\",\"display_name\":\"Loader\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Generic File Loader\",\"base_classes\":[\"Serializable\",\"Document\"],\"display_name\":\"File Loader\",\"documentation\":\"\",\"custom_fields\":{\"file_path\":null,\"loader\":null},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"UrlLoader\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List\\n\\nfrom langchain import document_loaders\\nfrom langchain_core.documents import Document\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass UrlLoaderComponent(CustomComponent):\\n    display_name: str = \\\"Url Loader\\\"\\n    description: str = \\\"Generic Url Loader Component\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"web_path\\\": {\\n                \\\"display_name\\\": \\\"Url\\\",\\n                \\\"required\\\": True,\\n            },\\n            \\\"loader\\\": {\\n                \\\"display_name\\\": \\\"Loader\\\",\\n                \\\"is_list\\\": True,\\n                \\\"required\\\": True,\\n                \\\"options\\\": [\\n                    \\\"AZLyricsLoader\\\",\\n                    \\\"CollegeConfidentialLoader\\\",\\n                    \\\"GitbookLoader\\\",\\n                    \\\"HNLoader\\\",\\n                    \\\"IFixitLoader\\\",\\n                    \\\"IMSDbLoader\\\",\\n                    \\\"WebBaseLoader\\\",\\n                ],\\n                \\\"value\\\": \\\"WebBaseLoader\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(self, web_path: str, loader: str) -> List[Document]:\\n        try:\\n            loader_instance = getattr(document_loaders, loader)(web_path=web_path)\\n        except Exception as e:\\n            raise ValueError(f\\\"No loader found for: {web_path}\\\") from e\\n        docs = loader_instance.load()\\n        avg_length = sum(len(doc.page_content) for doc in docs if hasattr(doc, \\\"page_content\\\")) / len(docs)\\n        self.status = f\\\"\\\"\\\"{len(docs)} documents)\\n        \\\\nAvg. Document Length (characters): {int(avg_length)}\\n        Documents: {docs[:3]}...\\\"\\\"\\\"\\n        return docs\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"loader\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"WebBaseLoader\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"AZLyricsLoader\",\"CollegeConfidentialLoader\",\"GitbookLoader\",\"HNLoader\",\"IFixitLoader\",\"IMSDbLoader\",\"WebBaseLoader\"],\"name\":\"loader\",\"display_name\":\"Loader\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"web_path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"web_path\",\"display_name\":\"Url\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Generic Url Loader Component\",\"base_classes\":[\"Serializable\",\"Document\"],\"display_name\":\"Url Loader\",\"documentation\":\"\",\"custom_fields\":{\"web_path\":null,\"loader\":null},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"GatherRecords\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from concurrent import futures\\nfrom pathlib import Path\\nfrom typing import Any, Dict, List\\n\\nfrom langflow import CustomComponent\\nfrom langflow.schema import Record\\n\\n\\nclass GatherRecordsComponent(CustomComponent):\\n    display_name = \\\"Gather Records\\\"\\n    description = \\\"Gather records from a directory.\\\"\\n\\n    def build_config(self) -> Dict[str, Any]:\\n        return {\\n            \\\"load_hidden\\\": {\\n                \\\"display_name\\\": \\\"Load Hidden Files\\\",\\n                \\\"value\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"max_concurrency\\\": {\\n                \\\"display_name\\\": \\\"Max Concurrency\\\",\\n                \\\"value\\\": 10,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"path\\\": {\\\"display_name\\\": \\\"Local Directory\\\"},\\n            \\\"recursive\\\": {\\\"display_name\\\": \\\"Recursive\\\", \\\"value\\\": True, \\\"advanced\\\": True},\\n            \\\"use_multithreading\\\": {\\n                \\\"display_name\\\": \\\"Use Multithreading\\\",\\n                \\\"value\\\": True,\\n                \\\"advanced\\\": True,\\n            },\\n        }\\n\\n    def is_hidden(self, path: Path) -> bool:\\n        return path.name.startswith(\\\".\\\")\\n\\n    def retrieve_file_paths(\\n        self,\\n        path: str,\\n        types: List[str],\\n        load_hidden: bool,\\n        recursive: bool,\\n        depth: int,\\n    ) -> List[str]:\\n        path_obj = Path(path)\\n        if not path_obj.exists() or not path_obj.is_dir():\\n            raise ValueError(f\\\"Path {path} must exist and be a directory.\\\")\\n\\n        def match_types(p: Path) -> bool:\\n            return any(p.suffix == f\\\".{t}\\\" for t in types) if types else True\\n\\n        def is_not_hidden(p: Path) -> bool:\\n            return not self.is_hidden(p) or load_hidden\\n\\n        def walk_level(directory: Path, max_depth: int):\\n            directory = directory.resolve()\\n            prefix_length = len(directory.parts)\\n            for p in directory.rglob(\\\"*\\\" if recursive else \\\"[!.]*\\\"):\\n                if len(p.parts) - prefix_length <= max_depth:\\n                    yield p\\n\\n        glob = \\\"**/*\\\" if recursive else \\\"*\\\"\\n        paths = walk_level(path_obj, depth) if depth else path_obj.glob(glob)\\n        file_paths = [str(p) for p in paths if p.is_file() and match_types(p) and is_not_hidden(p)]\\n\\n        return file_paths\\n\\n    def parse_file_to_record(self, file_path: str, silent_errors: bool) -> Record:\\n        # Use the partition function to load the file\\n        from unstructured.partition.auto import partition\\n\\n        try:\\n            elements = partition(file_path)\\n        except Exception as e:\\n            if not silent_errors:\\n                raise ValueError(f\\\"Error loading file {file_path}: {e}\\\") from e\\n            return None\\n\\n        # Create a Record\\n        text = \\\"\\\\n\\\\n\\\".join([str(el) for el in elements])\\n        metadata = elements.metadata if hasattr(elements, \\\"metadata\\\") else {}\\n        metadata[\\\"file_path\\\"] = file_path\\n        record = Record(text=text, data=metadata)\\n        return record\\n\\n    def get_elements(\\n        self,\\n        file_paths: List[str],\\n        silent_errors: bool,\\n        max_concurrency: int,\\n        use_multithreading: bool,\\n    ) -> List[Record]:\\n        if use_multithreading:\\n            records = self.parallel_load_records(file_paths, silent_errors, max_concurrency)\\n        else:\\n            records = [self.parse_file_to_record(file_path, silent_errors) for file_path in file_paths]\\n        records = list(filter(None, records))\\n        return records\\n\\n    def parallel_load_records(self, file_paths: List[str], silent_errors: bool, max_concurrency: int) -> List[Record]:\\n        with futures.ThreadPoolExecutor(max_workers=max_concurrency) as executor:\\n            loaded_files = executor.map(\\n                lambda file_path: self.parse_file_to_record(file_path, silent_errors),\\n                file_paths,\\n            )\\n        return loaded_files\\n\\n    def build(\\n        self,\\n        path: str,\\n        types: List[str] = None,\\n        depth: int = 0,\\n        max_concurrency: int = 2,\\n        load_hidden: bool = False,\\n        recursive: bool = True,\\n        silent_errors: bool = False,\\n        use_multithreading: bool = True,\\n    ) -> List[Record]:\\n        resolved_path = self.resolve_path(path)\\n        file_paths = self.retrieve_file_paths(resolved_path, types, load_hidden, recursive, depth)\\n        loaded_records = []\\n\\n        if use_multithreading:\\n            loaded_records = self.parallel_load_records(file_paths, silent_errors, max_concurrency)\\n        else:\\n            loaded_records = [self.parse_file_to_record(file_path, silent_errors) for file_path in file_paths]\\n        loaded_records = list(filter(None, loaded_records))\\n        self.status = loaded_records\\n        return loaded_records\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"depth\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"depth\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"load_hidden\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"load_hidden\",\"display_name\":\"Load Hidden Files\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"max_concurrency\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_concurrency\",\"display_name\":\"Max Concurrency\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"path\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"path\",\"display_name\":\"Local Directory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"recursive\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"recursive\",\"display_name\":\"Recursive\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"silent_errors\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"silent_errors\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"types\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"types\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"use_multithreading\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"use_multithreading\",\"display_name\":\"Use Multithreading\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Gather records from a directory.\",\"base_classes\":[\"Record\"],\"display_name\":\"Gather Records\",\"documentation\":\"\",\"custom_fields\":{\"path\":null,\"types\":null,\"depth\":null,\"max_concurrency\":null,\"load_hidden\":null,\"recursive\":null,\"silent_errors\":null,\"use_multithreading\":null},\"output_types\":[\"Record\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"textsplitters\":{\"CharacterTextSplitter\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chunk_overlap\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":200,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chunk_overlap\",\"display_name\":\"Chunk Overlap\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chunk_size\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1000,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chunk_size\",\"display_name\":\"Chunk Size\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List\\n\\nfrom langchain.text_splitter import CharacterTextSplitter\\nfrom langchain_core.documents.base import Document\\nfrom langflow import CustomComponent\\n\\n\\nclass CharacterTextSplitterComponent(CustomComponent):\\n    display_name = \\\"CharacterTextSplitter\\\"\\n    description = \\\"Splitting text that looks at characters.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\"},\\n            \\\"chunk_overlap\\\": {\\\"display_name\\\": \\\"Chunk Overlap\\\", \\\"default\\\": 200},\\n            \\\"chunk_size\\\": {\\\"display_name\\\": \\\"Chunk Size\\\", \\\"default\\\": 1000},\\n            \\\"separator\\\": {\\\"display_name\\\": \\\"Separator\\\", \\\"default\\\": \\\"\\\\n\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        documents: List[Document],\\n        chunk_overlap: int = 200,\\n        chunk_size: int = 1000,\\n        separator: str = \\\"\\\\n\\\",\\n    ) -> List[Document]:\\n        # separator may come escaped from the frontend\\n        separator = separator.encode().decode(\\\"unicode_escape\\\")\\n        docs = CharacterTextSplitter(\\n            chunk_overlap=chunk_overlap,\\n            chunk_size=chunk_size,\\n            separator=separator,\\n        ).split_documents(documents)\\n        self.status = docs\\n        return docs\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"separator\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\\\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"separator\",\"display_name\":\"Separator\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Splitting text that looks at characters.\",\"base_classes\":[\"Serializable\",\"Document\"],\"display_name\":\"CharacterTextSplitter\",\"documentation\":\"\",\"custom_fields\":{\"documents\":null,\"chunk_overlap\":null,\"chunk_size\":null,\"separator\":null},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"RecursiveCharacterTextSplitter\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"The documents to split.\",\"title_case\":false},\"chunk_overlap\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":200,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chunk_overlap\",\"display_name\":\"Chunk Overlap\",\"advanced\":false,\"dynamic\":false,\"info\":\"The amount of overlap between chunks.\",\"title_case\":false},\"chunk_size\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1000,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chunk_size\",\"display_name\":\"Chunk Size\",\"advanced\":false,\"dynamic\":false,\"info\":\"The maximum length of each chunk.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_core.documents import Document\\n\\nfrom langflow import CustomComponent\\nfrom langflow.utils.util import build_loader_repr_from_documents\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\n\\n\\nclass RecursiveCharacterTextSplitterComponent(CustomComponent):\\n    display_name: str = \\\"Recursive Character Text Splitter\\\"\\n    description: str = \\\"Split text into chunks of a specified length.\\\"\\n    documentation: str = \\\"https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"documents\\\": {\\n                \\\"display_name\\\": \\\"Documents\\\",\\n                \\\"info\\\": \\\"The documents to split.\\\",\\n            },\\n            \\\"separators\\\": {\\n                \\\"display_name\\\": \\\"Separators\\\",\\n                \\\"info\\\": 'The characters to split on.\\\\nIf left empty defaults to [\\\"\\\\\\\\n\\\\\\\\n\\\", \\\"\\\\\\\\n\\\", \\\" \\\", \\\"\\\"].',\\n                \\\"is_list\\\": True,\\n            },\\n            \\\"chunk_size\\\": {\\n                \\\"display_name\\\": \\\"Chunk Size\\\",\\n                \\\"info\\\": \\\"The maximum length of each chunk.\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"value\\\": 1000,\\n            },\\n            \\\"chunk_overlap\\\": {\\n                \\\"display_name\\\": \\\"Chunk Overlap\\\",\\n                \\\"info\\\": \\\"The amount of overlap between chunks.\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"value\\\": 200,\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        documents: list[Document],\\n        separators: Optional[list[str]] = None,\\n        chunk_size: Optional[int] = 1000,\\n        chunk_overlap: Optional[int] = 200,\\n    ) -> list[Document]:\\n        \\\"\\\"\\\"\\n        Split text into chunks of a specified length.\\n\\n        Args:\\n            separators (list[str]): The characters to split on.\\n            chunk_size (int): The maximum length of each chunk.\\n            chunk_overlap (int): The amount of overlap between chunks.\\n            length_function (function): The function to use to calculate the length of the text.\\n\\n        Returns:\\n            list[str]: The chunks of text.\\n        \\\"\\\"\\\"\\n\\n        if separators == \\\"\\\":\\n            separators = None\\n        elif separators:\\n            # check if the separators list has escaped characters\\n            # if there are escaped characters, unescape them\\n            separators = [x.encode().decode(\\\"unicode-escape\\\") for x in separators]\\n\\n        # Make sure chunk_size and chunk_overlap are ints\\n        if isinstance(chunk_size, str):\\n            chunk_size = int(chunk_size)\\n        if isinstance(chunk_overlap, str):\\n            chunk_overlap = int(chunk_overlap)\\n        splitter = RecursiveCharacterTextSplitter(\\n            separators=separators,\\n            chunk_size=chunk_size,\\n            chunk_overlap=chunk_overlap,\\n        )\\n\\n        docs = splitter.split_documents(documents)\\n        self.repr_value = build_loader_repr_from_documents(docs)\\n        return docs\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"separators\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"separators\",\"display_name\":\"Separators\",\"advanced\":false,\"dynamic\":false,\"info\":\"The characters to split on.\\nIf left empty defaults to [\\\"\\\\n\\\\n\\\", \\\"\\\\n\\\", \\\" \\\", \\\"\\\"].\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Split text into chunks of a specified length.\",\"base_classes\":[\"Serializable\",\"Document\"],\"display_name\":\"Recursive Character Text Splitter\",\"documentation\":\"https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter\",\"custom_fields\":{\"documents\":null,\"separators\":null,\"chunk_size\":null,\"chunk_overlap\":null},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"LanguageRecursiveTextSplitter\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"The documents to split.\",\"title_case\":false},\"chunk_overlap\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":200,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chunk_overlap\",\"display_name\":\"Chunk Overlap\",\"advanced\":false,\"dynamic\":false,\"info\":\"The amount of overlap between chunks.\",\"title_case\":false},\"chunk_size\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1000,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chunk_size\",\"display_name\":\"Chunk Size\",\"advanced\":false,\"dynamic\":false,\"info\":\"The maximum length of each chunk.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.text_splitter import Language\\nfrom langchain_core.documents import Document\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass LanguageRecursiveTextSplitterComponent(CustomComponent):\\n    display_name: str = \\\"Language Recursive Text Splitter\\\"\\n    description: str = \\\"Split text into chunks of a specified length based on language.\\\"\\n    documentation: str = \\\"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter\\\"\\n\\n    def build_config(self):\\n        options = [x.value for x in Language]\\n        return {\\n            \\\"documents\\\": {\\n                \\\"display_name\\\": \\\"Documents\\\",\\n                \\\"info\\\": \\\"The documents to split.\\\",\\n            },\\n            \\\"separator_type\\\": {\\n                \\\"display_name\\\": \\\"Separator Type\\\",\\n                \\\"info\\\": \\\"The type of separator to use.\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"options\\\": options,\\n                \\\"value\\\": \\\"Python\\\",\\n            },\\n            \\\"separators\\\": {\\n                \\\"display_name\\\": \\\"Separators\\\",\\n                \\\"info\\\": \\\"The characters to split on.\\\",\\n                \\\"is_list\\\": True,\\n            },\\n            \\\"chunk_size\\\": {\\n                \\\"display_name\\\": \\\"Chunk Size\\\",\\n                \\\"info\\\": \\\"The maximum length of each chunk.\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"value\\\": 1000,\\n            },\\n            \\\"chunk_overlap\\\": {\\n                \\\"display_name\\\": \\\"Chunk Overlap\\\",\\n                \\\"info\\\": \\\"The amount of overlap between chunks.\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"value\\\": 200,\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        documents: list[Document],\\n        chunk_size: Optional[int] = 1000,\\n        chunk_overlap: Optional[int] = 200,\\n        separator_type: str = \\\"Python\\\",\\n    ) -> list[Document]:\\n        \\\"\\\"\\\"\\n        Split text into chunks of a specified length.\\n\\n        Args:\\n            separators (list[str]): The characters to split on.\\n            chunk_size (int): The maximum length of each chunk.\\n            chunk_overlap (int): The amount of overlap between chunks.\\n            length_function (function): The function to use to calculate the length of the text.\\n\\n        Returns:\\n            list[str]: The chunks of text.\\n        \\\"\\\"\\\"\\n        from langchain.text_splitter import RecursiveCharacterTextSplitter\\n\\n        # Make sure chunk_size and chunk_overlap are ints\\n        if isinstance(chunk_size, str):\\n            chunk_size = int(chunk_size)\\n        if isinstance(chunk_overlap, str):\\n            chunk_overlap = int(chunk_overlap)\\n\\n        splitter = RecursiveCharacterTextSplitter.from_language(\\n            language=Language(separator_type),\\n            chunk_size=chunk_size,\\n            chunk_overlap=chunk_overlap,\\n        )\\n\\n        docs = splitter.split_documents(documents)\\n        return docs\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"separator_type\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"Python\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"cpp\",\"go\",\"java\",\"kotlin\",\"js\",\"ts\",\"php\",\"proto\",\"python\",\"rst\",\"ruby\",\"rust\",\"scala\",\"swift\",\"markdown\",\"latex\",\"html\",\"sol\",\"csharp\",\"cobol\",\"c\",\"lua\",\"perl\"],\"name\":\"separator_type\",\"display_name\":\"Separator Type\",\"advanced\":false,\"dynamic\":false,\"info\":\"The type of separator to use.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Split text into chunks of a specified length based on language.\",\"base_classes\":[\"Serializable\",\"Document\"],\"display_name\":\"Language Recursive Text Splitter\",\"documentation\":\"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter\",\"custom_fields\":{\"documents\":null,\"chunk_size\":null,\"chunk_overlap\":null,\"separator_type\":null},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"utilities\":{\"BingSearchAPIWrapper\":{\"template\":{\"bing_search_url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"bing_search_url\",\"display_name\":\"Bing Search URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"bing_subscription_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"bing_subscription_key\",\"display_name\":\"Bing Subscription Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\n\\n# Assuming `BingSearchAPIWrapper` is a class that exists in the context\\n# and has the appropriate methods and attributes.\\n# We need to make sure this class is importable from the context where this code will be running.\\nfrom langchain_community.utilities.bing_search import BingSearchAPIWrapper\\n\\n\\nclass BingSearchAPIWrapperComponent(CustomComponent):\\n    display_name = \\\"BingSearchAPIWrapper\\\"\\n    description = \\\"Wrapper for Bing Search API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"bing_search_url\\\": {\\\"display_name\\\": \\\"Bing Search URL\\\"},\\n            \\\"bing_subscription_key\\\": {\\n                \\\"display_name\\\": \\\"Bing Subscription Key\\\",\\n                \\\"password\\\": True,\\n            },\\n            \\\"k\\\": {\\\"display_name\\\": \\\"Number of results\\\", \\\"advanced\\\": True},\\n            # 'k' is not included as it is not shown (show=False)\\n        }\\n\\n    def build(\\n        self,\\n        bing_search_url: str,\\n        bing_subscription_key: str,\\n        k: int = 10,\\n    ) -> BingSearchAPIWrapper:\\n        # 'k' has a default value and is not shown (show=False), so it is hardcoded here\\n        return BingSearchAPIWrapper(bing_search_url=bing_search_url, bing_subscription_key=bing_subscription_key, k=k)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"k\",\"display_name\":\"Number of results\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Wrapper for Bing Search API.\",\"base_classes\":[\"BingSearchAPIWrapper\"],\"display_name\":\"BingSearchAPIWrapper\",\"documentation\":\"\",\"custom_fields\":{\"bing_search_url\":null,\"bing_subscription_key\":null,\"k\":null},\"output_types\":[\"BingSearchAPIWrapper\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"GoogleSearchAPIWrapper\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Union\\n\\nfrom langchain_community.utilities.google_search import GoogleSearchAPIWrapper\\nfrom langflow import CustomComponent\\n\\n\\nclass GoogleSearchAPIWrapperComponent(CustomComponent):\\n    display_name = \\\"GoogleSearchAPIWrapper\\\"\\n    description = \\\"Wrapper for Google Search API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"google_api_key\\\": {\\\"display_name\\\": \\\"Google API Key\\\", \\\"password\\\": True},\\n            \\\"google_cse_id\\\": {\\\"display_name\\\": \\\"Google CSE ID\\\", \\\"password\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        google_api_key: str,\\n        google_cse_id: str,\\n    ) -> Union[GoogleSearchAPIWrapper, Callable]:\\n        return GoogleSearchAPIWrapper(google_api_key=google_api_key, google_cse_id=google_cse_id)  # type: ignore\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"google_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"google_api_key\",\"display_name\":\"Google API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"google_cse_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"google_cse_id\",\"display_name\":\"Google CSE ID\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Wrapper for Google Search API.\",\"base_classes\":[\"GoogleSearchAPIWrapper\",\"Callable\"],\"display_name\":\"GoogleSearchAPIWrapper\",\"documentation\":\"\",\"custom_fields\":{\"google_api_key\":null,\"google_cse_id\":null},\"output_types\":[\"GoogleSearchAPIWrapper\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"GoogleSerperAPIWrapper\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Dict\\n\\n# Assuming the existence of GoogleSerperAPIWrapper class in the serper module\\n# If this class does not exist, you would need to create it or import the appropriate class from another module\\nfrom langchain_community.utilities.google_serper import GoogleSerperAPIWrapper\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass GoogleSerperAPIWrapperComponent(CustomComponent):\\n    display_name = \\\"GoogleSerperAPIWrapper\\\"\\n    description = \\\"Wrapper around the Serper.dev Google Search API.\\\"\\n\\n    def build_config(self) -> Dict[str, Dict]:\\n        return {\\n            \\\"result_key_for_type\\\": {\\n                \\\"display_name\\\": \\\"Result Key for Type\\\",\\n                \\\"show\\\": True,\\n                \\\"multiline\\\": False,\\n                \\\"password\\\": False,\\n                \\\"advanced\\\": False,\\n                \\\"dynamic\\\": False,\\n                \\\"info\\\": \\\"\\\",\\n                \\\"field_type\\\": \\\"dict\\\",\\n                \\\"list\\\": False,\\n                \\\"value\\\": {\\n                    \\\"news\\\": \\\"news\\\",\\n                    \\\"places\\\": \\\"places\\\",\\n                    \\\"images\\\": \\\"images\\\",\\n                    \\\"search\\\": \\\"organic\\\",\\n                },\\n            },\\n            \\\"serper_api_key\\\": {\\n                \\\"display_name\\\": \\\"Serper API Key\\\",\\n                \\\"show\\\": True,\\n                \\\"multiline\\\": False,\\n                \\\"password\\\": True,\\n                \\\"advanced\\\": False,\\n                \\\"dynamic\\\": False,\\n                \\\"info\\\": \\\"\\\",\\n                \\\"type\\\": \\\"str\\\",\\n                \\\"list\\\": False,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        serper_api_key: str,\\n    ) -> GoogleSerperAPIWrapper:\\n        return GoogleSerperAPIWrapper(serper_api_key=serper_api_key)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"serper_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"serper_api_key\",\"display_name\":\"Serper API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Wrapper around the Serper.dev Google Search API.\",\"base_classes\":[\"GoogleSerperAPIWrapper\"],\"display_name\":\"GoogleSerperAPIWrapper\",\"documentation\":\"\",\"custom_fields\":{\"serper_api_key\":null},\"output_types\":[\"GoogleSerperAPIWrapper\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"SearxSearchWrapper\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom typing import Optional, Dict\\nfrom langchain_community.utilities.searx_search import SearxSearchWrapper\\n\\n\\nclass SearxSearchWrapperComponent(CustomComponent):\\n    display_name = \\\"SearxSearchWrapper\\\"\\n    description = \\\"Wrapper for Searx API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"headers\\\": {\\n                \\\"field_type\\\": \\\"dict\\\",\\n                \\\"display_name\\\": \\\"Headers\\\",\\n                \\\"multiline\\\": True,\\n                \\\"value\\\": '{\\\"Authorization\\\": \\\"Bearer <token>\\\"}',\\n            },\\n            \\\"k\\\": {\\\"display_name\\\": \\\"k\\\", \\\"advanced\\\": True, \\\"field_type\\\": \\\"int\\\", \\\"value\\\": 10},\\n            \\\"searx_host\\\": {\\n                \\\"display_name\\\": \\\"Searx Host\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"value\\\": \\\"https://searx.example.com\\\",\\n                \\\"advanced\\\": True,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        k: int = 10,\\n        headers: Optional[Dict[str, str]] = None,\\n        searx_host: str = \\\"https://searx.example.com\\\",\\n    ) -> SearxSearchWrapper:\\n        return SearxSearchWrapper(headers=headers, k=k, searx_host=searx_host)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"headers\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"{\\\"Authorization\\\": \\\"Bearer <token>\\\"}\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"headers\",\"display_name\":\"Headers\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"k\",\"display_name\":\"k\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"searx_host\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"https://searx.example.com\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"searx_host\",\"display_name\":\"Searx Host\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Wrapper for Searx API.\",\"base_classes\":[\"SearxSearchWrapper\"],\"display_name\":\"SearxSearchWrapper\",\"documentation\":\"\",\"custom_fields\":{\"k\":null,\"headers\":null,\"searx_host\":null},\"output_types\":[\"SearxSearchWrapper\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"SerpAPIWrapper\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Union\\n\\nfrom langchain_community.utilities.serpapi import SerpAPIWrapper\\nfrom langflow import CustomComponent\\n\\n\\nclass SerpAPIWrapperComponent(CustomComponent):\\n    display_name = \\\"SerpAPIWrapper\\\"\\n    description = \\\"Wrapper around SerpAPI\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"serpapi_api_key\\\": {\\\"display_name\\\": \\\"SerpAPI API Key\\\", \\\"type\\\": \\\"str\\\", \\\"password\\\": True},\\n            \\\"params\\\": {\\n                \\\"display_name\\\": \\\"Parameters\\\",\\n                \\\"type\\\": \\\"dict\\\",\\n                \\\"advanced\\\": True,\\n                \\\"multiline\\\": True,\\n                \\\"value\\\": '{\\\"engine\\\": \\\"google\\\",\\\"google_domain\\\": \\\"google.com\\\",\\\"gl\\\": \\\"us\\\",\\\"hl\\\": \\\"en\\\"}',\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        serpapi_api_key: str,\\n        params: dict,\\n    ) -> Union[SerpAPIWrapper, Callable]:  # Removed quotes around SerpAPIWrapper\\n        return SerpAPIWrapper(  # type: ignore\\n            serpapi_api_key=serpapi_api_key,\\n            params=params,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"params\":{\"type\":\"dict\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"{\\\"engine\\\": \\\"google\\\",\\\"google_domain\\\": \\\"google.com\\\",\\\"gl\\\": \\\"us\\\",\\\"hl\\\": \\\"en\\\"}\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"params\",\"display_name\":\"Parameters\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"serpapi_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"serpapi_api_key\",\"display_name\":\"SerpAPI API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Wrapper around SerpAPI\",\"base_classes\":[\"Callable\",\"SerpAPIWrapper\"],\"display_name\":\"SerpAPIWrapper\",\"documentation\":\"\",\"custom_fields\":{\"serpapi_api_key\":null,\"params\":null},\"output_types\":[\"SerpAPIWrapper\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"WikipediaAPIWrapper\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Union\\n\\nfrom langchain_community.utilities.wikipedia import WikipediaAPIWrapper\\nfrom langflow import CustomComponent\\n\\n# Assuming WikipediaAPIWrapper is a class that needs to be imported.\\n# The import statement is not included as it is not provided in the JSON\\n# and the actual implementation details are unknown.\\n\\n\\nclass WikipediaAPIWrapperComponent(CustomComponent):\\n    display_name = \\\"WikipediaAPIWrapper\\\"\\n    description = \\\"Wrapper around WikipediaAPI.\\\"\\n\\n    def build_config(self):\\n        return {}\\n\\n    def build(\\n        self,\\n        top_k_results: int = 3,\\n        lang: str = \\\"en\\\",\\n        load_all_available_meta: bool = False,\\n        doc_content_chars_max: int = 4000,\\n    ) -> Union[WikipediaAPIWrapper, Callable]:\\n        return WikipediaAPIWrapper(  # type: ignore\\n            top_k_results=top_k_results,\\n            lang=lang,\\n            load_all_available_meta=load_all_available_meta,\\n            doc_content_chars_max=doc_content_chars_max,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"doc_content_chars_max\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":4000,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"doc_content_chars_max\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"lang\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"en\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"lang\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"load_all_available_meta\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"load_all_available_meta\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"top_k_results\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":3,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k_results\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Wrapper around WikipediaAPI.\",\"base_classes\":[\"WikipediaAPIWrapper\",\"Callable\"],\"display_name\":\"WikipediaAPIWrapper\",\"documentation\":\"\",\"custom_fields\":{\"top_k_results\":null,\"lang\":null,\"load_all_available_meta\":null,\"doc_content_chars_max\":null},\"output_types\":[\"WikipediaAPIWrapper\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"WolframAlphaAPIWrapper\":{\"template\":{\"appid\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"appid\",\"display_name\":\"App ID\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Union\\n\\nfrom langchain_community.utilities.wolfram_alpha import WolframAlphaAPIWrapper\\nfrom langflow import CustomComponent\\n\\n# Since all the fields in the JSON have show=False, we will only create a basic component\\n# without any configurable fields.\\n\\n\\nclass WolframAlphaAPIWrapperComponent(CustomComponent):\\n    display_name = \\\"WolframAlphaAPIWrapper\\\"\\n    description = \\\"Wrapper for Wolfram Alpha.\\\"\\n\\n    def build_config(self):\\n        return {\\\"appid\\\": {\\\"display_name\\\": \\\"App ID\\\", \\\"type\\\": \\\"str\\\", \\\"password\\\": True}}\\n\\n    def build(self, appid: str) -> Union[Callable, WolframAlphaAPIWrapper]:\\n        return WolframAlphaAPIWrapper(wolfram_alpha_appid=appid)  # type: ignore\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Wrapper for Wolfram Alpha.\",\"base_classes\":[\"WolframAlphaAPIWrapper\",\"Callable\"],\"display_name\":\"WolframAlphaAPIWrapper\",\"documentation\":\"\",\"custom_fields\":{\"appid\":null},\"output_types\":[\"Callable\",\"WolframAlphaAPIWrapper\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"RunnableExecutor\":{\"template\":{\"runnable\":{\"type\":\"Runnable\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"runnable\",\"display_name\":\"Runnable\",\"advanced\":false,\"dynamic\":false,\"info\":\"The runnable to execute.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langchain_core.runnables import Runnable\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass RunnableExecComponent(CustomComponent):\\n    documentation: str = \\\"http://docs.langflow.org/components/custom\\\"\\n    display_name = \\\"Runnable Executor\\\"\\n    beta = True\\n\\n    def build_config(self):\\n        return {\\n            \\\"input_key\\\": {\\n                \\\"display_name\\\": \\\"Input Key\\\",\\n                \\\"info\\\": \\\"The key to use for the input.\\\",\\n            },\\n            \\\"inputs\\\": {\\n                \\\"display_name\\\": \\\"Inputs\\\",\\n                \\\"info\\\": \\\"The inputs to pass to the runnable.\\\",\\n            },\\n            \\\"runnable\\\": {\\n                \\\"display_name\\\": \\\"Runnable\\\",\\n                \\\"info\\\": \\\"The runnable to execute.\\\",\\n            },\\n            \\\"output_key\\\": {\\n                \\\"display_name\\\": \\\"Output Key\\\",\\n                \\\"info\\\": \\\"The key to use for the output.\\\",\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        input_key: str,\\n        inputs: str,\\n        runnable: Runnable,\\n        output_key: str = \\\"output\\\",\\n    ) -> Text:\\n        result = runnable.invoke({input_key: inputs})\\n        result = result.get(output_key)\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"input_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"input_key\",\"display_name\":\"Input Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The key to use for the input.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Inputs\",\"advanced\":false,\"dynamic\":false,\"info\":\"The inputs to pass to the runnable.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"output_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"output\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"output_key\",\"display_name\":\"Output Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The key to use for the output.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"Runnable Executor\",\"documentation\":\"http://docs.langflow.org/components/custom\",\"custom_fields\":{\"input_key\":null,\"inputs\":null,\"runnable\":null,\"output_key\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"DocumentToRecord\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List\\n\\nfrom langchain_core.documents import Document\\n\\nfrom langflow import CustomComponent\\nfrom langflow.schema import Record\\n\\n\\nclass DocumentToRecordComponent(CustomComponent):\\n    display_name = \\\"Documents to Records\\\"\\n    description = \\\"Convert documents to records.\\\"\\n\\n    field_config = {\\n        \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\"},\\n    }\\n\\n    def build(self, documents: List[Document]) -> List[Record]:\\n        if isinstance(documents, Document):\\n            documents = [documents]\\n        records = [Record.from_document(document) for document in documents]\\n        self.status = records\\n        return records\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Convert documents to records.\",\"base_classes\":[\"Record\"],\"display_name\":\"Documents to Records\",\"documentation\":\"\",\"custom_fields\":{\"documents\":null},\"output_types\":[\"Record\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"GetRequest\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nimport requests\\nfrom langchain_core.documents import Document\\nfrom langflow import CustomComponent\\nfrom langflow.services.database.models.base import orjson_dumps\\n\\n\\nclass GetRequest(CustomComponent):\\n    display_name: str = \\\"GET Request\\\"\\n    description: str = \\\"Make a GET request to the given URL.\\\"\\n    output_types: list[str] = [\\\"Document\\\"]\\n    documentation: str = \\\"https://docs.langflow.org/components/utilities#get-request\\\"\\n    beta: bool = True\\n    field_config = {\\n        \\\"url\\\": {\\n            \\\"display_name\\\": \\\"URL\\\",\\n            \\\"info\\\": \\\"The URL to make the request to\\\",\\n            \\\"is_list\\\": True,\\n        },\\n        \\\"headers\\\": {\\n            \\\"display_name\\\": \\\"Headers\\\",\\n            \\\"info\\\": \\\"The headers to send with the request.\\\",\\n        },\\n        \\\"code\\\": {\\\"show\\\": False},\\n        \\\"timeout\\\": {\\n            \\\"display_name\\\": \\\"Timeout\\\",\\n            \\\"field_type\\\": \\\"int\\\",\\n            \\\"info\\\": \\\"The timeout to use for the request.\\\",\\n            \\\"value\\\": 5,\\n        },\\n    }\\n\\n    def get_document(self, session: requests.Session, url: str, headers: Optional[dict], timeout: int) -> Document:\\n        try:\\n            response = session.get(url, headers=headers, timeout=int(timeout))\\n            try:\\n                response_json = response.json()\\n                result = orjson_dumps(response_json, indent_2=False)\\n            except Exception:\\n                result = response.text\\n            self.repr_value = result\\n            return Document(\\n                page_content=result,\\n                metadata={\\n                    \\\"source\\\": url,\\n                    \\\"headers\\\": headers,\\n                    \\\"status_code\\\": response.status_code,\\n                },\\n            )\\n        except requests.Timeout:\\n            return Document(\\n                page_content=\\\"Request Timed Out\\\",\\n                metadata={\\\"source\\\": url, \\\"headers\\\": headers, \\\"status_code\\\": 408},\\n            )\\n        except Exception as exc:\\n            return Document(\\n                page_content=str(exc),\\n                metadata={\\\"source\\\": url, \\\"headers\\\": headers, \\\"status_code\\\": 500},\\n            )\\n\\n    def build(\\n        self,\\n        url: str,\\n        headers: Optional[dict] = None,\\n        timeout: int = 5,\\n    ) -> list[Document]:\\n        if headers is None:\\n            headers = {}\\n        urls = url if isinstance(url, list) else [url]\\n        with requests.Session() as session:\\n            documents = [self.get_document(session, u, headers, timeout) for u in urls]\\n            self.repr_value = documents\\n        return documents\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"headers\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"headers\",\"display_name\":\"Headers\",\"advanced\":false,\"dynamic\":false,\"info\":\"The headers to send with the request.\",\"title_case\":false},\"timeout\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":5,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"timeout\",\"display_name\":\"Timeout\",\"advanced\":false,\"dynamic\":false,\"info\":\"The timeout to use for the request.\",\"title_case\":false},\"url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"url\",\"display_name\":\"URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"The URL to make the request to\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Make a GET request to the given URL.\",\"base_classes\":[\"Serializable\",\"Document\"],\"display_name\":\"GET Request\",\"documentation\":\"https://docs.langflow.org/components/utilities#get-request\",\"custom_fields\":{\"url\":null,\"headers\":null,\"timeout\":null},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"SQLExecutor\":{\"template\":{\"database\":{\"type\":\"SQLDatabase\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"database\",\"display_name\":\"Database\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"add_error\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"add_error\",\"display_name\":\"Add Error\",\"advanced\":false,\"dynamic\":false,\"info\":\"Add the error to the result.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\\nfrom langchain_experimental.sql.base import SQLDatabase\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass SQLExecutorComponent(CustomComponent):\\n    display_name = \\\"SQL Executor\\\"\\n    description = \\\"Execute SQL query.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"database\\\": {\\\"display_name\\\": \\\"Database\\\"},\\n            \\\"include_columns\\\": {\\n                \\\"display_name\\\": \\\"Include Columns\\\",\\n                \\\"info\\\": \\\"Include columns in the result.\\\",\\n            },\\n            \\\"passthrough\\\": {\\n                \\\"display_name\\\": \\\"Passthrough\\\",\\n                \\\"info\\\": \\\"If an error occurs, return the query instead of raising an exception.\\\",\\n            },\\n            \\\"add_error\\\": {\\n                \\\"display_name\\\": \\\"Add Error\\\",\\n                \\\"info\\\": \\\"Add the error to the result.\\\",\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        query: str,\\n        database: SQLDatabase,\\n        include_columns: bool = False,\\n        passthrough: bool = False,\\n        add_error: bool = False,\\n    ) -> Text:\\n        error = None\\n        try:\\n            tool = QuerySQLDataBaseTool(db=database)\\n            result = tool.run(query, include_columns=include_columns)\\n            self.status = result\\n        except Exception as e:\\n            result = str(e)\\n            self.status = result\\n            if not passthrough:\\n                raise e\\n            error = repr(e)\\n\\n        if add_error and error is not None:\\n            result = f\\\"{result}\\\\n\\\\nError: {error}\\\\n\\\\nQuery: {query}\\\"\\n        elif error is not None:\\n            # Then we won't add the error to the result\\n            # but since we are in passthrough mode, we will return the query\\n            result = query\\n\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"include_columns\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"include_columns\",\"display_name\":\"Include Columns\",\"advanced\":false,\"dynamic\":false,\"info\":\"Include columns in the result.\",\"title_case\":false},\"passthrough\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"passthrough\",\"display_name\":\"Passthrough\",\"advanced\":false,\"dynamic\":false,\"info\":\"If an error occurs, return the query instead of raising an exception.\",\"title_case\":false},\"query\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"query\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Execute SQL query.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"SQL Executor\",\"documentation\":\"\",\"custom_fields\":{\"query\":null,\"database\":null,\"include_columns\":null,\"passthrough\":null,\"add_error\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"ShouldRunNext\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"The language model to use for the decision.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"# Implement ShouldRunNext component\\nfrom langchain_core.prompts import PromptTemplate\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, Prompt\\n\\n\\nclass ShouldRunNext(CustomComponent):\\n    display_name = \\\"Should Run Next\\\"\\n    description = \\\"Decides whether to run the next component.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"prompt\\\": {\\n                \\\"display_name\\\": \\\"Prompt\\\",\\n                \\\"info\\\": \\\"The prompt to use for the decision. It should generate a boolean response (True or False).\\\",\\n            },\\n            \\\"llm\\\": {\\n                \\\"display_name\\\": \\\"LLM\\\",\\n                \\\"info\\\": \\\"The language model to use for the decision.\\\",\\n            },\\n        }\\n\\n    def build(self, template: Prompt, llm: BaseLanguageModel, **kwargs) -> dict:\\n        # This is a simple component that always returns True\\n        prompt_template = PromptTemplate.from_template(template)\\n\\n        attributes_to_check = [\\\"text\\\", \\\"page_content\\\"]\\n        for key, value in kwargs.items():\\n            for attribute in attributes_to_check:\\n                if hasattr(value, attribute):\\n                    kwargs[key] = getattr(value, attribute)\\n\\n        chain = prompt_template | llm\\n        result = chain.invoke(kwargs)\\n        if hasattr(result, \\\"content\\\") and isinstance(result.content, str):\\n            result = result.content\\n        elif isinstance(result, str):\\n            result = result\\n        else:\\n            result = result.get(\\\"response\\\")\\n\\n        if result.lower() not in [\\\"true\\\", \\\"false\\\"]:\\n            raise ValueError(\\\"The prompt should generate a boolean response (True or False).\\\")\\n        # The string should be the words true or false\\n        # if not raise an error\\n        bool_result = result.lower() == \\\"true\\\"\\n        return {\\\"condition\\\": bool_result, \\\"result\\\": kwargs}\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"template\":{\"type\":\"prompt\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"template\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Decides whether to run the next component.\",\"base_classes\":[\"object\",\"dict\"],\"display_name\":\"Should Run Next\",\"documentation\":\"\",\"custom_fields\":{\"template\":null,\"llm\":null},\"output_types\":[\"dict\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"PythonFunction\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Code\\nfrom langflow.interface.custom.utils import get_function\\n\\n\\nclass PythonFunctionComponent(CustomComponent):\\n    display_name = \\\"Python Function\\\"\\n    description = \\\"Define a Python function.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"function_code\\\": {\\n                \\\"display_name\\\": \\\"Code\\\",\\n                \\\"info\\\": \\\"The code for the function.\\\",\\n                \\\"show\\\": True,\\n            },\\n        }\\n\\n    def build(self, function_code: Code) -> Callable:\\n        self.status = function_code\\n        func = get_function(function_code)\\n        return func\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"function_code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"function_code\",\"display_name\":\"Code\",\"advanced\":false,\"dynamic\":false,\"info\":\"The code for the function.\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Define a Python function.\",\"base_classes\":[\"Callable\"],\"display_name\":\"Python Function\",\"documentation\":\"\",\"custom_fields\":{\"function_code\":null},\"output_types\":[\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"PostRequest\":{\"template\":{\"document\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"document\",\"display_name\":\"Document\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nimport requests\\nfrom langchain_core.documents import Document\\nfrom langflow import CustomComponent\\nfrom langflow.services.database.models.base import orjson_dumps\\n\\n\\nclass PostRequest(CustomComponent):\\n    display_name: str = \\\"POST Request\\\"\\n    description: str = \\\"Make a POST request to the given URL.\\\"\\n    output_types: list[str] = [\\\"Document\\\"]\\n    documentation: str = \\\"https://docs.langflow.org/components/utilities#post-request\\\"\\n    beta: bool = True\\n    field_config = {\\n        \\\"url\\\": {\\\"display_name\\\": \\\"URL\\\", \\\"info\\\": \\\"The URL to make the request to.\\\"},\\n        \\\"headers\\\": {\\n            \\\"display_name\\\": \\\"Headers\\\",\\n            \\\"info\\\": \\\"The headers to send with the request.\\\",\\n        },\\n        \\\"code\\\": {\\\"show\\\": False},\\n        \\\"document\\\": {\\\"display_name\\\": \\\"Document\\\"},\\n    }\\n\\n    def post_document(\\n        self,\\n        session: requests.Session,\\n        document: Document,\\n        url: str,\\n        headers: Optional[dict] = None,\\n    ) -> Document:\\n        try:\\n            response = session.post(url, headers=headers, data=document.page_content)\\n            try:\\n                response_json = response.json()\\n                result = orjson_dumps(response_json, indent_2=False)\\n            except Exception:\\n                result = response.text\\n            self.repr_value = result\\n            return Document(\\n                page_content=result,\\n                metadata={\\n                    \\\"source\\\": url,\\n                    \\\"headers\\\": headers,\\n                    \\\"status_code\\\": response,\\n                },\\n            )\\n        except Exception as exc:\\n            return Document(\\n                page_content=str(exc),\\n                metadata={\\n                    \\\"source\\\": url,\\n                    \\\"headers\\\": headers,\\n                    \\\"status_code\\\": 500,\\n                },\\n            )\\n\\n    def build(\\n        self,\\n        document: Document,\\n        url: str,\\n        headers: Optional[dict] = None,\\n    ) -> list[Document]:\\n        if headers is None:\\n            headers = {}\\n\\n        if not isinstance(document, list) and isinstance(document, Document):\\n            documents: list[Document] = [document]\\n        elif isinstance(document, list) and all(isinstance(doc, Document) for doc in document):\\n            documents = document\\n        else:\\n            raise ValueError(\\\"document must be a Document or a list of Documents\\\")\\n\\n        with requests.Session() as session:\\n            documents = [self.post_document(session, doc, url, headers) for doc in documents]\\n            self.repr_value = documents\\n        return documents\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"headers\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"headers\",\"display_name\":\"Headers\",\"advanced\":false,\"dynamic\":false,\"info\":\"The headers to send with the request.\",\"title_case\":false},\"url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"url\",\"display_name\":\"URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"The URL to make the request to.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Make a POST request to the given URL.\",\"base_classes\":[\"Serializable\",\"Document\"],\"display_name\":\"POST Request\",\"documentation\":\"https://docs.langflow.org/components/utilities#post-request\",\"custom_fields\":{\"document\":null,\"url\":null,\"headers\":null},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"IDGenerator\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"import uuid\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass UUIDGeneratorComponent(CustomComponent):\\n    documentation: str = \\\"http://docs.langflow.org/components/custom\\\"\\n    display_name = \\\"Unique ID Generator\\\"\\n    description = \\\"Generates a unique ID.\\\"\\n\\n    def generate(self, *args, **kwargs):\\n        return str(uuid.uuid4().hex)\\n\\n    def build_config(self):\\n        return {\\\"unique_id\\\": {\\\"display_name\\\": \\\"Value\\\", \\\"value\\\": self.generate}}\\n\\n    def build(self, unique_id: str) -> str:\\n        return unique_id\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"unique_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"a62d43140aba4c799af4ddc400295790\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"unique_id\",\"display_name\":\"Value\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"refresh\":true,\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Generates a unique ID.\",\"base_classes\":[\"object\",\"str\"],\"display_name\":\"Unique ID Generator\",\"documentation\":\"http://docs.langflow.org/components/custom\",\"custom_fields\":{\"unique_id\":null},\"output_types\":[\"str\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"SQLDatabase\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langchain_experimental.sql.base import SQLDatabase\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass SQLDatabaseComponent(CustomComponent):\\n    display_name = \\\"SQLDatabase\\\"\\n    description = \\\"SQL Database\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"uri\\\": {\\\"display_name\\\": \\\"URI\\\", \\\"info\\\": \\\"URI to the database.\\\"},\\n        }\\n\\n    def clean_up_uri(self, uri: str) -> str:\\n        if uri.startswith(\\\"postgresql://\\\"):\\n            uri = uri.replace(\\\"postgresql://\\\", \\\"postgres://\\\")\\n        return uri.strip()\\n\\n    def build(self, uri: str) -> SQLDatabase:\\n        uri = self.clean_up_uri(uri)\\n        return SQLDatabase.from_uri(uri)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"uri\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"uri\",\"display_name\":\"URI\",\"advanced\":false,\"dynamic\":false,\"info\":\"URI to the database.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"SQL Database\",\"base_classes\":[\"object\",\"SQLDatabase\"],\"display_name\":\"SQLDatabase\",\"documentation\":\"\",\"custom_fields\":{\"uri\":null},\"output_types\":[\"SQLDatabase\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"RecordsAsText\":{\"template\":{\"records\":{\"type\":\"Record\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"records\",\"display_name\":\"Records\",\"advanced\":false,\"dynamic\":false,\"info\":\"The records to convert to text.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langflow.field_typing import Text\\nfrom langflow.schema import Record\\n\\n\\nclass RecordsAsTextComponent(CustomComponent):\\n    display_name = \\\"Records to Text\\\"\\n    description = \\\"Converts Records a list of Records to text using a template.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"records\\\": {\\n                \\\"display_name\\\": \\\"Records\\\",\\n                \\\"info\\\": \\\"The records to convert to text.\\\",\\n            },\\n            \\\"template\\\": {\\n                \\\"display_name\\\": \\\"Template\\\",\\n                \\\"info\\\": \\\"The template to use for formatting the records. It must contain the keys {text} and {data}.\\\",\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        records: list[Record],\\n        template: str = \\\"Text: {text}\\\\nData: {data}\\\",\\n    ) -> Text:\\n        if isinstance(records, Record):\\n            records = [records]\\n\\n        formated_records = [\\n            template.format(text=record.text, data=record.data, **record.data)\\n            for record in records\\n        ]\\n        result_string = \\\"\\\\n\\\".join(formated_records)\\n        self.status = result_string\\n        return result_string\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"template\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"Text: {text}\\\\nData: {data}\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"template\",\"display_name\":\"Template\",\"advanced\":false,\"dynamic\":false,\"info\":\"The template to use for formatting the records. It must contain the keys {text} and {data}.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Converts Records a list of Records to text using a template.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"Records to Text\",\"documentation\":\"\",\"custom_fields\":{\"records\":null,\"template\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"UpdateRequest\":{\"template\":{\"document\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"document\",\"display_name\":\"Document\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional\\n\\nimport requests\\nfrom langchain_core.documents import Document\\nfrom langflow import CustomComponent\\nfrom langflow.services.database.models.base import orjson_dumps\\n\\n\\nclass UpdateRequest(CustomComponent):\\n    display_name: str = \\\"Update Request\\\"\\n    description: str = \\\"Make a PATCH request to the given URL.\\\"\\n    output_types: list[str] = [\\\"Document\\\"]\\n    documentation: str = \\\"https://docs.langflow.org/components/utilities#update-request\\\"\\n    beta: bool = True\\n    field_config = {\\n        \\\"url\\\": {\\\"display_name\\\": \\\"URL\\\", \\\"info\\\": \\\"The URL to make the request to.\\\"},\\n        \\\"headers\\\": {\\n            \\\"display_name\\\": \\\"Headers\\\",\\n            \\\"field_type\\\": \\\"NestedDict\\\",\\n            \\\"info\\\": \\\"The headers to send with the request.\\\",\\n        },\\n        \\\"code\\\": {\\\"show\\\": False},\\n        \\\"document\\\": {\\\"display_name\\\": \\\"Document\\\"},\\n        \\\"method\\\": {\\n            \\\"display_name\\\": \\\"Method\\\",\\n            \\\"field_type\\\": \\\"str\\\",\\n            \\\"info\\\": \\\"The HTTP method to use.\\\",\\n            \\\"options\\\": [\\\"PATCH\\\", \\\"PUT\\\"],\\n            \\\"value\\\": \\\"PATCH\\\",\\n        },\\n    }\\n\\n    def update_document(\\n        self,\\n        session: requests.Session,\\n        document: Document,\\n        url: str,\\n        headers: Optional[dict] = None,\\n        method: str = \\\"PATCH\\\",\\n    ) -> Document:\\n        try:\\n            if method == \\\"PATCH\\\":\\n                response = session.patch(url, headers=headers, data=document.page_content)\\n            elif method == \\\"PUT\\\":\\n                response = session.put(url, headers=headers, data=document.page_content)\\n            else:\\n                raise ValueError(f\\\"Unsupported method: {method}\\\")\\n            try:\\n                response_json = response.json()\\n                result = orjson_dumps(response_json, indent_2=False)\\n            except Exception:\\n                result = response.text\\n            self.repr_value = result\\n            return Document(\\n                page_content=result,\\n                metadata={\\n                    \\\"source\\\": url,\\n                    \\\"headers\\\": headers,\\n                    \\\"status_code\\\": response.status_code,\\n                },\\n            )\\n        except Exception as exc:\\n            return Document(\\n                page_content=str(exc),\\n                metadata={\\\"source\\\": url, \\\"headers\\\": headers, \\\"status_code\\\": 500},\\n            )\\n\\n    def build(\\n        self,\\n        method: str,\\n        document: Document,\\n        url: str,\\n        headers: Optional[dict] = None,\\n    ) -> List[Document]:\\n        if headers is None:\\n            headers = {}\\n\\n        if not isinstance(document, list) and isinstance(document, Document):\\n            documents: list[Document] = [document]\\n        elif isinstance(document, list) and all(isinstance(doc, Document) for doc in document):\\n            documents = document\\n        else:\\n            raise ValueError(\\\"document must be a Document or a list of Documents\\\")\\n\\n        with requests.Session() as session:\\n            documents = [self.update_document(session, doc, url, headers, method) for doc in documents]\\n            self.repr_value = documents\\n        return documents\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"headers\":{\"type\":\"NestedDict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"headers\",\"display_name\":\"Headers\",\"advanced\":false,\"dynamic\":false,\"info\":\"The headers to send with the request.\",\"title_case\":false},\"method\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"PATCH\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"PATCH\",\"PUT\"],\"name\":\"method\",\"display_name\":\"Method\",\"advanced\":false,\"dynamic\":false,\"info\":\"The HTTP method to use.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"url\",\"display_name\":\"URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"The URL to make the request to.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Make a PATCH request to the given URL.\",\"base_classes\":[\"Serializable\",\"Document\"],\"display_name\":\"Update Request\",\"documentation\":\"https://docs.langflow.org/components/utilities#update-request\",\"custom_fields\":{\"method\":null,\"document\":null,\"url\":null,\"headers\":null},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"JSONDocumentBuilder\":{\"template\":{\"document\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"document\",\"display_name\":\"Document\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"### JSON Document Builder\\n\\n# Build a Document containing a JSON object using a key and another Document page content.\\n\\n# **Params**\\n\\n# - **Key:** The key to use for the JSON object.\\n# - **Document:** The Document page to use for the JSON object.\\n\\n# **Output**\\n\\n# - **Document:** The Document containing the JSON object.\\n\\nfrom langchain_core.documents import Document\\nfrom langflow import CustomComponent\\nfrom langflow.services.database.models.base import orjson_dumps\\n\\n\\nclass JSONDocumentBuilder(CustomComponent):\\n    display_name: str = \\\"JSON Document Builder\\\"\\n    description: str = \\\"Build a Document containing a JSON object using a key and another Document page content.\\\"\\n    output_types: list[str] = [\\\"Document\\\"]\\n    beta = True\\n    documentation: str = \\\"https://docs.langflow.org/components/utilities#json-document-builder\\\"\\n\\n    field_config = {\\n        \\\"key\\\": {\\\"display_name\\\": \\\"Key\\\"},\\n        \\\"document\\\": {\\\"display_name\\\": \\\"Document\\\"},\\n    }\\n\\n    def build(\\n        self,\\n        key: str,\\n        document: Document,\\n    ) -> Document:\\n        documents = None\\n        if isinstance(document, list):\\n            documents = [\\n                Document(page_content=orjson_dumps({key: doc.page_content}, indent_2=False)) for doc in document\\n            ]\\n        elif isinstance(document, Document):\\n            documents = Document(page_content=orjson_dumps({key: document.page_content}, indent_2=False))\\n        else:\\n            raise TypeError(f\\\"Expected Document or list of Documents, got {type(document)}\\\")\\n        self.repr_value = documents\\n        return documents\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"key\",\"display_name\":\"Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Build a Document containing a JSON object using a key and another Document page content.\",\"base_classes\":[\"Serializable\",\"Document\"],\"display_name\":\"JSON Document Builder\",\"documentation\":\"https://docs.langflow.org/components/utilities#json-document-builder\",\"custom_fields\":{\"key\":null,\"document\":null},\"output_types\":[\"Document\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"output_parsers\":{\"ResponseSchema\":{\"template\":{\"description\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"fileTypes\":[],\"password\":false,\"name\":\"description\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"type\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"string\",\"fileTypes\":[],\"password\":false,\"name\":\"type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"ResponseSchema\"},\"description\":\"A schema for a response from a structured output parser.\",\"base_classes\":[\"ResponseSchema\"],\"display_name\":\"ResponseSchema\",\"documentation\":\"https://python.langchain.com/docs/modules/model_io/output_parsers/structured\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"StructuredOutputParser\":{\"template\":{\"response_schemas\":{\"type\":\"ResponseSchema\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"password\":false,\"name\":\"response_schemas\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"StructuredOutputParser\"},\"description\":\"\",\"base_classes\":[\"BaseOutputParser\",\"Runnable\",\"BaseLLMOutputParser\",\"Generic\",\"RunnableSerializable\",\"StructuredOutputParser\",\"Serializable\",\"object\"],\"display_name\":\"StructuredOutputParser\",\"documentation\":\"https://python.langchain.com/docs/modules/model_io/output_parsers/structured\",\"custom_fields\":{},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":false}},\"retrievers\":{\"AmazonKendra\":{\"template\":{\"attribute_filter\":{\"type\":\"code\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"attribute_filter\",\"display_name\":\"Attribute Filter\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.schema import BaseRetriever\\nfrom langchain_community.retrievers import AmazonKendraRetriever\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass AmazonKendraRetrieverComponent(CustomComponent):\\n    display_name: str = \\\"Amazon Kendra Retriever\\\"\\n    description: str = \\\"Retriever that uses the Amazon Kendra API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"index_id\\\": {\\\"display_name\\\": \\\"Index ID\\\"},\\n            \\\"region_name\\\": {\\\"display_name\\\": \\\"Region Name\\\"},\\n            \\\"credentials_profile_name\\\": {\\\"display_name\\\": \\\"Credentials Profile Name\\\"},\\n            \\\"attribute_filter\\\": {\\n                \\\"display_name\\\": \\\"Attribute Filter\\\",\\n                \\\"field_type\\\": \\\"code\\\",\\n            },\\n            \\\"top_k\\\": {\\\"display_name\\\": \\\"Top K\\\", \\\"field_type\\\": \\\"int\\\"},\\n            \\\"user_context\\\": {\\n                \\\"display_name\\\": \\\"User Context\\\",\\n                \\\"field_type\\\": \\\"code\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        index_id: str,\\n        top_k: int = 3,\\n        region_name: Optional[str] = None,\\n        credentials_profile_name: Optional[str] = None,\\n        attribute_filter: Optional[dict] = None,\\n        user_context: Optional[dict] = None,\\n    ) -> BaseRetriever:\\n        try:\\n            output = AmazonKendraRetriever(\\n                index_id=index_id,\\n                top_k=top_k,\\n                region_name=region_name,\\n                credentials_profile_name=credentials_profile_name,\\n                attribute_filter=attribute_filter,\\n                user_context=user_context,\\n            )  # type: ignore\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to AmazonKendra API.\\\") from e\\n        return output\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"credentials_profile_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"credentials_profile_name\",\"display_name\":\"Credentials Profile Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"index_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"index_id\",\"display_name\":\"Index ID\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"region_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"region_name\",\"display_name\":\"Region Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"top_k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":3,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"user_context\":{\"type\":\"code\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"user_context\",\"display_name\":\"User Context\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Retriever that uses the Amazon Kendra API.\",\"base_classes\":[\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Amazon Kendra Retriever\",\"documentation\":\"\",\"custom_fields\":{\"index_id\":null,\"top_k\":null,\"region_name\":null,\"credentials_profile_name\":null,\"attribute_filter\":null,\"user_context\":null},\"output_types\":[\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"VectaraSelfQueryRetriver\":{\"template\":{\"llm\":{\"type\":\"BaseLanguageModel\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"For self query retriever\",\"title_case\":false},\"vectorstore\":{\"type\":\"VectorStore\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vectorstore\",\"display_name\":\"Vector Store\",\"advanced\":false,\"dynamic\":false,\"info\":\"Input Vectara Vectore Store\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List\\nfrom langflow import CustomComponent\\nimport json\\nfrom langchain.schema import BaseRetriever\\nfrom langchain.schema.vectorstore import VectorStore\\nfrom langchain.base_language import BaseLanguageModel\\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\\nfrom langchain.chains.query_constructor.base import AttributeInfo\\n\\n\\nclass VectaraSelfQueryRetriverComponent(CustomComponent):\\n    \\\"\\\"\\\"\\n    A custom component for implementing Vectara Self Query Retriever using a vector store.\\n    \\\"\\\"\\\"\\n\\n    display_name: str = \\\"Vectara Self Query Retriever for Vectara Vector Store\\\"\\n    description: str = \\\"Implementation of Vectara Self Query Retriever\\\"\\n    documentation = \\\"https://python.langchain.com/docs/integrations/retrievers/self_query/vectara_self_query\\\"\\n    beta = True\\n\\n    field_config = {\\n        \\\"code\\\": {\\\"show\\\": True},\\n        \\\"vectorstore\\\": {\\\"display_name\\\": \\\"Vector Store\\\", \\\"info\\\": \\\"Input Vectara Vectore Store\\\"},\\n        \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\", \\\"info\\\": \\\"For self query retriever\\\"},\\n        \\\"document_content_description\\\": {\\n            \\\"display_name\\\": \\\"Document Content Description\\\",\\n            \\\"info\\\": \\\"For self query retriever\\\",\\n        },\\n        \\\"metadata_field_info\\\": {\\n            \\\"display_name\\\": \\\"Metadata Field Info\\\",\\n            \\\"info\\\": 'Each metadata field info is a string in the form of key value pair dictionary containing additional search metadata.\\\\nExample input: {\\\"name\\\":\\\"speech\\\",\\\"description\\\":\\\"what name of the speech\\\",\\\"type\\\":\\\"string or list[string]\\\"}.\\\\nThe keys should remain constant(name, description, type)',\\n        },\\n    }\\n\\n    def build(\\n        self,\\n        vectorstore: VectorStore,\\n        document_content_description: str,\\n        llm: BaseLanguageModel,\\n        metadata_field_info: List[str],\\n    ) -> BaseRetriever:\\n        metadata_field_obj = []\\n\\n        for meta in metadata_field_info:\\n            meta_obj = json.loads(meta)\\n            if \\\"name\\\" not in meta_obj or \\\"description\\\" not in meta_obj or \\\"type\\\" not in meta_obj:\\n                raise Exception(\\\"Incorrect metadata field info format.\\\")\\n            attribute_info = AttributeInfo(\\n                name=meta_obj[\\\"name\\\"],\\n                description=meta_obj[\\\"description\\\"],\\n                type=meta_obj[\\\"type\\\"],\\n            )\\n            metadata_field_obj.append(attribute_info)\\n\\n        return SelfQueryRetriever.from_llm(\\n            llm, vectorstore, document_content_description, metadata_field_obj, verbose=True\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"document_content_description\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"document_content_description\",\"display_name\":\"Document Content Description\",\"advanced\":false,\"dynamic\":false,\"info\":\"For self query retriever\",\"title_case\":false,\"input_types\":[\"Text\"]},\"metadata_field_info\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata_field_info\",\"display_name\":\"Metadata Field Info\",\"advanced\":false,\"dynamic\":false,\"info\":\"Each metadata field info is a string in the form of key value pair dictionary containing additional search metadata.\\nExample input: {\\\"name\\\":\\\"speech\\\",\\\"description\\\":\\\"what name of the speech\\\",\\\"type\\\":\\\"string or list[string]\\\"}.\\nThe keys should remain constant(name, description, type)\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Implementation of Vectara Self Query Retriever\",\"base_classes\":[\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Vectara Self Query Retriever for Vectara Vector Store\",\"documentation\":\"https://python.langchain.com/docs/integrations/retrievers/self_query/vectara_self_query\",\"custom_fields\":{\"vectorstore\":null,\"document_content_description\":null,\"llm\":null,\"metadata_field_info\":null},\"output_types\":[\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"MultiQueryRetriever\":{\"template\":{\"llm\":{\"type\":\"BaseLLM\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"llm\",\"display_name\":\"LLM\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"prompt\":{\"type\":\"PromptTemplate\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"prompt\",\"display_name\":\"Prompt\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"retriever\":{\"type\":\"BaseRetriever\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"retriever\",\"display_name\":\"Retriever\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Callable, Optional, Union\\n\\nfrom langchain.retrievers import MultiQueryRetriever\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLLM, BaseRetriever, PromptTemplate\\n\\n\\nclass MultiQueryRetrieverComponent(CustomComponent):\\n    display_name = \\\"MultiQueryRetriever\\\"\\n    description = \\\"Initialize from llm using default template.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/data_connection/retrievers/how_to/MultiQueryRetriever\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"llm\\\": {\\\"display_name\\\": \\\"LLM\\\"},\\n            \\\"prompt\\\": {\\n                \\\"display_name\\\": \\\"Prompt\\\",\\n                \\\"default\\\": {\\n                    \\\"input_variables\\\": [\\\"question\\\"],\\n                    \\\"input_types\\\": {},\\n                    \\\"output_parser\\\": None,\\n                    \\\"partial_variables\\\": {},\\n                    \\\"template\\\": \\\"You are an AI language model assistant. Your task is \\\\n\\\"\\n                    \\\"to generate 3 different versions of the given user \\\\n\\\"\\n                    \\\"question to retrieve relevant documents from a vector database. \\\\n\\\"\\n                    \\\"By generating multiple perspectives on the user question, \\\\n\\\"\\n                    \\\"your goal is to help the user overcome some of the limitations \\\\n\\\"\\n                    \\\"of distance-based similarity search. Provide these alternative \\\\n\\\"\\n                    \\\"questions separated by newlines. Original question: {question}\\\",\\n                    \\\"template_format\\\": \\\"f-string\\\",\\n                    \\\"validate_template\\\": False,\\n                    \\\"_type\\\": \\\"prompt\\\",\\n                },\\n            },\\n            \\\"retriever\\\": {\\\"display_name\\\": \\\"Retriever\\\"},\\n            \\\"parser_key\\\": {\\\"display_name\\\": \\\"Parser Key\\\", \\\"default\\\": \\\"lines\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        llm: BaseLLM,\\n        retriever: BaseRetriever,\\n        prompt: Optional[PromptTemplate] = None,\\n        parser_key: str = \\\"lines\\\",\\n    ) -> Union[Callable, MultiQueryRetriever]:\\n        if not prompt:\\n            return MultiQueryRetriever.from_llm(llm=llm, retriever=retriever, parser_key=parser_key)\\n        else:\\n            return MultiQueryRetriever.from_llm(llm=llm, retriever=retriever, prompt=prompt, parser_key=parser_key)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"parser_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"lines\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"parser_key\",\"display_name\":\"Parser Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Initialize from llm using default template.\",\"base_classes\":[],\"display_name\":\"MultiQueryRetriever\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/retrievers/how_to/MultiQueryRetriever\",\"custom_fields\":{\"llm\":null,\"retriever\":null,\"prompt\":null,\"parser_key\":null},\"output_types\":[],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"MetalRetriever\":{\"template\":{\"api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_key\",\"display_name\":\"API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"client_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"client_id\",\"display_name\":\"Client ID\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.schema import BaseRetriever\\nfrom langchain_community.retrievers import MetalRetriever\\nfrom metal_sdk.metal import Metal  # type: ignore\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass MetalRetrieverComponent(CustomComponent):\\n    display_name: str = \\\"Metal Retriever\\\"\\n    description: str = \\\"Retriever that uses the Metal API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"api_key\\\": {\\\"display_name\\\": \\\"API Key\\\", \\\"password\\\": True},\\n            \\\"client_id\\\": {\\\"display_name\\\": \\\"Client ID\\\", \\\"password\\\": True},\\n            \\\"index_id\\\": {\\\"display_name\\\": \\\"Index ID\\\"},\\n            \\\"params\\\": {\\\"display_name\\\": \\\"Parameters\\\"},\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(self, api_key: str, client_id: str, index_id: str, params: Optional[dict] = None) -> BaseRetriever:\\n        try:\\n            metal = Metal(api_key=api_key, client_id=client_id, index_id=index_id)\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to Metal API.\\\") from e\\n        return MetalRetriever(client=metal, params=params or {})\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"index_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"index_id\",\"display_name\":\"Index ID\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"params\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"params\",\"display_name\":\"Parameters\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Retriever that uses the Metal API.\",\"base_classes\":[\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Metal Retriever\",\"documentation\":\"\",\"custom_fields\":{\"api_key\":null,\"client_id\":null,\"index_id\":null,\"params\":null},\"output_types\":[\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"custom_components\":{\"CustomComponent\":{\"template\":{\"param\":{\"type\":\"Data\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"param\",\"display_name\":\"Parameter\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langflow.field_typing import Data\\n\\n\\nclass Component(CustomComponent):\\n    documentation: str = \\\"http://docs.langflow.org/components/custom\\\"\\n\\n    def build_config(self):\\n        return {\\\"param\\\": {\\\"display_name\\\": \\\"Parameter\\\"}}\\n\\n    def build(self, param: Data) -> Data:\\n        return param\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"base_classes\":[\"object\",\"Data\"],\"display_name\":\"CustomComponent\",\"documentation\":\"http://docs.langflow.org/components/custom\",\"custom_fields\":{\"param\":null},\"output_types\":[\"Data\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"vectorstores\":{\"Weaviate\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"embedding\":{\"type\":\"Embeddings\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"api_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_key\",\"display_name\":\"API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"attributes\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"attributes\",\"display_name\":\"Attributes\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional, Union\\n\\nimport weaviate  # type: ignore\\nfrom langchain.embeddings.base import Embeddings\\nfrom langchain.schema import BaseRetriever, Document\\nfrom langchain_community.vectorstores import VectorStore, Weaviate\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass WeaviateVectorStore(CustomComponent):\\n    display_name: str = \\\"Weaviate\\\"\\n    description: str = \\\"Implementation of Vector Store using Weaviate\\\"\\n    documentation = \\\"https://python.langchain.com/docs/integrations/vectorstores/weaviate\\\"\\n    beta = True\\n    field_config = {\\n        \\\"url\\\": {\\\"display_name\\\": \\\"Weaviate URL\\\", \\\"value\\\": \\\"http://localhost:8080\\\"},\\n        \\\"api_key\\\": {\\n            \\\"display_name\\\": \\\"API Key\\\",\\n            \\\"password\\\": True,\\n            \\\"required\\\": False,\\n        },\\n        \\\"index_name\\\": {\\n            \\\"display_name\\\": \\\"Index name\\\",\\n            \\\"required\\\": False,\\n        },\\n        \\\"text_key\\\": {\\\"display_name\\\": \\\"Text Key\\\", \\\"required\\\": False, \\\"advanced\\\": True, \\\"value\\\": \\\"text\\\"},\\n        \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\", \\\"is_list\\\": True},\\n        \\\"embedding\\\": {\\\"display_name\\\": \\\"Embedding\\\"},\\n        \\\"attributes\\\": {\\n            \\\"display_name\\\": \\\"Attributes\\\",\\n            \\\"required\\\": False,\\n            \\\"is_list\\\": True,\\n            \\\"field_type\\\": \\\"str\\\",\\n            \\\"advanced\\\": True,\\n        },\\n        \\\"search_by_text\\\": {\\\"display_name\\\": \\\"Search By Text\\\", \\\"field_type\\\": \\\"bool\\\", \\\"advanced\\\": True},\\n        \\\"code\\\": {\\\"show\\\": False},\\n    }\\n\\n    def build(\\n        self,\\n        url: str,\\n        search_by_text: bool = False,\\n        api_key: Optional[str] = None,\\n        index_name: Optional[str] = None,\\n        text_key: str = \\\"text\\\",\\n        embedding: Optional[Embeddings] = None,\\n        documents: Optional[Document] = None,\\n        attributes: Optional[list] = None,\\n    ) -> Union[VectorStore, BaseRetriever]:\\n        if api_key:\\n            auth_config = weaviate.AuthApiKey(api_key=api_key)\\n            client = weaviate.Client(url=url, auth_client_secret=auth_config)\\n        else:\\n            client = weaviate.Client(url=url)\\n\\n        def _to_pascal_case(word: str):\\n            if word and not word[0].isupper():\\n                word = word.capitalize()\\n\\n            if word.isidentifier():\\n                return word\\n\\n            word = word.replace(\\\"-\\\", \\\" \\\").replace(\\\"_\\\", \\\" \\\")\\n            parts = word.split()\\n            pascal_case_word = \\\"\\\".join([part.capitalize() for part in parts])\\n\\n            return pascal_case_word\\n\\n        index_name = _to_pascal_case(index_name) if index_name else None\\n\\n        if documents is not None and embedding is not None:\\n            return Weaviate.from_documents(\\n                client=client,\\n                index_name=index_name,\\n                documents=documents,\\n                embedding=embedding,\\n                by_text=search_by_text,\\n            )\\n\\n        return Weaviate(\\n            client=client,\\n            index_name=index_name,\\n            text_key=text_key,\\n            embedding=embedding,\\n            by_text=search_by_text,\\n            attributes=attributes if attributes is not None else [],\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"index_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"index_name\",\"display_name\":\"Index name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"search_by_text\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"search_by_text\",\"display_name\":\"Search By Text\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"text_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"text\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"text_key\",\"display_name\":\"Text Key\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"http://localhost:8080\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"url\",\"display_name\":\"Weaviate URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Implementation of Vector Store using Weaviate\",\"base_classes\":[\"Runnable\",\"Generic\",\"VectorStore\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Weaviate\",\"documentation\":\"https://python.langchain.com/docs/integrations/vectorstores/weaviate\",\"custom_fields\":{\"url\":null,\"search_by_text\":null,\"api_key\":null,\"index_name\":null,\"text_key\":null,\"embedding\":null,\"documents\":null,\"attributes\":null},\"output_types\":[\"VectorStore\",\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"Vectara\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"If provided, will be upserted to corpus (optional)\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"import tempfile\\nimport urllib\\nimport urllib.request\\nfrom typing import List, Optional, Union\\n\\nfrom langchain_community.embeddings import FakeEmbeddings\\nfrom langchain_community.vectorstores.vectara import Vectara\\nfrom langchain_core.vectorstores import VectorStore\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseRetriever, Document\\n\\n\\nclass VectaraComponent(CustomComponent):\\n    display_name: str = \\\"Vectara\\\"\\n    description: str = \\\"Implementation of Vector Store using Vectara\\\"\\n    documentation = \\\"https://python.langchain.com/docs/integrations/vectorstores/vectara\\\"\\n    beta = True\\n    field_config = {\\n        \\\"vectara_customer_id\\\": {\\n            \\\"display_name\\\": \\\"Vectara Customer ID\\\",\\n        },\\n        \\\"vectara_corpus_id\\\": {\\n            \\\"display_name\\\": \\\"Vectara Corpus ID\\\",\\n        },\\n        \\\"vectara_api_key\\\": {\\n            \\\"display_name\\\": \\\"Vectara API Key\\\",\\n            \\\"password\\\": True,\\n        },\\n        \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\", \\\"info\\\": \\\"If provided, will be upserted to corpus (optional)\\\"},\\n        \\\"files_url\\\": {\\n            \\\"display_name\\\": \\\"Files Url\\\",\\n            \\\"info\\\": \\\"Make vectara object using url of files (optional)\\\",\\n        },\\n    }\\n\\n    def build(\\n        self,\\n        vectara_customer_id: str,\\n        vectara_corpus_id: str,\\n        vectara_api_key: str,\\n        files_url: Optional[List[str]] = None,\\n        documents: Optional[Document] = None,\\n    ) -> Union[VectorStore, BaseRetriever]:\\n        source = \\\"Langflow\\\"\\n\\n        if documents is not None:\\n            return Vectara.from_documents(\\n                documents=documents,  # type: ignore\\n                embedding=FakeEmbeddings(size=768),\\n                vectara_customer_id=vectara_customer_id,\\n                vectara_corpus_id=vectara_corpus_id,\\n                vectara_api_key=vectara_api_key,\\n                source=source,\\n            )\\n\\n        if files_url is not None:\\n            files_list = []\\n            for url in files_url:\\n                name = tempfile.NamedTemporaryFile().name\\n                urllib.request.urlretrieve(url, name)\\n                files_list.append(name)\\n\\n            return Vectara.from_files(\\n                files=files_list,\\n                embedding=FakeEmbeddings(size=768),\\n                vectara_customer_id=vectara_customer_id,\\n                vectara_corpus_id=vectara_corpus_id,\\n                vectara_api_key=vectara_api_key,\\n                source=source,\\n            )\\n\\n        return Vectara(\\n            vectara_customer_id=vectara_customer_id,\\n            vectara_corpus_id=vectara_corpus_id,\\n            vectara_api_key=vectara_api_key,\\n            source=source,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"files_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"files_url\",\"display_name\":\"Files Url\",\"advanced\":false,\"dynamic\":false,\"info\":\"Make vectara object using url of files (optional)\",\"title_case\":false,\"input_types\":[\"Text\"]},\"vectara_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"vectara_api_key\",\"display_name\":\"Vectara API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"vectara_corpus_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vectara_corpus_id\",\"display_name\":\"Vectara Corpus ID\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"vectara_customer_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vectara_customer_id\",\"display_name\":\"Vectara Customer ID\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Implementation of Vector Store using Vectara\",\"base_classes\":[\"Runnable\",\"Generic\",\"VectorStore\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Vectara\",\"documentation\":\"https://python.langchain.com/docs/integrations/vectorstores/vectara\",\"custom_fields\":{\"vectara_customer_id\":null,\"vectara_corpus_id\":null,\"vectara_api_key\":null,\"files_url\":null,\"documents\":null},\"output_types\":[\"VectorStore\",\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"Chroma\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"embedding\":{\"type\":\"Embeddings\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chroma_server_cors_allow_origins\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_cors_allow_origins\",\"display_name\":\"Server CORS Allow Origins\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"chroma_server_grpc_port\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_grpc_port\",\"display_name\":\"Server gRPC Port\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chroma_server_host\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_host\",\"display_name\":\"Server Host\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"chroma_server_port\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_port\",\"display_name\":\"Server Port\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chroma_server_ssl_enabled\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_ssl_enabled\",\"display_name\":\"Server SSL Enabled\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional, Union\\n\\nimport chromadb  # type: ignore\\nfrom langchain.embeddings.base import Embeddings\\nfrom langchain.schema import BaseRetriever, Document\\nfrom langchain_community.vectorstores import VectorStore\\nfrom langchain_community.vectorstores.chroma import Chroma\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass ChromaComponent(CustomComponent):\\n    \\\"\\\"\\\"\\n    A custom component for implementing a Vector Store using Chroma.\\n    \\\"\\\"\\\"\\n\\n    display_name: str = \\\"Chroma\\\"\\n    description: str = \\\"Implementation of Vector Store using Chroma\\\"\\n    documentation = \\\"https://python.langchain.com/docs/integrations/vectorstores/chroma\\\"\\n    beta: bool = True\\n    icon = \\\"Chroma\\\"\\n\\n    def build_config(self):\\n        \\\"\\\"\\\"\\n        Builds the configuration for the component.\\n\\n        Returns:\\n        - dict: A dictionary containing the configuration options for the component.\\n        \\\"\\\"\\\"\\n        return {\\n            \\\"collection_name\\\": {\\\"display_name\\\": \\\"Collection Name\\\", \\\"value\\\": \\\"langflow\\\"},\\n            \\\"index_directory\\\": {\\\"display_name\\\": \\\"Persist Directory\\\"},\\n            \\\"code\\\": {\\\"advanced\\\": True, \\\"display_name\\\": \\\"Code\\\"},\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\", \\\"is_list\\\": True},\\n            \\\"embedding\\\": {\\\"display_name\\\": \\\"Embedding\\\"},\\n            \\\"chroma_server_cors_allow_origins\\\": {\\n                \\\"display_name\\\": \\\"Server CORS Allow Origins\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"chroma_server_host\\\": {\\\"display_name\\\": \\\"Server Host\\\", \\\"advanced\\\": True},\\n            \\\"chroma_server_port\\\": {\\\"display_name\\\": \\\"Server Port\\\", \\\"advanced\\\": True},\\n            \\\"chroma_server_grpc_port\\\": {\\n                \\\"display_name\\\": \\\"Server gRPC Port\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"chroma_server_ssl_enabled\\\": {\\n                \\\"display_name\\\": \\\"Server SSL Enabled\\\",\\n                \\\"advanced\\\": True,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        collection_name: str,\\n        embedding: Embeddings,\\n        chroma_server_ssl_enabled: bool,\\n        index_directory: Optional[str] = None,\\n        documents: Optional[List[Document]] = None,\\n        chroma_server_cors_allow_origins: Optional[str] = None,\\n        chroma_server_host: Optional[str] = None,\\n        chroma_server_port: Optional[int] = None,\\n        chroma_server_grpc_port: Optional[int] = None,\\n    ) -> Union[VectorStore, BaseRetriever]:\\n        \\\"\\\"\\\"\\n        Builds the Vector Store or BaseRetriever object.\\n\\n        Args:\\n        - collection_name (str): The name of the collection.\\n        - index_directory (Optional[str]): The directory to persist the Vector Store to.\\n        - chroma_server_ssl_enabled (bool): Whether to enable SSL for the Chroma server.\\n        - embedding (Optional[Embeddings]): The embeddings to use for the Vector Store.\\n        - documents (Optional[Document]): The documents to use for the Vector Store.\\n        - chroma_server_cors_allow_origins (Optional[str]): The CORS allow origins for the Chroma server.\\n        - chroma_server_host (Optional[str]): The host for the Chroma server.\\n        - chroma_server_port (Optional[int]): The port for the Chroma server.\\n        - chroma_server_grpc_port (Optional[int]): The gRPC port for the Chroma server.\\n\\n        Returns:\\n        - Union[VectorStore, BaseRetriever]: The Vector Store or BaseRetriever object.\\n        \\\"\\\"\\\"\\n\\n        # Chroma settings\\n        chroma_settings = None\\n\\n        if chroma_server_host is not None:\\n            chroma_settings = chromadb.config.Settings(\\n                chroma_server_cors_allow_origins=chroma_server_cors_allow_origins\\n                or None,\\n                chroma_server_host=chroma_server_host,\\n                chroma_server_port=chroma_server_port or None,\\n                chroma_server_grpc_port=chroma_server_grpc_port or None,\\n                chroma_server_ssl_enabled=chroma_server_ssl_enabled,\\n            )\\n\\n        # If documents, then we need to create a Chroma instance using .from_documents\\n\\n        # Check index_directory and expand it if it is a relative path\\n\\n        index_directory = self.resolve_path(index_directory)\\n\\n        if documents is not None and embedding is not None:\\n            if len(documents) == 0:\\n                raise ValueError(\\n                    \\\"If documents are provided, there must be at least one document.\\\"\\n                )\\n            chroma = Chroma.from_documents(\\n                documents=documents,  # type: ignore\\n                persist_directory=index_directory,\\n                collection_name=collection_name,\\n                embedding=embedding,\\n                client_settings=chroma_settings,\\n            )\\n        else:\\n            chroma = Chroma(\\n                persist_directory=index_directory,\\n                client_settings=chroma_settings,\\n                embedding_function=embedding,\\n            )\\n        return chroma\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":true,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"collection_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"langflow\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"collection_name\",\"display_name\":\"Collection Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"index_directory\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"index_directory\",\"display_name\":\"Persist Directory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Implementation of Vector Store using Chroma\",\"icon\":\"Chroma\",\"base_classes\":[\"Runnable\",\"Generic\",\"VectorStore\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Chroma\",\"documentation\":\"https://python.langchain.com/docs/integrations/vectorstores/chroma\",\"custom_fields\":{\"collection_name\":null,\"embedding\":null,\"chroma_server_ssl_enabled\":null,\"index_directory\":null,\"documents\":null,\"chroma_server_cors_allow_origins\":null,\"chroma_server_host\":null,\"chroma_server_port\":null,\"chroma_server_grpc_port\":null},\"output_types\":[\"VectorStore\",\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"SupabaseVectorStore\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"embedding\":{\"type\":\"Embeddings\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Union\\n\\nfrom langchain.schema import BaseRetriever\\nfrom langchain_community.vectorstores import VectorStore\\nfrom langchain_community.vectorstores.supabase import SupabaseVectorStore\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Document, Embeddings, NestedDict\\nfrom supabase.client import Client, create_client\\n\\n\\nclass SupabaseComponent(CustomComponent):\\n    display_name = \\\"Supabase\\\"\\n    description = \\\"Return VectorStore initialized from texts and embeddings.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\"},\\n            \\\"embedding\\\": {\\\"display_name\\\": \\\"Embedding\\\"},\\n            \\\"query_name\\\": {\\\"display_name\\\": \\\"Query Name\\\"},\\n            \\\"search_kwargs\\\": {\\\"display_name\\\": \\\"Search Kwargs\\\", \\\"advanced\\\": True},\\n            \\\"supabase_service_key\\\": {\\\"display_name\\\": \\\"Supabase Service Key\\\"},\\n            \\\"supabase_url\\\": {\\\"display_name\\\": \\\"Supabase URL\\\"},\\n            \\\"table_name\\\": {\\\"display_name\\\": \\\"Table Name\\\", \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        embedding: Embeddings,\\n        documents: List[Document],\\n        query_name: str = \\\"\\\",\\n        search_kwargs: NestedDict = {},\\n        supabase_service_key: str = \\\"\\\",\\n        supabase_url: str = \\\"\\\",\\n        table_name: str = \\\"\\\",\\n    ) -> Union[VectorStore, SupabaseVectorStore, BaseRetriever]:\\n        supabase: Client = create_client(supabase_url, supabase_key=supabase_service_key)\\n        return SupabaseVectorStore.from_documents(\\n            documents=documents,\\n            embedding=embedding,\\n            query_name=query_name,\\n            search_kwargs=search_kwargs,\\n            client=supabase,\\n            table_name=table_name,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"query_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"query_name\",\"display_name\":\"Query Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"search_kwargs\":{\"type\":\"NestedDict\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"search_kwargs\",\"display_name\":\"Search Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"supabase_service_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"supabase_service_key\",\"display_name\":\"Supabase Service Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"supabase_url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"supabase_url\",\"display_name\":\"Supabase URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"table_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"table_name\",\"display_name\":\"Table Name\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Return VectorStore initialized from texts and embeddings.\",\"base_classes\":[\"Runnable\",\"Generic\",\"VectorStore\",\"SupabaseVectorStore\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Supabase\",\"documentation\":\"\",\"custom_fields\":{\"embedding\":null,\"documents\":null,\"query_name\":null,\"search_kwargs\":null,\"supabase_service_key\":null,\"supabase_url\":null,\"table_name\":null},\"output_types\":[\"VectorStore\",\"SupabaseVectorStore\",\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"Redis\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"embedding\":{\"type\":\"Embeddings\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional, Union\\n\\nfrom langchain.embeddings.base import Embeddings\\nfrom langchain_community.vectorstores import VectorStore\\nfrom langchain_community.vectorstores.redis import Redis\\nfrom langchain_core.documents import Document\\nfrom langchain_core.retrievers import BaseRetriever\\nfrom langflow import CustomComponent\\n\\n\\nclass RedisComponent(CustomComponent):\\n    \\\"\\\"\\\"\\n    A custom component for implementing a Vector Store using Redis.\\n    \\\"\\\"\\\"\\n\\n    display_name: str = \\\"Redis\\\"\\n    description: str = \\\"Implementation of Vector Store using Redis\\\"\\n    documentation = \\\"https://python.langchain.com/docs/integrations/vectorstores/redis\\\"\\n    beta = True\\n\\n    def build_config(self):\\n        \\\"\\\"\\\"\\n        Builds the configuration for the component.\\n\\n        Returns:\\n        - dict: A dictionary containing the configuration options for the component.\\n        \\\"\\\"\\\"\\n        return {\\n            \\\"index_name\\\": {\\\"display_name\\\": \\\"Index Name\\\", \\\"value\\\": \\\"your_index\\\"},\\n            \\\"code\\\": {\\\"show\\\": False, \\\"display_name\\\": \\\"Code\\\"},\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\", \\\"is_list\\\": True},\\n            \\\"embedding\\\": {\\\"display_name\\\": \\\"Embedding\\\"},\\n            \\\"schema\\\": {\\\"display_name\\\": \\\"Schema\\\", \\\"file_types\\\": [\\\".yaml\\\"]},\\n            \\\"redis_server_url\\\": {\\n                \\\"display_name\\\": \\\"Redis Server Connection String\\\",\\n                \\\"advanced\\\": False,\\n            },\\n            \\\"redis_index_name\\\": {\\\"display_name\\\": \\\"Redis Index\\\", \\\"advanced\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        embedding: Embeddings,\\n        redis_server_url: str,\\n        redis_index_name: str,\\n        schema: Optional[str] = None,\\n        documents: Optional[Document] = None,\\n    ) -> Union[VectorStore, BaseRetriever]:\\n        \\\"\\\"\\\"\\n        Builds the Vector Store or BaseRetriever object.\\n\\n        Args:\\n        - embedding (Embeddings): The embeddings to use for the Vector Store.\\n        - documents (Optional[Document]): The documents to use for the Vector Store.\\n        - redis_index_name (str): The name of the Redis index.\\n        - redis_server_url (str): The URL for the Redis server.\\n\\n        Returns:\\n        - VectorStore: The Vector Store object.\\n        \\\"\\\"\\\"\\n        if documents is None:\\n            if schema is None:\\n                raise ValueError(\\\"If no documents are provided, a schema must be provided.\\\")\\n            redis_vs = Redis.from_existing_index(\\n                embedding=embedding,\\n                index_name=redis_index_name,\\n                schema=schema,\\n                key_prefix=None,\\n                redis_url=redis_server_url,\\n            )\\n        else:\\n            redis_vs = Redis.from_documents(\\n                documents=documents,  # type: ignore\\n                embedding=embedding,\\n                redis_url=redis_server_url,\\n                index_name=redis_index_name,\\n            )\\n        return redis_vs\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"redis_index_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"redis_index_name\",\"display_name\":\"Redis Index\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"redis_server_url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"redis_server_url\",\"display_name\":\"Redis Server Connection String\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"schema\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".yaml\"],\"file_path\":\"\",\"password\":false,\"name\":\"schema\",\"display_name\":\"Schema\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Implementation of Vector Store using Redis\",\"base_classes\":[\"Runnable\",\"Generic\",\"VectorStore\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Redis\",\"documentation\":\"https://python.langchain.com/docs/integrations/vectorstores/redis\",\"custom_fields\":{\"embedding\":null,\"redis_server_url\":null,\"redis_index_name\":null,\"schema\":null,\"documents\":null},\"output_types\":[\"VectorStore\",\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"pgvector\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"embedding\":{\"type\":\"Embeddings\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional, Union\\n\\nfrom langchain.embeddings.base import Embeddings\\nfrom langchain_community.vectorstores import VectorStore\\nfrom langchain_community.vectorstores.pgvector import PGVector\\nfrom langchain_core.documents import Document\\nfrom langchain_core.retrievers import BaseRetriever\\nfrom langflow import CustomComponent\\n\\n\\nclass PGVectorComponent(CustomComponent):\\n    \\\"\\\"\\\"\\n    A custom component for implementing a Vector Store using PostgreSQL.\\n    \\\"\\\"\\\"\\n\\n    display_name: str = \\\"PGVector\\\"\\n    description: str = \\\"Implementation of Vector Store using PostgreSQL\\\"\\n    documentation = \\\"https://python.langchain.com/docs/integrations/vectorstores/pgvector\\\"\\n\\n    def build_config(self):\\n        \\\"\\\"\\\"\\n        Builds the configuration for the component.\\n\\n        Returns:\\n        - dict: A dictionary containing the configuration options for the component.\\n        \\\"\\\"\\\"\\n        return {\\n            \\\"code\\\": {\\\"show\\\": False},\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\", \\\"is_list\\\": True},\\n            \\\"embedding\\\": {\\\"display_name\\\": \\\"Embedding\\\"},\\n            \\\"pg_server_url\\\": {\\n                \\\"display_name\\\": \\\"PostgreSQL Server Connection String\\\",\\n                \\\"advanced\\\": False,\\n            },\\n            \\\"collection_name\\\": {\\\"display_name\\\": \\\"Table\\\", \\\"advanced\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        embedding: Embeddings,\\n        pg_server_url: str,\\n        collection_name: str,\\n        documents: Optional[Document] = None,\\n    ) -> Union[VectorStore, BaseRetriever]:\\n        \\\"\\\"\\\"\\n        Builds the Vector Store or BaseRetriever object.\\n\\n        Args:\\n        - embedding (Embeddings): The embeddings to use for the Vector Store.\\n        - documents (Optional[Document]): The documents to use for the Vector Store.\\n        - collection_name (str): The name of the PG table.\\n        - pg_server_url (str): The URL for the PG server.\\n\\n        Returns:\\n        - VectorStore: The Vector Store object.\\n        \\\"\\\"\\\"\\n\\n        try:\\n            if documents is None:\\n                vector_store = PGVector.from_existing_index(\\n                    embedding=embedding,\\n                    collection_name=collection_name,\\n                    connection_string=pg_server_url,\\n                )\\n            else:\\n                vector_store = PGVector.from_documents(\\n                    embedding=embedding,\\n                    documents=documents,  # type: ignore\\n                    collection_name=collection_name,\\n                    connection_string=pg_server_url,\\n                )\\n        except Exception as e:\\n            raise RuntimeError(f\\\"Failed to build PGVector: {e}\\\")\\n        return vector_store\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"collection_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"collection_name\",\"display_name\":\"Table\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"pg_server_url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"pg_server_url\",\"display_name\":\"PostgreSQL Server Connection String\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Implementation of Vector Store using PostgreSQL\",\"base_classes\":[\"Runnable\",\"Generic\",\"VectorStore\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"PGVector\",\"documentation\":\"https://python.langchain.com/docs/integrations/vectorstores/pgvector\",\"custom_fields\":{\"embedding\":null,\"pg_server_url\":null,\"collection_name\":null,\"documents\":null},\"output_types\":[\"VectorStore\",\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"Pinecone\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"embedding\":{\"type\":\"Embeddings\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"import os\\nfrom typing import List, Optional, Union\\n\\nimport pinecone  # type: ignore\\nfrom langchain.schema import BaseRetriever\\nfrom langchain_community.vectorstores import VectorStore\\nfrom langchain_community.vectorstores.pinecone import Pinecone\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Document, Embeddings\\n\\n\\nclass PineconeComponent(CustomComponent):\\n    display_name = \\\"Pinecone\\\"\\n    description = \\\"Construct Pinecone wrapper from raw documents.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\"},\\n            \\\"embedding\\\": {\\\"display_name\\\": \\\"Embedding\\\"},\\n            \\\"index_name\\\": {\\\"display_name\\\": \\\"Index Name\\\"},\\n            \\\"namespace\\\": {\\\"display_name\\\": \\\"Namespace\\\"},\\n            \\\"pinecone_api_key\\\": {\\\"display_name\\\": \\\"Pinecone API Key\\\", \\\"default\\\": \\\"\\\", \\\"password\\\": True, \\\"required\\\": True},\\n            \\\"pinecone_env\\\": {\\\"display_name\\\": \\\"Pinecone Environment\\\", \\\"default\\\": \\\"\\\", \\\"required\\\": True},\\n            \\\"search_kwargs\\\": {\\\"display_name\\\": \\\"Search Kwargs\\\", \\\"default\\\": \\\"{}\\\"},\\n            \\\"pool_threads\\\": {\\\"display_name\\\": \\\"Pool Threads\\\", \\\"default\\\": 1, \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        embedding: Embeddings,\\n        pinecone_env: str,\\n        documents: List[Document],\\n        text_key: str = \\\"text\\\",\\n        pool_threads: int = 4,\\n        index_name: Optional[str] = None,\\n        pinecone_api_key: Optional[str] = None,\\n        namespace: Optional[str] = \\\"default\\\",\\n    ) -> Union[VectorStore, Pinecone, BaseRetriever]:\\n        if pinecone_api_key is None or pinecone_env is None:\\n            raise ValueError(\\\"Pinecone API Key and Environment are required.\\\")\\n        if os.getenv(\\\"PINECONE_API_KEY\\\") is None and pinecone_api_key is None:\\n            raise ValueError(\\\"Pinecone API Key is required.\\\")\\n\\n        pinecone.init(api_key=pinecone_api_key, environment=pinecone_env)  # type: ignore\\n        if not index_name:\\n            raise ValueError(\\\"Index Name is required.\\\")\\n        if documents:\\n            return Pinecone.from_documents(\\n                documents=documents,\\n                embedding=embedding,\\n                index_name=index_name,\\n                pool_threads=pool_threads,\\n                namespace=namespace,\\n                text_key=text_key,\\n            )\\n\\n        return Pinecone.from_existing_index(\\n            index_name=index_name,\\n            embedding=embedding,\\n            text_key=text_key,\\n            namespace=namespace,\\n            pool_threads=pool_threads,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"index_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"index_name\",\"display_name\":\"Index Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"namespace\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"default\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"namespace\",\"display_name\":\"Namespace\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"pinecone_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"pinecone_api_key\",\"display_name\":\"Pinecone API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"pinecone_env\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"pinecone_env\",\"display_name\":\"Pinecone Environment\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"pool_threads\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":4,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"pool_threads\",\"display_name\":\"Pool Threads\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"text_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"text\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"text_key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Construct Pinecone wrapper from raw documents.\",\"base_classes\":[\"Runnable\",\"Generic\",\"VectorStore\",\"Pinecone\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Pinecone\",\"documentation\":\"\",\"custom_fields\":{\"embedding\":null,\"pinecone_env\":null,\"documents\":null,\"text_key\":null,\"pool_threads\":null,\"index_name\":null,\"pinecone_api_key\":null,\"namespace\":null},\"output_types\":[\"VectorStore\",\"Pinecone\",\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"Qdrant\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"embedding\":{\"type\":\"Embeddings\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"api_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_key\",\"display_name\":\"API Key\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional, Union\\n\\nfrom langchain.schema import BaseRetriever\\nfrom langchain_community.vectorstores import VectorStore\\nfrom langchain_community.vectorstores.qdrant import Qdrant\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Document, Embeddings, NestedDict\\n\\n\\nclass QdrantComponent(CustomComponent):\\n    display_name = \\\"Qdrant\\\"\\n    description = \\\"Construct Qdrant wrapper from a list of texts.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\"},\\n            \\\"embedding\\\": {\\\"display_name\\\": \\\"Embedding\\\"},\\n            \\\"api_key\\\": {\\\"display_name\\\": \\\"API Key\\\", \\\"password\\\": True, \\\"advanced\\\": True},\\n            \\\"collection_name\\\": {\\\"display_name\\\": \\\"Collection Name\\\"},\\n            \\\"content_payload_key\\\": {\\\"display_name\\\": \\\"Content Payload Key\\\", \\\"advanced\\\": True},\\n            \\\"distance_func\\\": {\\\"display_name\\\": \\\"Distance Function\\\", \\\"advanced\\\": True},\\n            \\\"grpc_port\\\": {\\\"display_name\\\": \\\"gRPC Port\\\", \\\"advanced\\\": True},\\n            \\\"host\\\": {\\\"display_name\\\": \\\"Host\\\", \\\"advanced\\\": True},\\n            \\\"https\\\": {\\\"display_name\\\": \\\"HTTPS\\\", \\\"advanced\\\": True},\\n            \\\"location\\\": {\\\"display_name\\\": \\\"Location\\\", \\\"advanced\\\": True},\\n            \\\"metadata_payload_key\\\": {\\\"display_name\\\": \\\"Metadata Payload Key\\\", \\\"advanced\\\": True},\\n            \\\"path\\\": {\\\"display_name\\\": \\\"Path\\\", \\\"advanced\\\": True},\\n            \\\"port\\\": {\\\"display_name\\\": \\\"Port\\\", \\\"advanced\\\": True},\\n            \\\"prefer_grpc\\\": {\\\"display_name\\\": \\\"Prefer gRPC\\\", \\\"advanced\\\": True},\\n            \\\"prefix\\\": {\\\"display_name\\\": \\\"Prefix\\\", \\\"advanced\\\": True},\\n            \\\"search_kwargs\\\": {\\\"display_name\\\": \\\"Search Kwargs\\\", \\\"advanced\\\": True},\\n            \\\"timeout\\\": {\\\"display_name\\\": \\\"Timeout\\\", \\\"advanced\\\": True},\\n            \\\"url\\\": {\\\"display_name\\\": \\\"URL\\\", \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        embedding: Embeddings,\\n        collection_name: str,\\n        documents: Optional[Document] = None,\\n        api_key: Optional[str] = None,\\n        content_payload_key: str = \\\"page_content\\\",\\n        distance_func: str = \\\"Cosine\\\",\\n        grpc_port: int = 6334,\\n        https: bool = False,\\n        host: Optional[str] = None,\\n        location: Optional[str] = None,\\n        metadata_payload_key: str = \\\"metadata\\\",\\n        path: Optional[str] = None,\\n        port: Optional[int] = 6333,\\n        prefer_grpc: bool = False,\\n        prefix: Optional[str] = None,\\n        search_kwargs: Optional[NestedDict] = None,\\n        timeout: Optional[int] = None,\\n        url: Optional[str] = None,\\n    ) -> Union[VectorStore, Qdrant, BaseRetriever]:\\n        if documents is None:\\n            from qdrant_client import QdrantClient\\n\\n            client = QdrantClient(\\n                location=location,\\n                url=host,\\n                port=port,\\n                grpc_port=grpc_port,\\n                https=https,\\n                prefix=prefix,\\n                timeout=timeout,\\n                prefer_grpc=prefer_grpc,\\n                metadata_payload_key=metadata_payload_key,\\n                content_payload_key=content_payload_key,\\n                api_key=api_key,\\n                collection_name=collection_name,\\n                host=host,\\n                path=path,\\n            )\\n            vs = Qdrant(\\n                client=client,\\n                collection_name=collection_name,\\n                embeddings=embedding,\\n            )\\n            return vs\\n        else:\\n            vs = Qdrant.from_documents(\\n                documents=documents,  # type: ignore\\n                embedding=embedding,\\n                api_key=api_key,\\n                collection_name=collection_name,\\n                content_payload_key=content_payload_key,\\n                distance_func=distance_func,\\n                grpc_port=grpc_port,\\n                host=host,\\n                https=https,\\n                location=location,\\n                metadata_payload_key=metadata_payload_key,\\n                path=path,\\n                port=port,\\n                prefer_grpc=prefer_grpc,\\n                prefix=prefix,\\n                search_kwargs=search_kwargs,\\n                timeout=timeout,\\n                url=url,\\n            )\\n        return vs\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"collection_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"collection_name\",\"display_name\":\"Collection Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"content_payload_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"page_content\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"content_payload_key\",\"display_name\":\"Content Payload Key\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"distance_func\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"Cosine\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"distance_func\",\"display_name\":\"Distance Function\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"grpc_port\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":6334,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"grpc_port\",\"display_name\":\"gRPC Port\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"host\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"host\",\"display_name\":\"Host\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"https\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"https\",\"display_name\":\"HTTPS\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"location\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"location\",\"display_name\":\"Location\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"metadata_payload_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"metadata\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata_payload_key\",\"display_name\":\"Metadata Payload Key\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"path\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"path\",\"display_name\":\"Path\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"port\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":6333,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"port\",\"display_name\":\"Port\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"prefer_grpc\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"prefer_grpc\",\"display_name\":\"Prefer gRPC\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"prefix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"prefix\",\"display_name\":\"Prefix\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"search_kwargs\":{\"type\":\"NestedDict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"search_kwargs\",\"display_name\":\"Search Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"timeout\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"timeout\",\"display_name\":\"Timeout\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"url\",\"display_name\":\"URL\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Construct Qdrant wrapper from a list of texts.\",\"base_classes\":[\"Runnable\",\"Generic\",\"VectorStore\",\"Qdrant\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"Qdrant\",\"documentation\":\"\",\"custom_fields\":{\"embedding\":null,\"collection_name\":null,\"documents\":null,\"api_key\":null,\"content_payload_key\":null,\"distance_func\":null,\"grpc_port\":null,\"https\":null,\"host\":null,\"location\":null,\"metadata_payload_key\":null,\"path\":null,\"port\":null,\"prefer_grpc\":null,\"prefix\":null,\"search_kwargs\":null,\"timeout\":null,\"url\":null},\"output_types\":[\"VectorStore\",\"Qdrant\",\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"MongoDBAtlasVectorSearch\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"embedding\":{\"type\":\"Embeddings\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional\\n\\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import (\\n    Document,\\n    Embeddings,\\n    NestedDict,\\n)\\n\\n\\nclass MongoDBAtlasComponent(CustomComponent):\\n    display_name = \\\"MongoDB Atlas\\\"\\n    description = \\\"Construct a `MongoDB Atlas Vector Search` vector store from raw documents.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\"},\\n            \\\"embedding\\\": {\\\"display_name\\\": \\\"Embedding\\\"},\\n            \\\"collection_name\\\": {\\\"display_name\\\": \\\"Collection Name\\\"},\\n            \\\"db_name\\\": {\\\"display_name\\\": \\\"Database Name\\\"},\\n            \\\"index_name\\\": {\\\"display_name\\\": \\\"Index Name\\\"},\\n            \\\"mongodb_atlas_cluster_uri\\\": {\\\"display_name\\\": \\\"MongoDB Atlas Cluster URI\\\"},\\n            \\\"search_kwargs\\\": {\\\"display_name\\\": \\\"Search Kwargs\\\", \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        documents: List[Document],\\n        embedding: Embeddings,\\n        collection_name: str = \\\"\\\",\\n        db_name: str = \\\"\\\",\\n        index_name: str = \\\"\\\",\\n        mongodb_atlas_cluster_uri: str = \\\"\\\",\\n        search_kwargs: Optional[NestedDict] = None,\\n    ) -> MongoDBAtlasVectorSearch:\\n        search_kwargs = search_kwargs or {}\\n        return MongoDBAtlasVectorSearch(\\n            documents=documents,\\n            embedding=embedding,\\n            collection_name=collection_name,\\n            db_name=db_name,\\n            index_name=index_name,\\n            mongodb_atlas_cluster_uri=mongodb_atlas_cluster_uri,\\n            search_kwargs=search_kwargs,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"collection_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"collection_name\",\"display_name\":\"Collection Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"db_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"db_name\",\"display_name\":\"Database Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"index_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"index_name\",\"display_name\":\"Index Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"mongodb_atlas_cluster_uri\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"mongodb_atlas_cluster_uri\",\"display_name\":\"MongoDB Atlas Cluster URI\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"search_kwargs\":{\"type\":\"NestedDict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"search_kwargs\",\"display_name\":\"Search Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Construct a `MongoDB Atlas Vector Search` vector store from raw documents.\",\"base_classes\":[\"VectorStore\",\"MongoDBAtlasVectorSearch\"],\"display_name\":\"MongoDB Atlas\",\"documentation\":\"\",\"custom_fields\":{\"documents\":null,\"embedding\":null,\"collection_name\":null,\"db_name\":null,\"index_name\":null,\"mongodb_atlas_cluster_uri\":null,\"search_kwargs\":null},\"output_types\":[\"MongoDBAtlasVectorSearch\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"ChromaSearch\":{\"template\":{\"embedding\":{\"type\":\"Embeddings\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"Embedding model to vectorize inputs (make sure to use same as index)\",\"title_case\":false},\"inputs\":{\"type\":\"Text\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chroma_server_cors_allow_origins\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_cors_allow_origins\",\"display_name\":\"Server CORS Allow Origins\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"chroma_server_grpc_port\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_grpc_port\",\"display_name\":\"Server gRPC Port\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chroma_server_host\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_host\",\"display_name\":\"Server Host\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"chroma_server_port\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_port\",\"display_name\":\"Server Port\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"chroma_server_ssl_enabled\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"chroma_server_ssl_enabled\",\"display_name\":\"Server SSL Enabled\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional\\n\\nimport chromadb  # type: ignore\\nfrom langchain_community.vectorstores.chroma import Chroma\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Embeddings, Text\\nfrom langflow.schema import Record, docs_to_records\\n\\n\\nclass ChromaSearchComponent(CustomComponent):\\n    \\\"\\\"\\\"\\n    A custom component for implementing a Vector Store using Chroma.\\n    \\\"\\\"\\\"\\n\\n    display_name: str = \\\"Chroma Search\\\"\\n    description: str = \\\"Search a Chroma collection for similar documents.\\\"\\n    beta: bool = True\\n    icon = \\\"Chroma\\\"\\n\\n    def build_config(self):\\n        \\\"\\\"\\\"\\n        Builds the configuration for the component.\\n\\n        Returns:\\n        - dict: A dictionary containing the configuration options for the component.\\n        \\\"\\\"\\\"\\n        return {\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n            \\\"search_type\\\": {\\n                \\\"display_name\\\": \\\"Search Type\\\",\\n                \\\"options\\\": [\\\"Similarity\\\", \\\"MMR\\\"],\\n            },\\n            \\\"collection_name\\\": {\\\"display_name\\\": \\\"Collection Name\\\", \\\"value\\\": \\\"langflow\\\"},\\n            # \\\"persist\\\": {\\\"display_name\\\": \\\"Persist\\\"},\\n            \\\"index_directory\\\": {\\\"display_name\\\": \\\"Index Directory\\\"},\\n            \\\"code\\\": {\\\"show\\\": False, \\\"display_name\\\": \\\"Code\\\"},\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\", \\\"is_list\\\": True},\\n            \\\"embedding\\\": {\\n                \\\"display_name\\\": \\\"Embedding\\\",\\n                \\\"info\\\": \\\"Embedding model to vectorize inputs (make sure to use same as index)\\\",\\n            },\\n            \\\"chroma_server_cors_allow_origins\\\": {\\n                \\\"display_name\\\": \\\"Server CORS Allow Origins\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"chroma_server_host\\\": {\\\"display_name\\\": \\\"Server Host\\\", \\\"advanced\\\": True},\\n            \\\"chroma_server_port\\\": {\\\"display_name\\\": \\\"Server Port\\\", \\\"advanced\\\": True},\\n            \\\"chroma_server_grpc_port\\\": {\\n                \\\"display_name\\\": \\\"Server gRPC Port\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"chroma_server_ssl_enabled\\\": {\\n                \\\"display_name\\\": \\\"Server SSL Enabled\\\",\\n                \\\"advanced\\\": True,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        inputs: Text,\\n        search_type: str,\\n        collection_name: str,\\n        embedding: Embeddings,\\n        chroma_server_ssl_enabled: bool,\\n        index_directory: Optional[str] = None,\\n        chroma_server_cors_allow_origins: Optional[str] = None,\\n        chroma_server_host: Optional[str] = None,\\n        chroma_server_port: Optional[int] = None,\\n        chroma_server_grpc_port: Optional[int] = None,\\n    ) -> List[Record]:\\n        \\\"\\\"\\\"\\n        Builds the Vector Store or BaseRetriever object.\\n\\n        Args:\\n        - collection_name (str): The name of the collection.\\n        - persist_directory (Optional[str]): The directory to persist the Vector Store to.\\n        - chroma_server_ssl_enabled (bool): Whether to enable SSL for the Chroma server.\\n        - persist (bool): Whether to persist the Vector Store or not.\\n        - embedding (Optional[Embeddings]): The embeddings to use for the Vector Store.\\n        - documents (Optional[Document]): The documents to use for the Vector Store.\\n        - chroma_server_cors_allow_origins (Optional[str]): The CORS allow origins for the Chroma server.\\n        - chroma_server_host (Optional[str]): The host for the Chroma server.\\n        - chroma_server_port (Optional[int]): The port for the Chroma server.\\n        - chroma_server_grpc_port (Optional[int]): The gRPC port for the Chroma server.\\n\\n        Returns:\\n        - Union[VectorStore, BaseRetriever]: The Vector Store or BaseRetriever object.\\n        \\\"\\\"\\\"\\n\\n        # Chroma settings\\n        chroma_settings = None\\n\\n        if chroma_server_host is not None:\\n            chroma_settings = chromadb.config.Settings(\\n                chroma_server_cors_allow_origins=chroma_server_cors_allow_origins or None,\\n                chroma_server_host=chroma_server_host,\\n                chroma_server_port=chroma_server_port or None,\\n                chroma_server_grpc_port=chroma_server_grpc_port or None,\\n                chroma_server_ssl_enabled=chroma_server_ssl_enabled,\\n            )\\n        index_directory = self.resolve_path(index_directory)\\n        chroma = Chroma(\\n            embedding_function=embedding,\\n            collection_name=collection_name,\\n            persist_directory=index_directory,\\n            client_settings=chroma_settings,\\n        )\\n\\n        # Validate the inputs\\n        docs = []\\n        if inputs and isinstance(inputs, str):\\n            docs = chroma.search(query=inputs, search_type=search_type.lower())\\n        else:\\n            raise ValueError(\\\"Invalid inputs provided.\\\")\\n        return docs_to_records(docs)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"collection_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"langflow\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"collection_name\",\"display_name\":\"Collection Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"index_directory\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"index_directory\",\"display_name\":\"Index Directory\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"search_type\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"Similarity\",\"MMR\"],\"name\":\"search_type\",\"display_name\":\"Search Type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Search a Chroma collection for similar documents.\",\"icon\":\"Chroma\",\"base_classes\":[\"Record\"],\"display_name\":\"Chroma Search\",\"documentation\":\"\",\"custom_fields\":{\"inputs\":null,\"search_type\":null,\"collection_name\":null,\"embedding\":null,\"chroma_server_ssl_enabled\":null,\"index_directory\":null,\"chroma_server_cors_allow_origins\":null,\"chroma_server_host\":null,\"chroma_server_port\":null,\"chroma_server_grpc_port\":null},\"output_types\":[\"Record\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"FAISS\":{\"template\":{\"documents\":{\"type\":\"Document\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"documents\",\"display_name\":\"Documents\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"embedding\":{\"type\":\"Embeddings\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"embedding\",\"display_name\":\"Embedding\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Union\\n\\nfrom langchain.schema import BaseRetriever\\nfrom langchain_community.vectorstores import VectorStore\\nfrom langchain_community.vectorstores.faiss import FAISS\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Document, Embeddings\\n\\n\\nclass FAISSComponent(CustomComponent):\\n    display_name = \\\"FAISS\\\"\\n    description = \\\"Construct FAISS wrapper from raw documents.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"documents\\\": {\\\"display_name\\\": \\\"Documents\\\"},\\n            \\\"embedding\\\": {\\\"display_name\\\": \\\"Embedding\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        embedding: Embeddings,\\n        documents: List[Document],\\n    ) -> Union[VectorStore, FAISS, BaseRetriever]:\\n        return FAISS.from_documents(documents=documents, embedding=embedding)\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Construct FAISS wrapper from raw documents.\",\"base_classes\":[\"Runnable\",\"FAISS\",\"Generic\",\"VectorStore\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseRetriever\"],\"display_name\":\"FAISS\",\"documentation\":\"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\",\"custom_fields\":{\"embedding\":null,\"documents\":null},\"output_types\":[\"VectorStore\",\"FAISS\",\"BaseRetriever\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"models\":{\"LlamaCppModel\":{\"template\":{\"metadata\":{\"type\":\"Dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_kwargs\":{\"type\":\"Dict\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".bin\"],\"file_path\":\"\",\"password\":false,\"name\":\"model_path\",\"display_name\":\"Model Path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"cache\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"cache\",\"display_name\":\"Cache\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"client\":{\"type\":\"Any\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"client\",\"display_name\":\"Client\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Any, Dict, List, Optional\\n\\nfrom langchain_community.llms.llamacpp import LlamaCpp\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass LlamaCppComponent(CustomComponent):\\n    display_name = \\\"LlamaCppModel\\\"\\n    description = \\\"Generate text using llama.cpp model.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/llamacpp\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"grammar\\\": {\\\"display_name\\\": \\\"Grammar\\\", \\\"advanced\\\": True},\\n            \\\"cache\\\": {\\\"display_name\\\": \\\"Cache\\\", \\\"advanced\\\": True},\\n            \\\"client\\\": {\\\"display_name\\\": \\\"Client\\\", \\\"advanced\\\": True},\\n            \\\"echo\\\": {\\\"display_name\\\": \\\"Echo\\\", \\\"advanced\\\": True},\\n            \\\"f16_kv\\\": {\\\"display_name\\\": \\\"F16 KV\\\", \\\"advanced\\\": True},\\n            \\\"grammar_path\\\": {\\\"display_name\\\": \\\"Grammar Path\\\", \\\"advanced\\\": True},\\n            \\\"last_n_tokens_size\\\": {\\n                \\\"display_name\\\": \\\"Last N Tokens Size\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"logits_all\\\": {\\\"display_name\\\": \\\"Logits All\\\", \\\"advanced\\\": True},\\n            \\\"logprobs\\\": {\\\"display_name\\\": \\\"Logprobs\\\", \\\"advanced\\\": True},\\n            \\\"lora_base\\\": {\\\"display_name\\\": \\\"Lora Base\\\", \\\"advanced\\\": True},\\n            \\\"lora_path\\\": {\\\"display_name\\\": \\\"Lora Path\\\", \\\"advanced\\\": True},\\n            \\\"max_tokens\\\": {\\\"display_name\\\": \\\"Max Tokens\\\", \\\"advanced\\\": True},\\n            \\\"metadata\\\": {\\\"display_name\\\": \\\"Metadata\\\", \\\"advanced\\\": True},\\n            \\\"model_kwargs\\\": {\\\"display_name\\\": \\\"Model Kwargs\\\", \\\"advanced\\\": True},\\n            \\\"model_path\\\": {\\n                \\\"display_name\\\": \\\"Model Path\\\",\\n                \\\"field_type\\\": \\\"file\\\",\\n                \\\"file_types\\\": [\\\".bin\\\"],\\n                \\\"required\\\": True,\\n            },\\n            \\\"n_batch\\\": {\\\"display_name\\\": \\\"N Batch\\\", \\\"advanced\\\": True},\\n            \\\"n_ctx\\\": {\\\"display_name\\\": \\\"N Ctx\\\", \\\"advanced\\\": True},\\n            \\\"n_gpu_layers\\\": {\\\"display_name\\\": \\\"N GPU Layers\\\", \\\"advanced\\\": True},\\n            \\\"n_parts\\\": {\\\"display_name\\\": \\\"N Parts\\\", \\\"advanced\\\": True},\\n            \\\"n_threads\\\": {\\\"display_name\\\": \\\"N Threads\\\", \\\"advanced\\\": True},\\n            \\\"repeat_penalty\\\": {\\\"display_name\\\": \\\"Repeat Penalty\\\", \\\"advanced\\\": True},\\n            \\\"rope_freq_base\\\": {\\\"display_name\\\": \\\"Rope Freq Base\\\", \\\"advanced\\\": True},\\n            \\\"rope_freq_scale\\\": {\\\"display_name\\\": \\\"Rope Freq Scale\\\", \\\"advanced\\\": True},\\n            \\\"seed\\\": {\\\"display_name\\\": \\\"Seed\\\", \\\"advanced\\\": True},\\n            \\\"stop\\\": {\\\"display_name\\\": \\\"Stop\\\", \\\"advanced\\\": True},\\n            \\\"streaming\\\": {\\\"display_name\\\": \\\"Streaming\\\", \\\"advanced\\\": True},\\n            \\\"suffix\\\": {\\\"display_name\\\": \\\"Suffix\\\", \\\"advanced\\\": True},\\n            \\\"tags\\\": {\\\"display_name\\\": \\\"Tags\\\", \\\"advanced\\\": True},\\n            \\\"temperature\\\": {\\\"display_name\\\": \\\"Temperature\\\"},\\n            \\\"top_k\\\": {\\\"display_name\\\": \\\"Top K\\\", \\\"advanced\\\": True},\\n            \\\"top_p\\\": {\\\"display_name\\\": \\\"Top P\\\", \\\"advanced\\\": True},\\n            \\\"use_mlock\\\": {\\\"display_name\\\": \\\"Use Mlock\\\", \\\"advanced\\\": True},\\n            \\\"use_mmap\\\": {\\\"display_name\\\": \\\"Use Mmap\\\", \\\"advanced\\\": True},\\n            \\\"verbose\\\": {\\\"display_name\\\": \\\"Verbose\\\", \\\"advanced\\\": True},\\n            \\\"vocab_only\\\": {\\\"display_name\\\": \\\"Vocab Only\\\", \\\"advanced\\\": True},\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        model_path: str,\\n        inputs: str,\\n        grammar: Optional[str] = None,\\n        cache: Optional[bool] = None,\\n        client: Optional[Any] = None,\\n        echo: Optional[bool] = False,\\n        f16_kv: bool = True,\\n        grammar_path: Optional[str] = None,\\n        last_n_tokens_size: Optional[int] = 64,\\n        logits_all: bool = False,\\n        logprobs: Optional[int] = None,\\n        lora_base: Optional[str] = None,\\n        lora_path: Optional[str] = None,\\n        max_tokens: Optional[int] = 256,\\n        metadata: Optional[Dict] = None,\\n        model_kwargs: Dict = {},\\n        n_batch: Optional[int] = 8,\\n        n_ctx: int = 512,\\n        n_gpu_layers: Optional[int] = 1,\\n        n_parts: int = -1,\\n        n_threads: Optional[int] = 1,\\n        repeat_penalty: Optional[float] = 1.1,\\n        rope_freq_base: float = 10000.0,\\n        rope_freq_scale: float = 1.0,\\n        seed: int = -1,\\n        stop: Optional[List[str]] = [],\\n        streaming: bool = True,\\n        suffix: Optional[str] = \\\"\\\",\\n        tags: Optional[List[str]] = [],\\n        temperature: Optional[float] = 0.8,\\n        top_k: Optional[int] = 40,\\n        top_p: Optional[float] = 0.95,\\n        use_mlock: bool = False,\\n        use_mmap: Optional[bool] = True,\\n        verbose: bool = True,\\n        vocab_only: bool = False,\\n    ) -> Text:\\n        output = LlamaCpp(\\n            model_path=model_path,\\n            grammar=grammar,\\n            cache=cache,\\n            client=client,\\n            echo=echo,\\n            f16_kv=f16_kv,\\n            grammar_path=grammar_path,\\n            last_n_tokens_size=last_n_tokens_size,\\n            logits_all=logits_all,\\n            logprobs=logprobs,\\n            lora_base=lora_base,\\n            lora_path=lora_path,\\n            max_tokens=max_tokens,\\n            metadata=metadata,\\n            model_kwargs=model_kwargs,\\n            n_batch=n_batch,\\n            n_ctx=n_ctx,\\n            n_gpu_layers=n_gpu_layers,\\n            n_parts=n_parts,\\n            n_threads=n_threads,\\n            repeat_penalty=repeat_penalty,\\n            rope_freq_base=rope_freq_base,\\n            rope_freq_scale=rope_freq_scale,\\n            seed=seed,\\n            stop=stop,\\n            streaming=streaming,\\n            suffix=suffix,\\n            tags=tags,\\n            temperature=temperature,\\n            top_k=top_k,\\n            top_p=top_p,\\n            use_mlock=use_mlock,\\n            use_mmap=use_mmap,\\n            verbose=verbose,\\n            vocab_only=vocab_only,\\n        )\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"echo\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"echo\",\"display_name\":\"Echo\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"f16_kv\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"f16_kv\",\"display_name\":\"F16 KV\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"grammar\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"grammar\",\"display_name\":\"Grammar\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"grammar_path\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"grammar_path\",\"display_name\":\"Grammar Path\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"last_n_tokens_size\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":64,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"last_n_tokens_size\",\"display_name\":\"Last N Tokens Size\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"logits_all\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"logits_all\",\"display_name\":\"Logits All\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"logprobs\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"logprobs\",\"display_name\":\"Logprobs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"lora_base\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"lora_base\",\"display_name\":\"Lora Base\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"lora_path\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"lora_path\",\"display_name\":\"Lora Path\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":256,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_batch\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_batch\",\"display_name\":\"N Batch\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_ctx\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":512,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_ctx\",\"display_name\":\"N Ctx\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_gpu_layers\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_gpu_layers\",\"display_name\":\"N GPU Layers\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_parts\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":-1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_parts\",\"display_name\":\"N Parts\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_threads\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_threads\",\"display_name\":\"N Threads\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"repeat_penalty\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1.1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"repeat_penalty\",\"display_name\":\"Repeat Penalty\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"rope_freq_base\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10000.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"rope_freq_base\",\"display_name\":\"Rope Freq Base\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"rope_freq_scale\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"rope_freq_scale\",\"display_name\":\"Rope Freq Scale\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"seed\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":-1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"seed\",\"display_name\":\"Seed\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"stop\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":[],\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"stop\",\"display_name\":\"Stop\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"streaming\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"streaming\",\"display_name\":\"Streaming\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"suffix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"suffix\",\"display_name\":\"Suffix\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":[],\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"display_name\":\"Tags\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":40,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.95,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"use_mlock\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"use_mlock\",\"display_name\":\"Use Mlock\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"use_mmap\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"use_mmap\",\"display_name\":\"Use Mmap\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"verbose\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"verbose\",\"display_name\":\"Verbose\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"vocab_only\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vocab_only\",\"display_name\":\"Vocab Only\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using llama.cpp model.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"LlamaCppModel\",\"documentation\":\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/llamacpp\",\"custom_fields\":{\"model_path\":null,\"inputs\":null,\"grammar\":null,\"cache\":null,\"client\":null,\"echo\":null,\"f16_kv\":null,\"grammar_path\":null,\"last_n_tokens_size\":null,\"logits_all\":null,\"logprobs\":null,\"lora_base\":null,\"lora_path\":null,\"max_tokens\":null,\"metadata\":null,\"model_kwargs\":null,\"n_batch\":null,\"n_ctx\":null,\"n_gpu_layers\":null,\"n_parts\":null,\"n_threads\":null,\"repeat_penalty\":null,\"rope_freq_base\":null,\"rope_freq_scale\":null,\"seed\":null,\"stop\":null,\"streaming\":null,\"suffix\":null,\"tags\":null,\"temperature\":null,\"top_k\":null,\"top_p\":null,\"use_mlock\":null,\"use_mmap\":null,\"verbose\":null,\"vocab_only\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"BaiduQianfanChatModel\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_community.chat_models.baidu_qianfan_endpoint import QianfanChatEndpoint\\nfrom pydantic.v1 import SecretStr\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass QianfanChatEndpointComponent(CustomComponent):\\n    display_name: str = \\\"QianfanChat Model\\\"\\n    description: str = (\\n        \\\"Generate text using Baidu Qianfan chat models. Get more detail from \\\"\\n        \\\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint.\\\"\\n    )\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"options\\\": [\\n                    \\\"ERNIE-Bot\\\",\\n                    \\\"ERNIE-Bot-turbo\\\",\\n                    \\\"BLOOMZ-7B\\\",\\n                    \\\"Llama-2-7b-chat\\\",\\n                    \\\"Llama-2-13b-chat\\\",\\n                    \\\"Llama-2-70b-chat\\\",\\n                    \\\"Qianfan-BLOOMZ-7B-compressed\\\",\\n                    \\\"Qianfan-Chinese-Llama-2-7B\\\",\\n                    \\\"ChatGLM2-6B-32K\\\",\\n                    \\\"AquilaChat-7B\\\",\\n                ],\\n                \\\"info\\\": \\\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\\\",\\n                \\\"required\\\": True,\\n            },\\n            \\\"qianfan_ak\\\": {\\n                \\\"display_name\\\": \\\"Qianfan Ak\\\",\\n                \\\"required\\\": True,\\n                \\\"password\\\": True,\\n                \\\"info\\\": \\\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\\\",\\n            },\\n            \\\"qianfan_sk\\\": {\\n                \\\"display_name\\\": \\\"Qianfan Sk\\\",\\n                \\\"required\\\": True,\\n                \\\"password\\\": True,\\n                \\\"info\\\": \\\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\\\",\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top p\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\\\",\\n                \\\"value\\\": 0.8,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\\\",\\n                \\\"value\\\": 0.95,\\n            },\\n            \\\"penalty_score\\\": {\\n                \\\"display_name\\\": \\\"Penalty Score\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\\\",\\n                \\\"value\\\": 1.0,\\n            },\\n            \\\"endpoint\\\": {\\n                \\\"display_name\\\": \\\"Endpoint\\\",\\n                \\\"info\\\": \\\"Endpoint of the Qianfan LLM, required if custom model used.\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        inputs: str,\\n        model: str = \\\"ERNIE-Bot-turbo\\\",\\n        qianfan_ak: Optional[str] = None,\\n        qianfan_sk: Optional[str] = None,\\n        top_p: Optional[float] = None,\\n        temperature: Optional[float] = None,\\n        penalty_score: Optional[float] = None,\\n        endpoint: Optional[str] = None,\\n    ) -> Text:\\n        try:\\n            output = QianfanChatEndpoint(  # type: ignore\\n                model=model,\\n                qianfan_ak=SecretStr(qianfan_ak) if qianfan_ak else None,\\n                qianfan_sk=SecretStr(qianfan_sk) if qianfan_sk else None,\\n                top_p=top_p,\\n                temperature=temperature,\\n                penalty_score=penalty_score,\\n                endpoint=endpoint,\\n            )\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to Baidu Qianfan API.\\\") from e\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"endpoint\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"endpoint\",\"display_name\":\"Endpoint\",\"advanced\":false,\"dynamic\":false,\"info\":\"Endpoint of the Qianfan LLM, required if custom model used.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"ERNIE-Bot-turbo\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"ERNIE-Bot\",\"ERNIE-Bot-turbo\",\"BLOOMZ-7B\",\"Llama-2-7b-chat\",\"Llama-2-13b-chat\",\"Llama-2-70b-chat\",\"Qianfan-BLOOMZ-7B-compressed\",\"Qianfan-Chinese-Llama-2-7B\",\"ChatGLM2-6B-32K\",\"AquilaChat-7B\"],\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\",\"title_case\":false,\"input_types\":[\"Text\"]},\"penalty_score\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"penalty_score\",\"display_name\":\"Penalty Score\",\"advanced\":false,\"dynamic\":false,\"info\":\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"qianfan_ak\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"qianfan_ak\",\"display_name\":\"Qianfan Ak\",\"advanced\":false,\"dynamic\":false,\"info\":\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\"title_case\":false,\"input_types\":[\"Text\"]},\"qianfan_sk\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"qianfan_sk\",\"display_name\":\"Qianfan Sk\",\"advanced\":false,\"dynamic\":false,\"info\":\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.95,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top p\",\"advanced\":false,\"dynamic\":false,\"info\":\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using Baidu Qianfan chat models. Get more detail from https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"QianfanChat Model\",\"documentation\":\"\",\"custom_fields\":{\"inputs\":null,\"model\":null,\"qianfan_ak\":null,\"qianfan_sk\":null,\"top_p\":null,\"temperature\":null,\"penalty_score\":null,\"endpoint\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"GoogleGenerativeAIModel\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_google_genai import ChatGoogleGenerativeAI  # type: ignore\\nfrom pydantic.v1.types import SecretStr\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import RangeSpec, Text\\n\\n\\nclass GoogleGenerativeAIComponent(CustomComponent):\\n    display_name: str = \\\"Google Generative AIModel\\\"\\n    description: str = \\\"Generate text using Google Generative AI to generate text.\\\"\\n    documentation: str = \\\"http://docs.langflow.org/components/custom\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"google_api_key\\\": {\\n                \\\"display_name\\\": \\\"Google API Key\\\",\\n                \\\"info\\\": \\\"The Google API Key to use for the Google Generative AI.\\\",\\n            },\\n            \\\"max_output_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Output Tokens\\\",\\n                \\\"info\\\": \\\"The maximum number of tokens to generate.\\\",\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"info\\\": \\\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\\\",\\n            },\\n            \\\"top_k\\\": {\\n                \\\"display_name\\\": \\\"Top K\\\",\\n                \\\"info\\\": \\\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\\\",\\n                \\\"range_spec\\\": RangeSpec(min=0, max=2, step=0.1),\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top P\\\",\\n                \\\"info\\\": \\\"The maximum cumulative probability of tokens to consider when sampling.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"n\\\": {\\n                \\\"display_name\\\": \\\"N\\\",\\n                \\\"info\\\": \\\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model\\\",\\n                \\\"info\\\": \\\"The name of the model to use. Supported examples: gemini-pro\\\",\\n                \\\"options\\\": [\\\"gemini-pro\\\", \\\"gemini-pro-vision\\\"],\\n            },\\n            \\\"code\\\": {\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        google_api_key: str,\\n        model: str,\\n        inputs: str,\\n        max_output_tokens: Optional[int] = None,\\n        temperature: float = 0.1,\\n        top_k: Optional[int] = None,\\n        top_p: Optional[float] = None,\\n        n: Optional[int] = 1,\\n    ) -> Text:\\n        output = ChatGoogleGenerativeAI(\\n            model=model,\\n            max_output_tokens=max_output_tokens or None,  # type: ignore\\n            temperature=temperature,\\n            top_k=top_k or None,\\n            top_p=top_p or None,  # type: ignore\\n            n=n or 1,\\n            google_api_key=SecretStr(google_api_key),\\n        )\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":true,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"google_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"google_api_key\",\"display_name\":\"Google API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The Google API Key to use for the Google Generative AI.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_output_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_output_tokens\",\"display_name\":\"Max Output Tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"The maximum number of tokens to generate.\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"gemini-pro\",\"gemini-pro-vision\"],\"name\":\"model\",\"display_name\":\"Model\",\"advanced\":false,\"dynamic\":false,\"info\":\"The name of the model to use. Supported examples: gemini-pro\",\"title_case\":false,\"input_types\":[\"Text\"]},\"n\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n\",\"display_name\":\"N\",\"advanced\":true,\"dynamic\":false,\"info\":\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\"title_case\":false},\"temperature\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\"rangeSpec\":{\"min\":0.0,\"max\":2.0,\"step\":0.1},\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"The maximum cumulative probability of tokens to consider when sampling.\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using Google Generative AI to generate text.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"Google Generative AIModel\",\"documentation\":\"http://docs.langflow.org/components/custom\",\"custom_fields\":{\"google_api_key\":null,\"model\":null,\"inputs\":null,\"max_output_tokens\":null,\"temperature\":null,\"top_k\":null,\"top_p\":null,\"n\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"CTransformersModel\":{\"template\":{\"model_file\":{\"type\":\"file\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".bin\"],\"file_path\":\"\",\"password\":false,\"name\":\"model_file\",\"display_name\":\"Model File\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Dict, Optional\\n\\nfrom langchain_community.llms.ctransformers import CTransformers\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass CTransformersComponent(CustomComponent):\\n    display_name = \\\"CTransformersModel\\\"\\n    description = \\\"Generate text using CTransformers LLM models\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/ctransformers\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\\"display_name\\\": \\\"Model\\\", \\\"required\\\": True},\\n            \\\"model_file\\\": {\\n                \\\"display_name\\\": \\\"Model File\\\",\\n                \\\"required\\\": False,\\n                \\\"field_type\\\": \\\"file\\\",\\n                \\\"file_types\\\": [\\\".bin\\\"],\\n            },\\n            \\\"model_type\\\": {\\\"display_name\\\": \\\"Model Type\\\", \\\"required\\\": True},\\n            \\\"config\\\": {\\n                \\\"display_name\\\": \\\"Config\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n                \\\"field_type\\\": \\\"dict\\\",\\n                \\\"value\\\": '{\\\"top_k\\\":40,\\\"top_p\\\":0.95,\\\"temperature\\\":0.8,\\\"repetition_penalty\\\":1.1,\\\"last_n_tokens\\\":64,\\\"seed\\\":-1,\\\"max_new_tokens\\\":256,\\\"stop\\\":\\\"\\\",\\\"stream\\\":\\\"False\\\",\\\"reset\\\":\\\"True\\\",\\\"batch_size\\\":8,\\\"threads\\\":-1,\\\"context_length\\\":-1,\\\"gpu_layers\\\":0}',\\n            },\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        model: str,\\n        model_file: str,\\n        inputs: str,\\n        model_type: str,\\n        config: Optional[Dict] = None,\\n    ) -> Text:\\n        output = CTransformers(model=model, model_file=model_file, model_type=model_type, config=config)\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"config\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"{\\\"top_k\\\":40,\\\"top_p\\\":0.95,\\\"temperature\\\":0.8,\\\"repetition_penalty\\\":1.1,\\\"last_n_tokens\\\":64,\\\"seed\\\":-1,\\\"max_new_tokens\\\":256,\\\"stop\\\":\\\"\\\",\\\"stream\\\":\\\"False\\\",\\\"reset\\\":\\\"True\\\",\\\"batch_size\\\":8,\\\"threads\\\":-1,\\\"context_length\\\":-1,\\\"gpu_layers\\\":0}\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"config\",\"display_name\":\"Config\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model\",\"display_name\":\"Model\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_type\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_type\",\"display_name\":\"Model Type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using CTransformers LLM models\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"CTransformersModel\",\"documentation\":\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/ctransformers\",\"custom_fields\":{\"model\":null,\"model_file\":null,\"inputs\":null,\"model_type\":null,\"config\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"VertexAiModel\":{\"template\":{\"credentials\":{\"type\":\"file\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".json\"],\"password\":false,\"name\":\"credentials\",\"display_name\":\"Credentials\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"examples\":{\"type\":\"BaseMessage\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":true,\"value\":[],\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"examples\",\"display_name\":\"Examples\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional\\n\\nfrom langchain_core.messages.base import BaseMessage\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass ChatVertexAIComponent(CustomComponent):\\n    display_name = \\\"ChatVertexAIModel\\\"\\n    description = \\\"Generate text using Vertex AI Chat large language models API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"credentials\\\": {\\n                \\\"display_name\\\": \\\"Credentials\\\",\\n                \\\"field_type\\\": \\\"file\\\",\\n                \\\"file_types\\\": [\\\".json\\\"],\\n                \\\"file_path\\\": None,\\n            },\\n            \\\"examples\\\": {\\n                \\\"display_name\\\": \\\"Examples\\\",\\n                \\\"multiline\\\": True,\\n            },\\n            \\\"location\\\": {\\n                \\\"display_name\\\": \\\"Location\\\",\\n                \\\"value\\\": \\\"us-central1\\\",\\n            },\\n            \\\"max_output_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Output Tokens\\\",\\n                \\\"value\\\": 128,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"model_name\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"value\\\": \\\"chat-bison\\\",\\n            },\\n            \\\"project\\\": {\\n                \\\"display_name\\\": \\\"Project\\\",\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"value\\\": 0.0,\\n            },\\n            \\\"top_k\\\": {\\n                \\\"display_name\\\": \\\"Top K\\\",\\n                \\\"value\\\": 40,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top P\\\",\\n                \\\"value\\\": 0.95,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"verbose\\\": {\\n                \\\"display_name\\\": \\\"Verbose\\\",\\n                \\\"value\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        inputs: str,\\n        credentials: Optional[str],\\n        project: str,\\n        examples: Optional[List[BaseMessage]] = [],\\n        location: str = \\\"us-central1\\\",\\n        max_output_tokens: int = 128,\\n        model_name: str = \\\"chat-bison\\\",\\n        temperature: float = 0.0,\\n        top_k: int = 40,\\n        top_p: float = 0.95,\\n        verbose: bool = False,\\n    ) -> Text:\\n        try:\\n            from langchain_google_vertexai import ChatVertexAI\\n        except ImportError:\\n            raise ImportError(\\n                \\\"To use the ChatVertexAI model, you need to install the langchain-google-vertexai package.\\\"\\n            )\\n        output = ChatVertexAI(\\n            credentials=credentials,\\n            examples=examples,\\n            location=location,\\n            max_output_tokens=max_output_tokens,\\n            model_name=model_name,\\n            project=project,\\n            temperature=temperature,\\n            top_k=top_k,\\n            top_p=top_p,\\n            verbose=verbose,\\n        )\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"location\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"us-central1\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"location\",\"display_name\":\"Location\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_output_tokens\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":128,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_output_tokens\",\"display_name\":\"Max Output Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"chat-bison\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_name\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"project\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"project\",\"display_name\":\"Project\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":40,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.95,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"verbose\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"verbose\",\"display_name\":\"Verbose\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using Vertex AI Chat large language models API.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"ChatVertexAIModel\",\"documentation\":\"\",\"custom_fields\":{\"inputs\":null,\"credentials\":null,\"project\":null,\"examples\":null,\"location\":null,\"max_output_tokens\":null,\"model_name\":null,\"temperature\":null,\"top_k\":null,\"top_p\":null,\"verbose\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"OllamaModel\":{\"template\":{\"metadata\":{\"type\":\"Dict[str, Any]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":true,\"dynamic\":false,\"info\":\"Metadata to add to the run trace.\",\"title_case\":false},\"stop\":{\"type\":\"list\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"stop\",\"display_name\":\"Stop Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"List of tokens to signal the model to stop generating text.\",\"title_case\":false},\"tags\":{\"type\":\"list\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"display_name\":\"Tags\",\"advanced\":true,\"dynamic\":false,\"info\":\"Tags to add to the run trace.\",\"title_case\":false},\"base_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"base_url\",\"display_name\":\"Base URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"cache\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"cache\",\"display_name\":\"Cache\",\"advanced\":true,\"dynamic\":false,\"info\":\"Enable or disable caching.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Any, Dict, List, Optional\\n\\n# from langchain_community.chat_models import ChatOllama\\nfrom langchain_community.chat_models import ChatOllama\\n\\n# from langchain.chat_models import ChatOllama\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n# whe When a callback component is added to Langflow, the comment must be uncommented.\\n# from langchain.callbacks.manager import CallbackManager\\n\\n\\nclass ChatOllamaComponent(CustomComponent):\\n    display_name = \\\"ChatOllamaModel\\\"\\n    description = \\\"Generate text using Local LLM for chat with Ollama.\\\"\\n\\n    def build_config(self) -> dict:\\n        return {\\n            \\\"base_url\\\": {\\n                \\\"display_name\\\": \\\"Base URL\\\",\\n                \\\"info\\\": \\\"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\\\",\\n            },\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"value\\\": \\\"llama2\\\",\\n                \\\"info\\\": \\\"Refer to https://ollama.ai/library for more models.\\\",\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"value\\\": 0.8,\\n                \\\"info\\\": \\\"Controls the creativity of model responses.\\\",\\n            },\\n            \\\"cache\\\": {\\n                \\\"display_name\\\": \\\"Cache\\\",\\n                \\\"field_type\\\": \\\"bool\\\",\\n                \\\"info\\\": \\\"Enable or disable caching.\\\",\\n                \\\"advanced\\\": True,\\n                \\\"value\\\": False,\\n            },\\n            ### When a callback component is added to Langflow, the comment must be uncommented. ###\\n            # \\\"callback_manager\\\": {\\n            #     \\\"display_name\\\": \\\"Callback Manager\\\",\\n            #     \\\"info\\\": \\\"Optional callback manager for additional functionality.\\\",\\n            #     \\\"advanced\\\": True,\\n            # },\\n            # \\\"callbacks\\\": {\\n            #     \\\"display_name\\\": \\\"Callbacks\\\",\\n            #     \\\"info\\\": \\\"Callbacks to execute during model runtime.\\\",\\n            #     \\\"advanced\\\": True,\\n            # },\\n            ########################################################################################\\n            \\\"format\\\": {\\n                \\\"display_name\\\": \\\"Format\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"info\\\": \\\"Specify the format of the output (e.g., json).\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"metadata\\\": {\\n                \\\"display_name\\\": \\\"Metadata\\\",\\n                \\\"info\\\": \\\"Metadata to add to the run trace.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"mirostat\\\": {\\n                \\\"display_name\\\": \\\"Mirostat\\\",\\n                \\\"options\\\": [\\\"Disabled\\\", \\\"Mirostat\\\", \\\"Mirostat 2.0\\\"],\\n                \\\"info\\\": \\\"Enable/disable Mirostat sampling for controlling perplexity.\\\",\\n                \\\"value\\\": \\\"Disabled\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"mirostat_eta\\\": {\\n                \\\"display_name\\\": \\\"Mirostat Eta\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Learning rate for Mirostat algorithm. (Default: 0.1)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"mirostat_tau\\\": {\\n                \\\"display_name\\\": \\\"Mirostat Tau\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Controls the balance between coherence and diversity of the output. (Default: 5.0)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"num_ctx\\\": {\\n                \\\"display_name\\\": \\\"Context Window Size\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Size of the context window for generating tokens. (Default: 2048)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"num_gpu\\\": {\\n                \\\"display_name\\\": \\\"Number of GPUs\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"num_thread\\\": {\\n                \\\"display_name\\\": \\\"Number of Threads\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Number of threads to use during computation. (Default: detected for optimal performance)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"repeat_last_n\\\": {\\n                \\\"display_name\\\": \\\"Repeat Last N\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"repeat_penalty\\\": {\\n                \\\"display_name\\\": \\\"Repeat Penalty\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Penalty for repetitions in generated text. (Default: 1.1)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"tfs_z\\\": {\\n                \\\"display_name\\\": \\\"TFS Z\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Tail free sampling value. (Default: 1)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"timeout\\\": {\\n                \\\"display_name\\\": \\\"Timeout\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Timeout for the request stream.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_k\\\": {\\n                \\\"display_name\\\": \\\"Top K\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Limits token selection to top K. (Default: 40)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top P\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Works together with top-k. (Default: 0.9)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"verbose\\\": {\\n                \\\"display_name\\\": \\\"Verbose\\\",\\n                \\\"field_type\\\": \\\"bool\\\",\\n                \\\"info\\\": \\\"Whether to print out response text.\\\",\\n            },\\n            \\\"tags\\\": {\\n                \\\"display_name\\\": \\\"Tags\\\",\\n                \\\"field_type\\\": \\\"list\\\",\\n                \\\"info\\\": \\\"Tags to add to the run trace.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"stop\\\": {\\n                \\\"display_name\\\": \\\"Stop Tokens\\\",\\n                \\\"field_type\\\": \\\"list\\\",\\n                \\\"info\\\": \\\"List of tokens to signal the model to stop generating text.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"system\\\": {\\n                \\\"display_name\\\": \\\"System\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"info\\\": \\\"System to use for generating text.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"template\\\": {\\n                \\\"display_name\\\": \\\"Template\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"info\\\": \\\"Template to use for generating text.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        base_url: Optional[str],\\n        model: str,\\n        inputs: str,\\n        mirostat: Optional[str],\\n        mirostat_eta: Optional[float] = None,\\n        mirostat_tau: Optional[float] = None,\\n        ### When a callback component is added to Langflow, the comment must be uncommented.###\\n        # callback_manager: Optional[CallbackManager] = None,\\n        # callbacks: Optional[List[Callbacks]] = None,\\n        #######################################################################################\\n        repeat_last_n: Optional[int] = None,\\n        verbose: Optional[bool] = None,\\n        cache: Optional[bool] = None,\\n        num_ctx: Optional[int] = None,\\n        num_gpu: Optional[int] = None,\\n        format: Optional[str] = None,\\n        metadata: Optional[Dict[str, Any]] = None,\\n        num_thread: Optional[int] = None,\\n        repeat_penalty: Optional[float] = None,\\n        stop: Optional[List[str]] = None,\\n        system: Optional[str] = None,\\n        tags: Optional[List[str]] = None,\\n        temperature: Optional[float] = None,\\n        template: Optional[str] = None,\\n        tfs_z: Optional[float] = None,\\n        timeout: Optional[int] = None,\\n        top_k: Optional[int] = None,\\n        top_p: Optional[int] = None,\\n    ) -> Text:\\n        if not base_url:\\n            base_url = \\\"http://localhost:11434\\\"\\n\\n        # Mapping mirostat settings to their corresponding values\\n        mirostat_options = {\\\"Mirostat\\\": 1, \\\"Mirostat 2.0\\\": 2}\\n\\n        # Default to 0 for 'Disabled'\\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\\n\\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\\n        if mirostat_value == 0:\\n            mirostat_eta = None\\n            mirostat_tau = None\\n\\n        # Mapping system settings to their corresponding values\\n        llm_params = {\\n            \\\"base_url\\\": base_url,\\n            \\\"cache\\\": cache,\\n            \\\"model\\\": model,\\n            \\\"mirostat\\\": mirostat_value,\\n            \\\"format\\\": format,\\n            \\\"metadata\\\": metadata,\\n            \\\"tags\\\": tags,\\n            ## When a callback component is added to Langflow, the comment must be uncommented.##\\n            # \\\"callback_manager\\\": callback_manager,\\n            # \\\"callbacks\\\": callbacks,\\n            #####################################################################################\\n            \\\"mirostat_eta\\\": mirostat_eta,\\n            \\\"mirostat_tau\\\": mirostat_tau,\\n            \\\"num_ctx\\\": num_ctx,\\n            \\\"num_gpu\\\": num_gpu,\\n            \\\"num_thread\\\": num_thread,\\n            \\\"repeat_last_n\\\": repeat_last_n,\\n            \\\"repeat_penalty\\\": repeat_penalty,\\n            \\\"temperature\\\": temperature,\\n            \\\"stop\\\": stop,\\n            \\\"system\\\": system,\\n            \\\"template\\\": template,\\n            \\\"tfs_z\\\": tfs_z,\\n            \\\"timeout\\\": timeout,\\n            \\\"top_k\\\": top_k,\\n            \\\"top_p\\\": top_p,\\n            \\\"verbose\\\": verbose,\\n        }\\n\\n        # None Value remove\\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\\n\\n        try:\\n            output = ChatOllama(**llm_params)  # type: ignore\\n        except Exception as e:\\n            raise ValueError(\\\"Could not initialize Ollama LLM.\\\") from e\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"format\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"format\",\"display_name\":\"Format\",\"advanced\":true,\"dynamic\":false,\"info\":\"Specify the format of the output (e.g., json).\",\"title_case\":false,\"input_types\":[\"Text\"]},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"mirostat\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"Disabled\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"Disabled\",\"Mirostat\",\"Mirostat 2.0\"],\"name\":\"mirostat\",\"display_name\":\"Mirostat\",\"advanced\":true,\"dynamic\":false,\"info\":\"Enable/disable Mirostat sampling for controlling perplexity.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"mirostat_eta\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"mirostat_eta\",\"display_name\":\"Mirostat Eta\",\"advanced\":true,\"dynamic\":false,\"info\":\"Learning rate for Mirostat algorithm. (Default: 0.1)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"mirostat_tau\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"mirostat_tau\",\"display_name\":\"Mirostat Tau\",\"advanced\":true,\"dynamic\":false,\"info\":\"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"llama2\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"Refer to https://ollama.ai/library for more models.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"num_ctx\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_ctx\",\"display_name\":\"Context Window Size\",\"advanced\":true,\"dynamic\":false,\"info\":\"Size of the context window for generating tokens. (Default: 2048)\",\"title_case\":false},\"num_gpu\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_gpu\",\"display_name\":\"Number of GPUs\",\"advanced\":true,\"dynamic\":false,\"info\":\"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\"title_case\":false},\"num_thread\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_thread\",\"display_name\":\"Number of Threads\",\"advanced\":true,\"dynamic\":false,\"info\":\"Number of threads to use during computation. (Default: detected for optimal performance)\",\"title_case\":false},\"repeat_last_n\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"repeat_last_n\",\"display_name\":\"Repeat Last N\",\"advanced\":true,\"dynamic\":false,\"info\":\"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\"title_case\":false},\"repeat_penalty\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"repeat_penalty\",\"display_name\":\"Repeat Penalty\",\"advanced\":true,\"dynamic\":false,\"info\":\"Penalty for repetitions in generated text. (Default: 1.1)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"system\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"system\",\"display_name\":\"System\",\"advanced\":true,\"dynamic\":false,\"info\":\"System to use for generating text.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"Controls the creativity of model responses.\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"template\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"template\",\"display_name\":\"Template\",\"advanced\":true,\"dynamic\":false,\"info\":\"Template to use for generating text.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"tfs_z\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tfs_z\",\"display_name\":\"TFS Z\",\"advanced\":true,\"dynamic\":false,\"info\":\"Tail free sampling value. (Default: 1)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"timeout\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"timeout\",\"display_name\":\"Timeout\",\"advanced\":true,\"dynamic\":false,\"info\":\"Timeout for the request stream.\",\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"Limits token selection to top K. (Default: 40)\",\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"Works together with top-k. (Default: 0.9)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"verbose\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"verbose\",\"display_name\":\"Verbose\",\"advanced\":false,\"dynamic\":false,\"info\":\"Whether to print out response text.\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using Local LLM for chat with Ollama.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"ChatOllamaModel\",\"documentation\":\"\",\"custom_fields\":{\"base_url\":null,\"model\":null,\"inputs\":null,\"mirostat\":null,\"mirostat_eta\":null,\"mirostat_tau\":null,\"repeat_last_n\":null,\"verbose\":null,\"cache\":null,\"num_ctx\":null,\"num_gpu\":null,\"format\":null,\"metadata\":null,\"num_thread\":null,\"repeat_penalty\":null,\"stop\":null,\"system\":null,\"tags\":null,\"temperature\":null,\"template\":null,\"tfs_z\":null,\"timeout\":null,\"top_k\":null,\"top_p\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"AnthropicModel\":{\"template\":{\"anthropic_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"anthropic_api_key\",\"display_name\":\"Anthropic API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"Your Anthropic API key.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"api_endpoint\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"api_endpoint\",\"display_name\":\"API Endpoint\",\"advanced\":false,\"dynamic\":false,\"info\":\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_community.chat_models.anthropic import ChatAnthropic\\nfrom pydantic.v1 import SecretStr\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass AnthropicLLM(CustomComponent):\\n    display_name: str = \\\"AnthropicModel\\\"\\n    description: str = \\\"Generate text using Anthropic Chat&Completion large language models.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"options\\\": [\\n                    \\\"claude-2.1\\\",\\n                    \\\"claude-2.0\\\",\\n                    \\\"claude-instant-1.2\\\",\\n                    \\\"claude-instant-1\\\",\\n                    # Add more models as needed\\n                ],\\n                \\\"info\\\": \\\"https://python.langchain.com/docs/integrations/chat/anthropic\\\",\\n                \\\"required\\\": True,\\n                \\\"value\\\": \\\"claude-2.1\\\",\\n            },\\n            \\\"anthropic_api_key\\\": {\\n                \\\"display_name\\\": \\\"Anthropic API Key\\\",\\n                \\\"required\\\": True,\\n                \\\"password\\\": True,\\n                \\\"info\\\": \\\"Your Anthropic API key.\\\",\\n            },\\n            \\\"max_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Tokens\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"value\\\": 256,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"value\\\": 0.7,\\n            },\\n            \\\"api_endpoint\\\": {\\n                \\\"display_name\\\": \\\"API Endpoint\\\",\\n                \\\"info\\\": \\\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        model: str,\\n        inputs: str,\\n        anthropic_api_key: Optional[str] = None,\\n        max_tokens: Optional[int] = None,\\n        temperature: Optional[float] = None,\\n        api_endpoint: Optional[str] = None,\\n    ) -> Text:\\n        # Set default API endpoint if not provided\\n        if not api_endpoint:\\n            api_endpoint = \\\"https://api.anthropic.com\\\"\\n\\n        try:\\n            output = ChatAnthropic(\\n                model_name=model,\\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\\n                max_tokens_to_sample=max_tokens,  # type: ignore\\n                temperature=temperature,\\n                anthropic_api_url=api_endpoint,\\n            )\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to Anthropic API.\\\") from e\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":256,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"claude-2.1\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"claude-2.1\",\"claude-2.0\",\"claude-instant-1.2\",\"claude-instant-1\"],\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"https://python.langchain.com/docs/integrations/chat/anthropic\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.7,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using Anthropic Chat&Completion large language models.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"AnthropicModel\",\"documentation\":\"\",\"custom_fields\":{\"model\":null,\"inputs\":null,\"anthropic_api_key\":null,\"max_tokens\":null,\"temperature\":null,\"api_endpoint\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"OpenAIModel\":{\"template\":{\"inputs\":{\"type\":\"Text\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_openai import ChatOpenAI\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import NestedDict, Text\\n\\n\\nclass OpenAIModelComponent(CustomComponent):\\n    display_name = \\\"OpenAI Model\\\"\\n    description = \\\"Generates text using OpenAI's models.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n            \\\"max_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Tokens\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n            },\\n            \\\"model_kwargs\\\": {\\n                \\\"display_name\\\": \\\"Model Kwargs\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n            },\\n            \\\"model_name\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"options\\\": [\\n                    \\\"gpt-4-turbo-preview\\\",\\n                    \\\"gpt-4-0125-preview\\\",\\n                    \\\"gpt-4-1106-preview\\\",\\n                    \\\"gpt-4-vision-preview\\\",\\n                    \\\"gpt-3.5-turbo-0125\\\",\\n                    \\\"gpt-3.5-turbo-1106\\\",\\n                ],\\n            },\\n            \\\"openai_api_base\\\": {\\n                \\\"display_name\\\": \\\"OpenAI API Base\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"info\\\": (\\n                    \\\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\\\n\\\\n\\\"\\n                    \\\"You can change this to use other APIs like JinaChat, LocalAI and Prem.\\\"\\n                ),\\n            },\\n            \\\"openai_api_key\\\": {\\n                \\\"display_name\\\": \\\"OpenAI API Key\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"password\\\": True,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"value\\\": 0.7,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        inputs: Text,\\n        max_tokens: Optional[int] = 256,\\n        model_kwargs: NestedDict = {},\\n        model_name: str = \\\"gpt-4-1106-preview\\\",\\n        openai_api_base: Optional[str] = None,\\n        openai_api_key: Optional[str] = None,\\n        temperature: float = 0.7,\\n    ) -> Text:\\n        if not openai_api_base:\\n            openai_api_base = \\\"https://api.openai.com/v1\\\"\\n        model = ChatOpenAI(\\n            max_tokens=max_tokens,\\n            model_kwargs=model_kwargs,\\n            model=model_name,\\n            base_url=openai_api_base,\\n            api_key=openai_api_key,\\n            temperature=temperature,\\n        )\\n\\n        message = model.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"max_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":256,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_kwargs\":{\"type\":\"NestedDict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"gpt-4-1106-preview\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"gpt-4-turbo-preview\",\"gpt-4-0125-preview\",\"gpt-4-1106-preview\",\"gpt-4-vision-preview\",\"gpt-3.5-turbo-0125\",\"gpt-3.5-turbo-1106\"],\"name\":\"model_name\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_api_base\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"openai_api_base\",\"display_name\":\"OpenAI API Base\",\"advanced\":false,\"dynamic\":false,\"info\":\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_api_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"openai_api_key\",\"display_name\":\"OpenAI API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.7,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generates text using OpenAI's models.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"OpenAI Model\",\"documentation\":\"\",\"custom_fields\":{\"inputs\":null,\"max_tokens\":null,\"model_kwargs\":null,\"model_name\":null,\"openai_api_base\":null,\"openai_api_key\":null,\"temperature\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"HuggingFaceModel\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_community.chat_models.huggingface import ChatHuggingFace\\nfrom langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\\n\\nfrom langflow import CustomComponent\\n\\nfrom langflow.field_typing import Text\\n\\n\\nclass HuggingFaceEndpointsComponent(CustomComponent):\\n    display_name: str = \\\"Hugging Face Inference API models\\\"\\n    description: str = \\\"Generate text using LLM model from Hugging Face Inference API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"endpoint_url\\\": {\\\"display_name\\\": \\\"Endpoint URL\\\", \\\"password\\\": True},\\n            \\\"task\\\": {\\n                \\\"display_name\\\": \\\"Task\\\",\\n                \\\"options\\\": [\\\"text2text-generation\\\", \\\"text-generation\\\", \\\"summarization\\\"],\\n            },\\n            \\\"huggingfacehub_api_token\\\": {\\\"display_name\\\": \\\"API token\\\", \\\"password\\\": True},\\n            \\\"model_kwargs\\\": {\\n                \\\"display_name\\\": \\\"Model Keyword Arguments\\\",\\n                \\\"field_type\\\": \\\"code\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        inputs: str,\\n        endpoint_url: str,\\n        task: str = \\\"text2text-generation\\\",\\n        huggingfacehub_api_token: Optional[str] = None,\\n        model_kwargs: Optional[dict] = None,\\n    ) -> Text:\\n        try:\\n            llm = HuggingFaceEndpoint(\\n                endpoint_url=endpoint_url,\\n                task=task,\\n                huggingfacehub_api_token=huggingfacehub_api_token,\\n                model_kwargs=model_kwargs,\\n            )\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to HuggingFace Endpoints API.\\\") from e\\n        output = ChatHuggingFace(llm=llm)\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"endpoint_url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"endpoint_url\",\"display_name\":\"Endpoint URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"huggingfacehub_api_token\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"huggingfacehub_api_token\",\"display_name\":\"API token\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_kwargs\":{\"type\":\"code\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Keyword Arguments\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"task\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"text2text-generation\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"text2text-generation\",\"text-generation\",\"summarization\"],\"name\":\"task\",\"display_name\":\"Task\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using LLM model from Hugging Face Inference API.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"Hugging Face Inference API models\",\"documentation\":\"\",\"custom_fields\":{\"inputs\":null,\"endpoint_url\":null,\"task\":null,\"huggingfacehub_api_token\":null,\"model_kwargs\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"AzureOpenAIModel\":{\"template\":{\"api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_key\",\"display_name\":\"API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"api_version\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"2023-12-01-preview\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"2023-03-15-preview\",\"2023-05-15\",\"2023-06-01-preview\",\"2023-07-01-preview\",\"2023-08-01-preview\",\"2023-09-01-preview\",\"2023-12-01-preview\"],\"name\":\"api_version\",\"display_name\":\"API Version\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"azure_deployment\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"azure_deployment\",\"display_name\":\"Deployment Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"azure_endpoint\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"azure_endpoint\",\"display_name\":\"Azure Endpoint\",\"advanced\":false,\"dynamic\":false,\"info\":\"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.llms.base import BaseLanguageModel\\nfrom langchain_openai import AzureChatOpenAI\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass AzureChatOpenAIComponent(CustomComponent):\\n    display_name: str = \\\"AzureOpenAI Model\\\"\\n    description: str = \\\"Generate text using LLM model from Azure OpenAI.\\\"\\n    documentation: str = \\\"https://python.langchain.com/docs/integrations/llms/azure_openai\\\"\\n    beta = False\\n\\n    AZURE_OPENAI_MODELS = [\\n        \\\"gpt-35-turbo\\\",\\n        \\\"gpt-35-turbo-16k\\\",\\n        \\\"gpt-35-turbo-instruct\\\",\\n        \\\"gpt-4\\\",\\n        \\\"gpt-4-32k\\\",\\n        \\\"gpt-4-vision\\\",\\n    ]\\n\\n    AZURE_OPENAI_API_VERSIONS = [\\n        \\\"2023-03-15-preview\\\",\\n        \\\"2023-05-15\\\",\\n        \\\"2023-06-01-preview\\\",\\n        \\\"2023-07-01-preview\\\",\\n        \\\"2023-08-01-preview\\\",\\n        \\\"2023-09-01-preview\\\",\\n        \\\"2023-12-01-preview\\\",\\n    ]\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"value\\\": self.AZURE_OPENAI_MODELS[0],\\n                \\\"options\\\": self.AZURE_OPENAI_MODELS,\\n                \\\"required\\\": True,\\n            },\\n            \\\"azure_endpoint\\\": {\\n                \\\"display_name\\\": \\\"Azure Endpoint\\\",\\n                \\\"required\\\": True,\\n                \\\"info\\\": \\\"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\\\",\\n            },\\n            \\\"azure_deployment\\\": {\\n                \\\"display_name\\\": \\\"Deployment Name\\\",\\n                \\\"required\\\": True,\\n            },\\n            \\\"api_version\\\": {\\n                \\\"display_name\\\": \\\"API Version\\\",\\n                \\\"options\\\": self.AZURE_OPENAI_API_VERSIONS,\\n                \\\"value\\\": self.AZURE_OPENAI_API_VERSIONS[-1],\\n                \\\"required\\\": True,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"api_key\\\": {\\\"display_name\\\": \\\"API Key\\\", \\\"required\\\": True, \\\"password\\\": True},\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"value\\\": 0.7,\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"required\\\": False,\\n            },\\n            \\\"max_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Tokens\\\",\\n                \\\"value\\\": 1000,\\n                \\\"required\\\": False,\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"advanced\\\": True,\\n                \\\"info\\\": \\\"Maximum number of tokens to generate.\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        model: str,\\n        azure_endpoint: str,\\n        inputs: str,\\n        azure_deployment: str,\\n        api_key: str,\\n        api_version: str,\\n        temperature: float = 0.7,\\n        max_tokens: Optional[int] = 1000,\\n    ) -> BaseLanguageModel:\\n        try:\\n            output = AzureChatOpenAI(\\n                model=model,\\n                azure_endpoint=azure_endpoint,\\n                azure_deployment=azure_deployment,\\n                api_version=api_version,\\n                api_key=api_key,\\n                temperature=temperature,\\n                max_tokens=max_tokens,\\n            )\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to AzureOpenAI API.\\\") from e\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1000,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"Maximum number of tokens to generate.\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"gpt-35-turbo\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"gpt-35-turbo\",\"gpt-35-turbo-16k\",\"gpt-35-turbo-instruct\",\"gpt-4\",\"gpt-4-32k\",\"gpt-4-vision\"],\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.7,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using LLM model from Azure OpenAI.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\"],\"display_name\":\"AzureOpenAI Model\",\"documentation\":\"https://python.langchain.com/docs/integrations/llms/azure_openai\",\"custom_fields\":{\"model\":null,\"azure_endpoint\":null,\"inputs\":null,\"azure_deployment\":null,\"api_key\":null,\"api_version\":null,\"temperature\":null,\"max_tokens\":null},\"output_types\":[\"BaseLanguageModel\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"AmazonBedrockModel\":{\"template\":{\"cache\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"cache\",\"display_name\":\"Cache\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_community.chat_models.bedrock import BedrockChat\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass AmazonBedrockComponent(CustomComponent):\\n    display_name: str = \\\"Amazon Bedrock Model\\\"\\n    description: str = \\\"Generate text using LLM model from Amazon Bedrock.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"model_id\\\": {\\n                \\\"display_name\\\": \\\"Model Id\\\",\\n                \\\"options\\\": [\\n                    \\\"ai21.j2-grande-instruct\\\",\\n                    \\\"ai21.j2-jumbo-instruct\\\",\\n                    \\\"ai21.j2-mid\\\",\\n                    \\\"ai21.j2-mid-v1\\\",\\n                    \\\"ai21.j2-ultra\\\",\\n                    \\\"ai21.j2-ultra-v1\\\",\\n                    \\\"anthropic.claude-instant-v1\\\",\\n                    \\\"anthropic.claude-v1\\\",\\n                    \\\"anthropic.claude-v2\\\",\\n                    \\\"cohere.command-text-v14\\\",\\n                ],\\n            },\\n            \\\"credentials_profile_name\\\": {\\\"display_name\\\": \\\"Credentials Profile Name\\\"},\\n            \\\"streaming\\\": {\\\"display_name\\\": \\\"Streaming\\\", \\\"field_type\\\": \\\"bool\\\"},\\n            \\\"endpoint_url\\\": {\\\"display_name\\\": \\\"Endpoint URL\\\"},\\n            \\\"region_name\\\": {\\\"display_name\\\": \\\"Region Name\\\"},\\n            \\\"model_kwargs\\\": {\\\"display_name\\\": \\\"Model Kwargs\\\"},\\n            \\\"cache\\\": {\\\"display_name\\\": \\\"Cache\\\"},\\n            \\\"code\\\": {\\\"advanced\\\": True},\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        inputs: str,\\n        model_id: str = \\\"anthropic.claude-instant-v1\\\",\\n        credentials_profile_name: Optional[str] = None,\\n        region_name: Optional[str] = None,\\n        model_kwargs: Optional[dict] = None,\\n        endpoint_url: Optional[str] = None,\\n        streaming: bool = False,\\n        cache: Optional[bool] = None,\\n    ) -> Text:\\n        try:\\n            output = BedrockChat(\\n                credentials_profile_name=credentials_profile_name,\\n                model_id=model_id,\\n                region_name=region_name,\\n                model_kwargs=model_kwargs,\\n                endpoint_url=endpoint_url,\\n                streaming=streaming,\\n                cache=cache,\\n            )  # type: ignore\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to AmazonBedrock API.\\\") from e\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":true,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"credentials_profile_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"credentials_profile_name\",\"display_name\":\"Credentials Profile Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"endpoint_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"endpoint_url\",\"display_name\":\"Endpoint URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"anthropic.claude-instant-v1\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"ai21.j2-grande-instruct\",\"ai21.j2-jumbo-instruct\",\"ai21.j2-mid\",\"ai21.j2-mid-v1\",\"ai21.j2-ultra\",\"ai21.j2-ultra-v1\",\"anthropic.claude-instant-v1\",\"anthropic.claude-v1\",\"anthropic.claude-v2\",\"cohere.command-text-v14\"],\"name\":\"model_id\",\"display_name\":\"Model Id\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_kwargs\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"region_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"region_name\",\"display_name\":\"Region Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"streaming\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"streaming\",\"display_name\":\"Streaming\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using LLM model from Amazon Bedrock.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"Amazon Bedrock Model\",\"documentation\":\"\",\"custom_fields\":{\"inputs\":null,\"model_id\":null,\"credentials_profile_name\":null,\"region_name\":null,\"model_kwargs\":null,\"endpoint_url\":null,\"streaming\":null,\"cache\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"CohereModel\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langchain_community.chat_models.cohere import ChatCohere\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass CohereComponent(CustomComponent):\\n    display_name = \\\"CohereModel\\\"\\n    description = \\\"Generate text using Cohere large language models.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"cohere_api_key\\\": {\\n                \\\"display_name\\\": \\\"Cohere API Key\\\",\\n                \\\"type\\\": \\\"password\\\",\\n                \\\"password\\\": True,\\n            },\\n            \\\"max_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Tokens\\\",\\n                \\\"default\\\": 256,\\n                \\\"type\\\": \\\"int\\\",\\n                \\\"show\\\": True,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"default\\\": 0.75,\\n                \\\"type\\\": \\\"float\\\",\\n                \\\"show\\\": True,\\n            },\\n            \\\"inputs\\\": {\\\"display_name\\\": \\\"Input\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        cohere_api_key: str,\\n        inputs: str,\\n        max_tokens: int = 256,\\n        temperature: float = 0.75,\\n    ) -> Text:\\n        output = ChatCohere(\\n            cohere_api_key=cohere_api_key,\\n            max_tokens=max_tokens,\\n            temperature=temperature,\\n        )\\n        message = output.invoke(inputs)\\n        result = message.content if hasattr(message, \\\"content\\\") else message\\n        self.status = result\\n        return result\\n        return result\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"cohere_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"cohere_api_key\",\"display_name\":\"Cohere API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"inputs\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"inputs\",\"display_name\":\"Input\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_tokens\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":256,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"temperature\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.75,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Generate text using Cohere large language models.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"CohereModel\",\"documentation\":\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere\",\"custom_fields\":{\"cohere_api_key\":null,\"inputs\":null,\"max_tokens\":null,\"temperature\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"model_specs\":{\"AmazonBedrockSpecs\":{\"template\":{\"cache\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"cache\",\"display_name\":\"Cache\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.llms.base import BaseLLM\\nfrom langchain_community.llms.bedrock import Bedrock\\n\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass AmazonBedrockComponent(CustomComponent):\\n    display_name: str = \\\"Amazon Bedrock\\\"\\n    description: str = \\\"LLM model from Amazon Bedrock.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"model_id\\\": {\\n                \\\"display_name\\\": \\\"Model Id\\\",\\n                \\\"options\\\": [\\n                    \\\"ai21.j2-grande-instruct\\\",\\n                    \\\"ai21.j2-jumbo-instruct\\\",\\n                    \\\"ai21.j2-mid\\\",\\n                    \\\"ai21.j2-mid-v1\\\",\\n                    \\\"ai21.j2-ultra\\\",\\n                    \\\"ai21.j2-ultra-v1\\\",\\n                    \\\"anthropic.claude-instant-v1\\\",\\n                    \\\"anthropic.claude-v1\\\",\\n                    \\\"anthropic.claude-v2\\\",\\n                    \\\"cohere.command-text-v14\\\",\\n                ],\\n            },\\n            \\\"credentials_profile_name\\\": {\\\"display_name\\\": \\\"Credentials Profile Name\\\"},\\n            \\\"streaming\\\": {\\\"display_name\\\": \\\"Streaming\\\", \\\"field_type\\\": \\\"bool\\\"},\\n            \\\"endpoint_url\\\": {\\\"display_name\\\": \\\"Endpoint URL\\\"},\\n            \\\"region_name\\\": {\\\"display_name\\\": \\\"Region Name\\\"},\\n            \\\"model_kwargs\\\": {\\\"display_name\\\": \\\"Model Kwargs\\\"},\\n            \\\"cache\\\": {\\\"display_name\\\": \\\"Cache\\\"},\\n            \\\"code\\\": {\\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        model_id: str = \\\"anthropic.claude-instant-v1\\\",\\n        credentials_profile_name: Optional[str] = None,\\n        region_name: Optional[str] = None,\\n        model_kwargs: Optional[dict] = None,\\n        endpoint_url: Optional[str] = None,\\n        streaming: bool = False,\\n        cache: Optional[bool] = None,\\n    ) -> BaseLLM:\\n        try:\\n            output = Bedrock(\\n                credentials_profile_name=credentials_profile_name,\\n                model_id=model_id,\\n                region_name=region_name,\\n                model_kwargs=model_kwargs,\\n                endpoint_url=endpoint_url,\\n                streaming=streaming,\\n                cache=cache,\\n            )  # type: ignore\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to AmazonBedrock API.\\\") from e\\n        return output\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":true,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"credentials_profile_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"credentials_profile_name\",\"display_name\":\"Credentials Profile Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"endpoint_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"endpoint_url\",\"display_name\":\"Endpoint URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_id\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"anthropic.claude-instant-v1\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"ai21.j2-grande-instruct\",\"ai21.j2-jumbo-instruct\",\"ai21.j2-mid\",\"ai21.j2-mid-v1\",\"ai21.j2-ultra\",\"ai21.j2-ultra-v1\",\"anthropic.claude-instant-v1\",\"anthropic.claude-v1\",\"anthropic.claude-v2\",\"cohere.command-text-v14\"],\"name\":\"model_id\",\"display_name\":\"Model Id\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_kwargs\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"region_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"region_name\",\"display_name\":\"Region Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"streaming\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"streaming\",\"display_name\":\"Streaming\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"LLM model from Amazon Bedrock.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\"],\"display_name\":\"Amazon Bedrock\",\"documentation\":\"\",\"custom_fields\":{\"model_id\":null,\"credentials_profile_name\":null,\"region_name\":null,\"model_kwargs\":null,\"endpoint_url\":null,\"streaming\":null,\"cache\":null},\"output_types\":[\"BaseLLM\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"ChatVertexAISpecs\":{\"template\":{\"credentials\":{\"type\":\"file\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".json\"],\"password\":false,\"name\":\"credentials\",\"display_name\":\"Credentials\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"examples\":{\"type\":\"BaseMessage\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":true,\"value\":[],\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"examples\",\"display_name\":\"Examples\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional, Union\\n\\nfrom langchain.llms import BaseLLM\\nfrom langchain_community.chat_models.vertexai import ChatVertexAI\\nfrom langchain_core.messages.base import BaseMessage\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel\\n\\n\\nclass ChatVertexAIComponent(CustomComponent):\\n    display_name = \\\"ChatVertexAI\\\"\\n    description = \\\"`Vertex AI` Chat large language models API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"credentials\\\": {\\n                \\\"display_name\\\": \\\"Credentials\\\",\\n                \\\"field_type\\\": \\\"file\\\",\\n                \\\"file_types\\\": [\\\".json\\\"],\\n                \\\"file_path\\\": None,\\n            },\\n            \\\"examples\\\": {\\n                \\\"display_name\\\": \\\"Examples\\\",\\n                \\\"multiline\\\": True,\\n            },\\n            \\\"location\\\": {\\n                \\\"display_name\\\": \\\"Location\\\",\\n                \\\"value\\\": \\\"us-central1\\\",\\n            },\\n            \\\"max_output_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Output Tokens\\\",\\n                \\\"value\\\": 128,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"model_name\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"value\\\": \\\"chat-bison\\\",\\n            },\\n            \\\"project\\\": {\\n                \\\"display_name\\\": \\\"Project\\\",\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"value\\\": 0.0,\\n            },\\n            \\\"top_k\\\": {\\n                \\\"display_name\\\": \\\"Top K\\\",\\n                \\\"value\\\": 40,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top P\\\",\\n                \\\"value\\\": 0.95,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"verbose\\\": {\\n                \\\"display_name\\\": \\\"Verbose\\\",\\n                \\\"value\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        credentials: Optional[str],\\n        project: str,\\n        examples: Optional[List[BaseMessage]] = [],\\n        location: str = \\\"us-central1\\\",\\n        max_output_tokens: int = 128,\\n        model_name: str = \\\"chat-bison\\\",\\n        temperature: float = 0.0,\\n        top_k: int = 40,\\n        top_p: float = 0.95,\\n        verbose: bool = False,\\n    ) -> Union[BaseLanguageModel, BaseLLM]:\\n        return ChatVertexAI(\\n            credentials=credentials,\\n            examples=examples,\\n            location=location,\\n            max_output_tokens=max_output_tokens,\\n            model_name=model_name,\\n            project=project,\\n            temperature=temperature,\\n            top_k=top_k,\\n            top_p=top_p,\\n            verbose=verbose,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"location\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"us-central1\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"location\",\"display_name\":\"Location\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_output_tokens\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":128,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_output_tokens\",\"display_name\":\"Max Output Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_name\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"chat-bison\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_name\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"project\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"project\",\"display_name\":\"Project\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":40,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.95,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"verbose\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"verbose\",\"display_name\":\"Verbose\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"`Vertex AI` Chat large language models API.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\"],\"display_name\":\"ChatVertexAI\",\"documentation\":\"\",\"custom_fields\":{\"credentials\":null,\"project\":null,\"examples\":null,\"location\":null,\"max_output_tokens\":null,\"model_name\":null,\"temperature\":null,\"top_k\":null,\"top_p\":null,\"verbose\":null},\"output_types\":[\"BaseLanguageModel\",\"BaseLLM\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"VertexAISpecs\":{\"template\":{\"credentials\":{\"type\":\"file\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".json\"],\"file_path\":\"\",\"password\":false,\"name\":\"credentials\",\"display_name\":\"Credentials\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langflow import CustomComponent\\nfrom langchain.llms import BaseLLM\\nfrom typing import Optional, Union, Callable, Dict\\nfrom langchain_community.llms.vertexai import VertexAI\\n\\n\\nclass VertexAIComponent(CustomComponent):\\n    display_name = \\\"VertexAI\\\"\\n    description = \\\"Google Vertex AI large language models\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"credentials\\\": {\\n                \\\"display_name\\\": \\\"Credentials\\\",\\n                \\\"field_type\\\": \\\"file\\\",\\n                \\\"file_types\\\": [\\\".json\\\"],\\n                \\\"required\\\": False,\\n                \\\"value\\\": None,\\n            },\\n            \\\"location\\\": {\\n                \\\"display_name\\\": \\\"Location\\\",\\n                \\\"type\\\": \\\"str\\\",\\n                \\\"advanced\\\": True,\\n                \\\"value\\\": \\\"us-central1\\\",\\n                \\\"required\\\": False,\\n            },\\n            \\\"max_output_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Output Tokens\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"value\\\": 128,\\n                \\\"required\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"max_retries\\\": {\\n                \\\"display_name\\\": \\\"Max Retries\\\",\\n                \\\"type\\\": \\\"int\\\",\\n                \\\"value\\\": 6,\\n                \\\"required\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"metadata\\\": {\\n                \\\"display_name\\\": \\\"Metadata\\\",\\n                \\\"field_type\\\": \\\"dict\\\",\\n                \\\"required\\\": False,\\n                \\\"default\\\": {},\\n            },\\n            \\\"model_name\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"type\\\": \\\"str\\\",\\n                \\\"value\\\": \\\"text-bison\\\",\\n                \\\"required\\\": False,\\n            },\\n            \\\"n\\\": {\\n                \\\"advanced\\\": True,\\n                \\\"display_name\\\": \\\"N\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"value\\\": 1,\\n                \\\"required\\\": False,\\n            },\\n            \\\"project\\\": {\\n                \\\"display_name\\\": \\\"Project\\\",\\n                \\\"type\\\": \\\"str\\\",\\n                \\\"required\\\": False,\\n                \\\"default\\\": None,\\n            },\\n            \\\"request_parallelism\\\": {\\n                \\\"display_name\\\": \\\"Request Parallelism\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"value\\\": 5,\\n                \\\"required\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"streaming\\\": {\\n                \\\"display_name\\\": \\\"Streaming\\\",\\n                \\\"field_type\\\": \\\"bool\\\",\\n                \\\"value\\\": False,\\n                \\\"required\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"value\\\": 0.0,\\n                \\\"required\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_k\\\": {\\\"display_name\\\": \\\"Top K\\\", \\\"type\\\": \\\"int\\\", \\\"default\\\": 40, \\\"required\\\": False, \\\"advanced\\\": True},\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top P\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"value\\\": 0.95,\\n                \\\"required\\\": False,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"tuned_model_name\\\": {\\n                \\\"display_name\\\": \\\"Tuned Model Name\\\",\\n                \\\"type\\\": \\\"str\\\",\\n                \\\"required\\\": False,\\n                \\\"value\\\": None,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"verbose\\\": {\\n                \\\"display_name\\\": \\\"Verbose\\\",\\n                \\\"field_type\\\": \\\"bool\\\",\\n                \\\"value\\\": False,\\n                \\\"required\\\": False,\\n            },\\n            \\\"name\\\": {\\\"display_name\\\": \\\"Name\\\", \\\"field_type\\\": \\\"str\\\"},\\n        }\\n\\n    def build(\\n        self,\\n        credentials: Optional[str] = None,\\n        location: str = \\\"us-central1\\\",\\n        max_output_tokens: int = 128,\\n        max_retries: int = 6,\\n        metadata: Dict = {},\\n        model_name: str = \\\"text-bison\\\",\\n        n: int = 1,\\n        name: Optional[str] = None,\\n        project: Optional[str] = None,\\n        request_parallelism: int = 5,\\n        streaming: bool = False,\\n        temperature: float = 0.0,\\n        top_k: int = 40,\\n        top_p: float = 0.95,\\n        tuned_model_name: Optional[str] = None,\\n        verbose: bool = False,\\n    ) -> Union[BaseLLM, Callable]:\\n        return VertexAI(\\n            credentials=credentials,\\n            location=location,\\n            max_output_tokens=max_output_tokens,\\n            max_retries=max_retries,\\n            metadata=metadata,\\n            model_name=model_name,\\n            n=n,\\n            name=name,\\n            project=project,\\n            request_parallelism=request_parallelism,\\n            streaming=streaming,\\n            temperature=temperature,\\n            top_k=top_k,\\n            top_p=top_p,\\n            tuned_model_name=tuned_model_name,\\n            verbose=verbose,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"location\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"us-central1\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"location\",\"display_name\":\"Location\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_output_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":128,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_output_tokens\",\"display_name\":\"Max Output Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"max_retries\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":6,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_retries\",\"display_name\":\"Max Retries\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"metadata\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"text-bison\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_name\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"n\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n\",\"display_name\":\"N\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"name\",\"display_name\":\"Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"project\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"project\",\"display_name\":\"Project\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"request_parallelism\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":5,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"request_parallelism\",\"display_name\":\"Request Parallelism\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"streaming\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"streaming\",\"display_name\":\"Streaming\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":40,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.95,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"tuned_model_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tuned_model_name\",\"display_name\":\"Tuned Model Name\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"verbose\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"verbose\",\"display_name\":\"Verbose\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Google Vertex AI large language models\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\",\"Callable\"],\"display_name\":\"VertexAI\",\"documentation\":\"\",\"custom_fields\":{\"credentials\":null,\"location\":null,\"max_output_tokens\":null,\"max_retries\":null,\"metadata\":null,\"model_name\":null,\"n\":null,\"name\":null,\"project\":null,\"request_parallelism\":null,\"streaming\":null,\"temperature\":null,\"top_k\":null,\"top_p\":null,\"tuned_model_name\":null,\"verbose\":null},\"output_types\":[\"BaseLLM\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"ChatAnthropicSpecs\":{\"template\":{\"anthropic_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"anthropic_api_key\",\"display_name\":\"Anthropic API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"anthropic_api_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"anthropic_api_url\",\"display_name\":\"Anthropic API URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from pydantic.v1.types import SecretStr\\nfrom langflow import CustomComponent\\nfrom typing import Optional, Union, Callable\\nfrom langflow.field_typing import BaseLanguageModel\\nfrom langchain_community.chat_models.anthropic import ChatAnthropic\\n\\n\\nclass ChatAnthropicComponent(CustomComponent):\\n    display_name = \\\"ChatAnthropic\\\"\\n    description = \\\"`Anthropic` chat large language models.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/model_io/models/chat/integrations/anthropic\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"anthropic_api_key\\\": {\\n                \\\"display_name\\\": \\\"Anthropic API Key\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"password\\\": True,\\n            },\\n            \\\"anthropic_api_url\\\": {\\n                \\\"display_name\\\": \\\"Anthropic API URL\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n            },\\n            \\\"model_kwargs\\\": {\\n                \\\"display_name\\\": \\\"Model Kwargs\\\",\\n                \\\"field_type\\\": \\\"dict\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        anthropic_api_key: str,\\n        anthropic_api_url: Optional[str] = None,\\n        model_kwargs: dict = {},\\n        temperature: Optional[float] = None,\\n    ) -> Union[BaseLanguageModel, Callable]:\\n        return ChatAnthropic(\\n            anthropic_api_key=SecretStr(anthropic_api_key),\\n            anthropic_api_url=anthropic_api_url,\\n            model_kwargs=model_kwargs,\\n            temperature=temperature,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"model_kwargs\":{\"type\":\"dict\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"`Anthropic` chat large language models.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"Callable\"],\"display_name\":\"ChatAnthropic\",\"documentation\":\"https://python.langchain.com/docs/modules/model_io/models/chat/integrations/anthropic\",\"custom_fields\":{\"anthropic_api_key\":null,\"anthropic_api_url\":null,\"model_kwargs\":null,\"temperature\":null},\"output_types\":[\"BaseLanguageModel\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"AzureChatOpenAISpecs\":{\"template\":{\"api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_key\",\"display_name\":\"API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"api_version\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"2023-12-01-preview\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"2023-03-15-preview\",\"2023-05-15\",\"2023-06-01-preview\",\"2023-07-01-preview\",\"2023-08-01-preview\",\"2023-09-01-preview\",\"2023-12-01-preview\"],\"name\":\"api_version\",\"display_name\":\"API Version\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"azure_deployment\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"azure_deployment\",\"display_name\":\"Deployment Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"azure_endpoint\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"azure_endpoint\",\"display_name\":\"Azure Endpoint\",\"advanced\":false,\"dynamic\":false,\"info\":\"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.llms.base import BaseLanguageModel\\nfrom langchain_community.chat_models.azure_openai import AzureChatOpenAI\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass AzureChatOpenAISpecsComponent(CustomComponent):\\n    display_name: str = \\\"AzureChatOpenAI\\\"\\n    description: str = \\\"LLM model from Azure OpenAI.\\\"\\n    documentation: str = \\\"https://python.langchain.com/docs/integrations/llms/azure_openai\\\"\\n    beta = False\\n\\n    AZURE_OPENAI_MODELS = [\\n        \\\"gpt-35-turbo\\\",\\n        \\\"gpt-35-turbo-16k\\\",\\n        \\\"gpt-35-turbo-instruct\\\",\\n        \\\"gpt-4\\\",\\n        \\\"gpt-4-32k\\\",\\n        \\\"gpt-4-vision\\\",\\n    ]\\n\\n    AZURE_OPENAI_API_VERSIONS = [\\n        \\\"2023-03-15-preview\\\",\\n        \\\"2023-05-15\\\",\\n        \\\"2023-06-01-preview\\\",\\n        \\\"2023-07-01-preview\\\",\\n        \\\"2023-08-01-preview\\\",\\n        \\\"2023-09-01-preview\\\",\\n        \\\"2023-12-01-preview\\\",\\n    ]\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"value\\\": self.AZURE_OPENAI_MODELS[0],\\n                \\\"options\\\": self.AZURE_OPENAI_MODELS,\\n                \\\"required\\\": True,\\n            },\\n            \\\"azure_endpoint\\\": {\\n                \\\"display_name\\\": \\\"Azure Endpoint\\\",\\n                \\\"required\\\": True,\\n                \\\"info\\\": \\\"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\\\",\\n            },\\n            \\\"azure_deployment\\\": {\\n                \\\"display_name\\\": \\\"Deployment Name\\\",\\n                \\\"required\\\": True,\\n            },\\n            \\\"api_version\\\": {\\n                \\\"display_name\\\": \\\"API Version\\\",\\n                \\\"options\\\": self.AZURE_OPENAI_API_VERSIONS,\\n                \\\"value\\\": self.AZURE_OPENAI_API_VERSIONS[-1],\\n                \\\"required\\\": True,\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"api_key\\\": {\\\"display_name\\\": \\\"API Key\\\", \\\"required\\\": True, \\\"password\\\": True},\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"value\\\": 0.7,\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"required\\\": False,\\n            },\\n            \\\"max_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Tokens\\\",\\n                \\\"value\\\": 1000,\\n                \\\"required\\\": False,\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"advanced\\\": True,\\n                \\\"info\\\": \\\"Maximum number of tokens to generate.\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        model: str,\\n        azure_endpoint: str,\\n        azure_deployment: str,\\n        api_key: str,\\n        api_version: str,\\n        temperature: float = 0.7,\\n        max_tokens: Optional[int] = 1000,\\n    ) -> BaseLanguageModel:\\n        try:\\n            llm = AzureChatOpenAI(\\n                model=model,\\n                azure_endpoint=azure_endpoint,\\n                azure_deployment=azure_deployment,\\n                api_version=api_version,\\n                api_key=api_key,\\n                temperature=temperature,\\n                max_tokens=max_tokens,\\n            )\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to AzureOpenAI API.\\\") from e\\n        return llm\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"max_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1000,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"Maximum number of tokens to generate.\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"gpt-35-turbo\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"gpt-35-turbo\",\"gpt-35-turbo-16k\",\"gpt-35-turbo-instruct\",\"gpt-4\",\"gpt-4-32k\",\"gpt-4-vision\"],\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.7,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"LLM model from Azure OpenAI.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\"],\"display_name\":\"AzureChatOpenAI\",\"documentation\":\"https://python.langchain.com/docs/integrations/llms/azure_openai\",\"custom_fields\":{\"model\":null,\"azure_endpoint\":null,\"azure_deployment\":null,\"api_key\":null,\"api_version\":null,\"temperature\":null,\"max_tokens\":null},\"output_types\":[\"BaseLanguageModel\"],\"field_formatters\":{},\"pinned\":false,\"beta\":false},\"ChatOllamaEndpointSpecs\":{\"template\":{\"metadata\":{\"type\":\"Dict[str, Any]\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":true,\"dynamic\":false,\"info\":\"Metadata to add to the run trace.\",\"title_case\":false},\"stop\":{\"type\":\"list\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"stop\",\"display_name\":\"Stop Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"List of tokens to signal the model to stop generating text.\",\"title_case\":false},\"tags\":{\"type\":\"list\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"display_name\":\"Tags\",\"advanced\":true,\"dynamic\":false,\"info\":\"Tags to add to the run trace.\",\"title_case\":false},\"base_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"base_url\",\"display_name\":\"Base URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"cache\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"cache\",\"display_name\":\"Cache\",\"advanced\":true,\"dynamic\":false,\"info\":\"Enable or disable caching.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Any, Dict, List, Optional\\n\\n# from langchain_community.chat_models import ChatOllama\\nfrom langchain_community.chat_models import ChatOllama\\nfrom langchain_core.language_models.chat_models import BaseChatModel\\n\\n# from langchain.chat_models import ChatOllama\\nfrom langflow import CustomComponent\\n\\n# whe When a callback component is added to Langflow, the comment must be uncommented.\\n# from langchain.callbacks.manager import CallbackManager\\n\\n\\nclass ChatOllamaComponent(CustomComponent):\\n    display_name = \\\"ChatOllama\\\"\\n    description = \\\"Local LLM for chat with Ollama.\\\"\\n\\n    def build_config(self) -> dict:\\n        return {\\n            \\\"base_url\\\": {\\n                \\\"display_name\\\": \\\"Base URL\\\",\\n                \\\"info\\\": \\\"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\\\",\\n            },\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"value\\\": \\\"llama2\\\",\\n                \\\"info\\\": \\\"Refer to https://ollama.ai/library for more models.\\\",\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"value\\\": 0.8,\\n                \\\"info\\\": \\\"Controls the creativity of model responses.\\\",\\n            },\\n            \\\"cache\\\": {\\n                \\\"display_name\\\": \\\"Cache\\\",\\n                \\\"field_type\\\": \\\"bool\\\",\\n                \\\"info\\\": \\\"Enable or disable caching.\\\",\\n                \\\"advanced\\\": True,\\n                \\\"value\\\": False,\\n            },\\n            ### When a callback component is added to Langflow, the comment must be uncommented. ###\\n            # \\\"callback_manager\\\": {\\n            #     \\\"display_name\\\": \\\"Callback Manager\\\",\\n            #     \\\"info\\\": \\\"Optional callback manager for additional functionality.\\\",\\n            #     \\\"advanced\\\": True,\\n            # },\\n            # \\\"callbacks\\\": {\\n            #     \\\"display_name\\\": \\\"Callbacks\\\",\\n            #     \\\"info\\\": \\\"Callbacks to execute during model runtime.\\\",\\n            #     \\\"advanced\\\": True,\\n            # },\\n            ########################################################################################\\n            \\\"format\\\": {\\n                \\\"display_name\\\": \\\"Format\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"info\\\": \\\"Specify the format of the output (e.g., json).\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"metadata\\\": {\\n                \\\"display_name\\\": \\\"Metadata\\\",\\n                \\\"info\\\": \\\"Metadata to add to the run trace.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"mirostat\\\": {\\n                \\\"display_name\\\": \\\"Mirostat\\\",\\n                \\\"options\\\": [\\\"Disabled\\\", \\\"Mirostat\\\", \\\"Mirostat 2.0\\\"],\\n                \\\"info\\\": \\\"Enable/disable Mirostat sampling for controlling perplexity.\\\",\\n                \\\"value\\\": \\\"Disabled\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"mirostat_eta\\\": {\\n                \\\"display_name\\\": \\\"Mirostat Eta\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Learning rate for Mirostat algorithm. (Default: 0.1)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"mirostat_tau\\\": {\\n                \\\"display_name\\\": \\\"Mirostat Tau\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Controls the balance between coherence and diversity of the output. (Default: 5.0)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"num_ctx\\\": {\\n                \\\"display_name\\\": \\\"Context Window Size\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Size of the context window for generating tokens. (Default: 2048)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"num_gpu\\\": {\\n                \\\"display_name\\\": \\\"Number of GPUs\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"num_thread\\\": {\\n                \\\"display_name\\\": \\\"Number of Threads\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Number of threads to use during computation. (Default: detected for optimal performance)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"repeat_last_n\\\": {\\n                \\\"display_name\\\": \\\"Repeat Last N\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"repeat_penalty\\\": {\\n                \\\"display_name\\\": \\\"Repeat Penalty\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Penalty for repetitions in generated text. (Default: 1.1)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"tfs_z\\\": {\\n                \\\"display_name\\\": \\\"TFS Z\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Tail free sampling value. (Default: 1)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"timeout\\\": {\\n                \\\"display_name\\\": \\\"Timeout\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Timeout for the request stream.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_k\\\": {\\n                \\\"display_name\\\": \\\"Top K\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Limits token selection to top K. (Default: 40)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top P\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Works together with top-k. (Default: 0.9)\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"verbose\\\": {\\n                \\\"display_name\\\": \\\"Verbose\\\",\\n                \\\"field_type\\\": \\\"bool\\\",\\n                \\\"info\\\": \\\"Whether to print out response text.\\\",\\n            },\\n            \\\"tags\\\": {\\n                \\\"display_name\\\": \\\"Tags\\\",\\n                \\\"field_type\\\": \\\"list\\\",\\n                \\\"info\\\": \\\"Tags to add to the run trace.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"stop\\\": {\\n                \\\"display_name\\\": \\\"Stop Tokens\\\",\\n                \\\"field_type\\\": \\\"list\\\",\\n                \\\"info\\\": \\\"List of tokens to signal the model to stop generating text.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"system\\\": {\\n                \\\"display_name\\\": \\\"System\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"info\\\": \\\"System to use for generating text.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"template\\\": {\\n                \\\"display_name\\\": \\\"Template\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"info\\\": \\\"Template to use for generating text.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        base_url: Optional[str],\\n        model: str,\\n        mirostat: Optional[str],\\n        mirostat_eta: Optional[float] = None,\\n        mirostat_tau: Optional[float] = None,\\n        ### When a callback component is added to Langflow, the comment must be uncommented.###\\n        # callback_manager: Optional[CallbackManager] = None,\\n        # callbacks: Optional[List[Callbacks]] = None,\\n        #######################################################################################\\n        repeat_last_n: Optional[int] = None,\\n        verbose: Optional[bool] = None,\\n        cache: Optional[bool] = None,\\n        num_ctx: Optional[int] = None,\\n        num_gpu: Optional[int] = None,\\n        format: Optional[str] = None,\\n        metadata: Optional[Dict[str, Any]] = None,\\n        num_thread: Optional[int] = None,\\n        repeat_penalty: Optional[float] = None,\\n        stop: Optional[List[str]] = None,\\n        system: Optional[str] = None,\\n        tags: Optional[List[str]] = None,\\n        temperature: Optional[float] = None,\\n        template: Optional[str] = None,\\n        tfs_z: Optional[float] = None,\\n        timeout: Optional[int] = None,\\n        top_k: Optional[int] = None,\\n        top_p: Optional[int] = None,\\n    ) -> BaseChatModel:\\n        if not base_url:\\n            base_url = \\\"http://localhost:11434\\\"\\n\\n        # Mapping mirostat settings to their corresponding values\\n        mirostat_options = {\\\"Mirostat\\\": 1, \\\"Mirostat 2.0\\\": 2}\\n\\n        # Default to 0 for 'Disabled'\\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\\n\\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\\n        if mirostat_value == 0:\\n            mirostat_eta = None\\n            mirostat_tau = None\\n\\n        # Mapping system settings to their corresponding values\\n        llm_params = {\\n            \\\"base_url\\\": base_url,\\n            \\\"cache\\\": cache,\\n            \\\"model\\\": model,\\n            \\\"mirostat\\\": mirostat_value,\\n            \\\"format\\\": format,\\n            \\\"metadata\\\": metadata,\\n            \\\"tags\\\": tags,\\n            ## When a callback component is added to Langflow, the comment must be uncommented.##\\n            # \\\"callback_manager\\\": callback_manager,\\n            # \\\"callbacks\\\": callbacks,\\n            #####################################################################################\\n            \\\"mirostat_eta\\\": mirostat_eta,\\n            \\\"mirostat_tau\\\": mirostat_tau,\\n            \\\"num_ctx\\\": num_ctx,\\n            \\\"num_gpu\\\": num_gpu,\\n            \\\"num_thread\\\": num_thread,\\n            \\\"repeat_last_n\\\": repeat_last_n,\\n            \\\"repeat_penalty\\\": repeat_penalty,\\n            \\\"temperature\\\": temperature,\\n            \\\"stop\\\": stop,\\n            \\\"system\\\": system,\\n            \\\"template\\\": template,\\n            \\\"tfs_z\\\": tfs_z,\\n            \\\"timeout\\\": timeout,\\n            \\\"top_k\\\": top_k,\\n            \\\"top_p\\\": top_p,\\n            \\\"verbose\\\": verbose,\\n        }\\n\\n        # None Value remove\\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\\n\\n        try:\\n            output = ChatOllama(**llm_params)  # type: ignore\\n        except Exception as e:\\n            raise ValueError(\\\"Could not initialize Ollama LLM.\\\") from e\\n\\n        return output  # type: ignore\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"format\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"format\",\"display_name\":\"Format\",\"advanced\":true,\"dynamic\":false,\"info\":\"Specify the format of the output (e.g., json).\",\"title_case\":false,\"input_types\":[\"Text\"]},\"mirostat\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"Disabled\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"Disabled\",\"Mirostat\",\"Mirostat 2.0\"],\"name\":\"mirostat\",\"display_name\":\"Mirostat\",\"advanced\":true,\"dynamic\":false,\"info\":\"Enable/disable Mirostat sampling for controlling perplexity.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"mirostat_eta\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"mirostat_eta\",\"display_name\":\"Mirostat Eta\",\"advanced\":true,\"dynamic\":false,\"info\":\"Learning rate for Mirostat algorithm. (Default: 0.1)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"mirostat_tau\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"mirostat_tau\",\"display_name\":\"Mirostat Tau\",\"advanced\":true,\"dynamic\":false,\"info\":\"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"llama2\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"Refer to https://ollama.ai/library for more models.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"num_ctx\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_ctx\",\"display_name\":\"Context Window Size\",\"advanced\":true,\"dynamic\":false,\"info\":\"Size of the context window for generating tokens. (Default: 2048)\",\"title_case\":false},\"num_gpu\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_gpu\",\"display_name\":\"Number of GPUs\",\"advanced\":true,\"dynamic\":false,\"info\":\"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\"title_case\":false},\"num_thread\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_thread\",\"display_name\":\"Number of Threads\",\"advanced\":true,\"dynamic\":false,\"info\":\"Number of threads to use during computation. (Default: detected for optimal performance)\",\"title_case\":false},\"repeat_last_n\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"repeat_last_n\",\"display_name\":\"Repeat Last N\",\"advanced\":true,\"dynamic\":false,\"info\":\"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\"title_case\":false},\"repeat_penalty\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"repeat_penalty\",\"display_name\":\"Repeat Penalty\",\"advanced\":true,\"dynamic\":false,\"info\":\"Penalty for repetitions in generated text. (Default: 1.1)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"system\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"system\",\"display_name\":\"System\",\"advanced\":true,\"dynamic\":false,\"info\":\"System to use for generating text.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"Controls the creativity of model responses.\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"template\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"template\",\"display_name\":\"Template\",\"advanced\":true,\"dynamic\":false,\"info\":\"Template to use for generating text.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"tfs_z\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tfs_z\",\"display_name\":\"TFS Z\",\"advanced\":true,\"dynamic\":false,\"info\":\"Tail free sampling value. (Default: 1)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"timeout\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"timeout\",\"display_name\":\"Timeout\",\"advanced\":true,\"dynamic\":false,\"info\":\"Timeout for the request stream.\",\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"Limits token selection to top K. (Default: 40)\",\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"Works together with top-k. (Default: 0.9)\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"verbose\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"verbose\",\"display_name\":\"Verbose\",\"advanced\":false,\"dynamic\":false,\"info\":\"Whether to print out response text.\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Local LLM for chat with Ollama.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseChatModel\"],\"display_name\":\"ChatOllama\",\"documentation\":\"\",\"custom_fields\":{\"base_url\":null,\"model\":null,\"mirostat\":null,\"mirostat_eta\":null,\"mirostat_tau\":null,\"repeat_last_n\":null,\"verbose\":null,\"cache\":null,\"num_ctx\":null,\"num_gpu\":null,\"format\":null,\"metadata\":null,\"num_thread\":null,\"repeat_penalty\":null,\"stop\":null,\"system\":null,\"tags\":null,\"temperature\":null,\"template\":null,\"tfs_z\":null,\"timeout\":null,\"top_k\":null,\"top_p\":null},\"output_types\":[\"BaseChatModel\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"BaiduQianfanChatEndpointsSpecs\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_community.chat_models.baidu_qianfan_endpoint import QianfanChatEndpoint\\nfrom langchain.llms.base import BaseLLM\\nfrom pydantic.v1 import SecretStr\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass QianfanChatEndpointComponent(CustomComponent):\\n    display_name: str = \\\"QianfanChatEndpoint\\\"\\n    description: str = (\\n        \\\"Baidu Qianfan chat models. Get more detail from \\\"\\n        \\\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint.\\\"\\n    )\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"options\\\": [\\n                    \\\"ERNIE-Bot\\\",\\n                    \\\"ERNIE-Bot-turbo\\\",\\n                    \\\"BLOOMZ-7B\\\",\\n                    \\\"Llama-2-7b-chat\\\",\\n                    \\\"Llama-2-13b-chat\\\",\\n                    \\\"Llama-2-70b-chat\\\",\\n                    \\\"Qianfan-BLOOMZ-7B-compressed\\\",\\n                    \\\"Qianfan-Chinese-Llama-2-7B\\\",\\n                    \\\"ChatGLM2-6B-32K\\\",\\n                    \\\"AquilaChat-7B\\\",\\n                ],\\n                \\\"info\\\": \\\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\\\",\\n                \\\"required\\\": True,\\n            },\\n            \\\"qianfan_ak\\\": {\\n                \\\"display_name\\\": \\\"Qianfan Ak\\\",\\n                \\\"required\\\": True,\\n                \\\"password\\\": True,\\n                \\\"info\\\": \\\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\\\",\\n            },\\n            \\\"qianfan_sk\\\": {\\n                \\\"display_name\\\": \\\"Qianfan Sk\\\",\\n                \\\"required\\\": True,\\n                \\\"password\\\": True,\\n                \\\"info\\\": \\\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\\\",\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top p\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\\\",\\n                \\\"value\\\": 0.8,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\\\",\\n                \\\"value\\\": 0.95,\\n            },\\n            \\\"penalty_score\\\": {\\n                \\\"display_name\\\": \\\"Penalty Score\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\\\",\\n                \\\"value\\\": 1.0,\\n            },\\n            \\\"endpoint\\\": {\\n                \\\"display_name\\\": \\\"Endpoint\\\",\\n                \\\"info\\\": \\\"Endpoint of the Qianfan LLM, required if custom model used.\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        model: str = \\\"ERNIE-Bot-turbo\\\",\\n        qianfan_ak: Optional[str] = None,\\n        qianfan_sk: Optional[str] = None,\\n        top_p: Optional[float] = None,\\n        temperature: Optional[float] = None,\\n        penalty_score: Optional[float] = None,\\n        endpoint: Optional[str] = None,\\n    ) -> BaseLLM:\\n        try:\\n            output = QianfanChatEndpoint(  # type: ignore\\n                model=model,\\n                qianfan_ak=SecretStr(qianfan_ak) if qianfan_ak else None,\\n                qianfan_sk=SecretStr(qianfan_sk) if qianfan_sk else None,\\n                top_p=top_p,\\n                temperature=temperature,\\n                penalty_score=penalty_score,\\n                endpoint=endpoint,\\n            )\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to Baidu Qianfan API.\\\") from e\\n        return output  # type: ignore\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"endpoint\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"endpoint\",\"display_name\":\"Endpoint\",\"advanced\":false,\"dynamic\":false,\"info\":\"Endpoint of the Qianfan LLM, required if custom model used.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"ERNIE-Bot-turbo\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"ERNIE-Bot\",\"ERNIE-Bot-turbo\",\"BLOOMZ-7B\",\"Llama-2-7b-chat\",\"Llama-2-13b-chat\",\"Llama-2-70b-chat\",\"Qianfan-BLOOMZ-7B-compressed\",\"Qianfan-Chinese-Llama-2-7B\",\"ChatGLM2-6B-32K\",\"AquilaChat-7B\"],\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\",\"title_case\":false,\"input_types\":[\"Text\"]},\"penalty_score\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"penalty_score\",\"display_name\":\"Penalty Score\",\"advanced\":false,\"dynamic\":false,\"info\":\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"qianfan_ak\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"qianfan_ak\",\"display_name\":\"Qianfan Ak\",\"advanced\":false,\"dynamic\":false,\"info\":\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\"title_case\":false,\"input_types\":[\"Text\"]},\"qianfan_sk\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"qianfan_sk\",\"display_name\":\"Qianfan Sk\",\"advanced\":false,\"dynamic\":false,\"info\":\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.95,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top p\",\"advanced\":false,\"dynamic\":false,\"info\":\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Baidu Qianfan chat models. Get more detail from https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\"],\"display_name\":\"QianfanChatEndpoint\",\"documentation\":\"\",\"custom_fields\":{\"model\":null,\"qianfan_ak\":null,\"qianfan_sk\":null,\"top_p\":null,\"temperature\":null,\"penalty_score\":null,\"endpoint\":null},\"output_types\":[\"BaseLLM\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"LlamaCppSpecs\":{\"template\":{\"metadata\":{\"type\":\"Dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"metadata\",\"display_name\":\"Metadata\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_kwargs\":{\"type\":\"Dict\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_path\":{\"type\":\"file\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".bin\"],\"file_path\":\"\",\"password\":false,\"name\":\"model_path\",\"display_name\":\"Model Path\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"cache\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"cache\",\"display_name\":\"Cache\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"client\":{\"type\":\"Any\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"client\",\"display_name\":\"Client\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional, List, Dict, Any\\nfrom langflow import CustomComponent\\nfrom langchain_community.llms.llamacpp import LlamaCpp\\n\\n\\nclass LlamaCppComponent(CustomComponent):\\n    display_name = \\\"LlamaCpp\\\"\\n    description = \\\"llama.cpp model.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/llamacpp\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"grammar\\\": {\\\"display_name\\\": \\\"Grammar\\\", \\\"advanced\\\": True},\\n            \\\"cache\\\": {\\\"display_name\\\": \\\"Cache\\\", \\\"advanced\\\": True},\\n            \\\"client\\\": {\\\"display_name\\\": \\\"Client\\\", \\\"advanced\\\": True},\\n            \\\"echo\\\": {\\\"display_name\\\": \\\"Echo\\\", \\\"advanced\\\": True},\\n            \\\"f16_kv\\\": {\\\"display_name\\\": \\\"F16 KV\\\", \\\"advanced\\\": True},\\n            \\\"grammar_path\\\": {\\\"display_name\\\": \\\"Grammar Path\\\", \\\"advanced\\\": True},\\n            \\\"last_n_tokens_size\\\": {\\\"display_name\\\": \\\"Last N Tokens Size\\\", \\\"advanced\\\": True},\\n            \\\"logits_all\\\": {\\\"display_name\\\": \\\"Logits All\\\", \\\"advanced\\\": True},\\n            \\\"logprobs\\\": {\\\"display_name\\\": \\\"Logprobs\\\", \\\"advanced\\\": True},\\n            \\\"lora_base\\\": {\\\"display_name\\\": \\\"Lora Base\\\", \\\"advanced\\\": True},\\n            \\\"lora_path\\\": {\\\"display_name\\\": \\\"Lora Path\\\", \\\"advanced\\\": True},\\n            \\\"max_tokens\\\": {\\\"display_name\\\": \\\"Max Tokens\\\", \\\"advanced\\\": True},\\n            \\\"metadata\\\": {\\\"display_name\\\": \\\"Metadata\\\", \\\"advanced\\\": True},\\n            \\\"model_kwargs\\\": {\\\"display_name\\\": \\\"Model Kwargs\\\", \\\"advanced\\\": True},\\n            \\\"model_path\\\": {\\n                \\\"display_name\\\": \\\"Model Path\\\",\\n                \\\"field_type\\\": \\\"file\\\",\\n                \\\"file_types\\\": [\\\".bin\\\"],\\n                \\\"required\\\": True,\\n            },\\n            \\\"n_batch\\\": {\\\"display_name\\\": \\\"N Batch\\\", \\\"advanced\\\": True},\\n            \\\"n_ctx\\\": {\\\"display_name\\\": \\\"N Ctx\\\", \\\"advanced\\\": True},\\n            \\\"n_gpu_layers\\\": {\\\"display_name\\\": \\\"N GPU Layers\\\", \\\"advanced\\\": True},\\n            \\\"n_parts\\\": {\\\"display_name\\\": \\\"N Parts\\\", \\\"advanced\\\": True},\\n            \\\"n_threads\\\": {\\\"display_name\\\": \\\"N Threads\\\", \\\"advanced\\\": True},\\n            \\\"repeat_penalty\\\": {\\\"display_name\\\": \\\"Repeat Penalty\\\", \\\"advanced\\\": True},\\n            \\\"rope_freq_base\\\": {\\\"display_name\\\": \\\"Rope Freq Base\\\", \\\"advanced\\\": True},\\n            \\\"rope_freq_scale\\\": {\\\"display_name\\\": \\\"Rope Freq Scale\\\", \\\"advanced\\\": True},\\n            \\\"seed\\\": {\\\"display_name\\\": \\\"Seed\\\", \\\"advanced\\\": True},\\n            \\\"stop\\\": {\\\"display_name\\\": \\\"Stop\\\", \\\"advanced\\\": True},\\n            \\\"streaming\\\": {\\\"display_name\\\": \\\"Streaming\\\", \\\"advanced\\\": True},\\n            \\\"suffix\\\": {\\\"display_name\\\": \\\"Suffix\\\", \\\"advanced\\\": True},\\n            \\\"tags\\\": {\\\"display_name\\\": \\\"Tags\\\", \\\"advanced\\\": True},\\n            \\\"temperature\\\": {\\\"display_name\\\": \\\"Temperature\\\"},\\n            \\\"top_k\\\": {\\\"display_name\\\": \\\"Top K\\\", \\\"advanced\\\": True},\\n            \\\"top_p\\\": {\\\"display_name\\\": \\\"Top P\\\", \\\"advanced\\\": True},\\n            \\\"use_mlock\\\": {\\\"display_name\\\": \\\"Use Mlock\\\", \\\"advanced\\\": True},\\n            \\\"use_mmap\\\": {\\\"display_name\\\": \\\"Use Mmap\\\", \\\"advanced\\\": True},\\n            \\\"verbose\\\": {\\\"display_name\\\": \\\"Verbose\\\", \\\"advanced\\\": True},\\n            \\\"vocab_only\\\": {\\\"display_name\\\": \\\"Vocab Only\\\", \\\"advanced\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        model_path: str,\\n        grammar: Optional[str] = None,\\n        cache: Optional[bool] = None,\\n        client: Optional[Any] = None,\\n        echo: Optional[bool] = False,\\n        f16_kv: bool = True,\\n        grammar_path: Optional[str] = None,\\n        last_n_tokens_size: Optional[int] = 64,\\n        logits_all: bool = False,\\n        logprobs: Optional[int] = None,\\n        lora_base: Optional[str] = None,\\n        lora_path: Optional[str] = None,\\n        max_tokens: Optional[int] = 256,\\n        metadata: Optional[Dict] = None,\\n        model_kwargs: Dict = {},\\n        n_batch: Optional[int] = 8,\\n        n_ctx: int = 512,\\n        n_gpu_layers: Optional[int] = 1,\\n        n_parts: int = -1,\\n        n_threads: Optional[int] = 1,\\n        repeat_penalty: Optional[float] = 1.1,\\n        rope_freq_base: float = 10000.0,\\n        rope_freq_scale: float = 1.0,\\n        seed: int = -1,\\n        stop: Optional[List[str]] = [],\\n        streaming: bool = True,\\n        suffix: Optional[str] = \\\"\\\",\\n        tags: Optional[List[str]] = [],\\n        temperature: Optional[float] = 0.8,\\n        top_k: Optional[int] = 40,\\n        top_p: Optional[float] = 0.95,\\n        use_mlock: bool = False,\\n        use_mmap: Optional[bool] = True,\\n        verbose: bool = True,\\n        vocab_only: bool = False,\\n    ) -> LlamaCpp:\\n        return LlamaCpp(\\n            model_path=model_path,\\n            grammar=grammar,\\n            cache=cache,\\n            client=client,\\n            echo=echo,\\n            f16_kv=f16_kv,\\n            grammar_path=grammar_path,\\n            last_n_tokens_size=last_n_tokens_size,\\n            logits_all=logits_all,\\n            logprobs=logprobs,\\n            lora_base=lora_base,\\n            lora_path=lora_path,\\n            max_tokens=max_tokens,\\n            metadata=metadata,\\n            model_kwargs=model_kwargs,\\n            n_batch=n_batch,\\n            n_ctx=n_ctx,\\n            n_gpu_layers=n_gpu_layers,\\n            n_parts=n_parts,\\n            n_threads=n_threads,\\n            repeat_penalty=repeat_penalty,\\n            rope_freq_base=rope_freq_base,\\n            rope_freq_scale=rope_freq_scale,\\n            seed=seed,\\n            stop=stop,\\n            streaming=streaming,\\n            suffix=suffix,\\n            tags=tags,\\n            temperature=temperature,\\n            top_k=top_k,\\n            top_p=top_p,\\n            use_mlock=use_mlock,\\n            use_mmap=use_mmap,\\n            verbose=verbose,\\n            vocab_only=vocab_only,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"echo\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"echo\",\"display_name\":\"Echo\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"f16_kv\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"f16_kv\",\"display_name\":\"F16 KV\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"grammar\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"grammar\",\"display_name\":\"Grammar\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"grammar_path\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"grammar_path\",\"display_name\":\"Grammar Path\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"last_n_tokens_size\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":64,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"last_n_tokens_size\",\"display_name\":\"Last N Tokens Size\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"logits_all\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"logits_all\",\"display_name\":\"Logits All\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"logprobs\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"logprobs\",\"display_name\":\"Logprobs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"lora_base\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"lora_base\",\"display_name\":\"Lora Base\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"lora_path\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"lora_path\",\"display_name\":\"Lora Path\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":256,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_batch\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_batch\",\"display_name\":\"N Batch\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_ctx\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":512,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_ctx\",\"display_name\":\"N Ctx\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_gpu_layers\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_gpu_layers\",\"display_name\":\"N GPU Layers\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_parts\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":-1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_parts\",\"display_name\":\"N Parts\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n_threads\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_threads\",\"display_name\":\"N Threads\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"repeat_penalty\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1.1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"repeat_penalty\",\"display_name\":\"Repeat Penalty\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"rope_freq_base\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":10000.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"rope_freq_base\",\"display_name\":\"Rope Freq Base\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"rope_freq_scale\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"rope_freq_scale\",\"display_name\":\"Rope Freq Scale\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"seed\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":-1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"seed\",\"display_name\":\"Seed\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"stop\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":[],\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"stop\",\"display_name\":\"Stop\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"streaming\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"streaming\",\"display_name\":\"Streaming\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"suffix\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"suffix\",\"display_name\":\"Suffix\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"tags\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":[],\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tags\",\"display_name\":\"Tags\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":40,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.95,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"use_mlock\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"use_mlock\",\"display_name\":\"Use Mlock\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"use_mmap\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"use_mmap\",\"display_name\":\"Use Mmap\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"verbose\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"verbose\",\"display_name\":\"Verbose\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"vocab_only\":{\"type\":\"bool\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"vocab_only\",\"display_name\":\"Vocab Only\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"llama.cpp model.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"LlamaCpp\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\",\"LLM\"],\"display_name\":\"LlamaCpp\",\"documentation\":\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/llamacpp\",\"custom_fields\":{\"model_path\":null,\"grammar\":null,\"cache\":null,\"client\":null,\"echo\":null,\"f16_kv\":null,\"grammar_path\":null,\"last_n_tokens_size\":null,\"logits_all\":null,\"logprobs\":null,\"lora_base\":null,\"lora_path\":null,\"max_tokens\":null,\"metadata\":null,\"model_kwargs\":null,\"n_batch\":null,\"n_ctx\":null,\"n_gpu_layers\":null,\"n_parts\":null,\"n_threads\":null,\"repeat_penalty\":null,\"rope_freq_base\":null,\"rope_freq_scale\":null,\"seed\":null,\"stop\":null,\"streaming\":null,\"suffix\":null,\"tags\":null,\"temperature\":null,\"top_k\":null,\"top_p\":null,\"use_mlock\":null,\"use_mmap\":null,\"verbose\":null,\"vocab_only\":null},\"output_types\":[\"LlamaCpp\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"AnthropicSpecs\":{\"template\":{\"anthropic_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"anthropic_api_key\",\"display_name\":\"Anthropic API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"anthropic_api_url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"anthropic_api_url\",\"display_name\":\"Anthropic API URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_community.llms.anthropic import Anthropic\\nfrom pydantic.v1 import SecretStr\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, NestedDict\\n\\n\\nclass AnthropicComponent(CustomComponent):\\n    display_name = \\\"Anthropic\\\"\\n    description = \\\"Anthropic large language models.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"anthropic_api_key\\\": {\\n                \\\"display_name\\\": \\\"Anthropic API Key\\\",\\n                \\\"type\\\": str,\\n                \\\"password\\\": True,\\n            },\\n            \\\"anthropic_api_url\\\": {\\n                \\\"display_name\\\": \\\"Anthropic API URL\\\",\\n                \\\"type\\\": str,\\n            },\\n            \\\"model_kwargs\\\": {\\n                \\\"display_name\\\": \\\"Model Kwargs\\\",\\n                \\\"field_type\\\": \\\"NestedDict\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        anthropic_api_key: str,\\n        anthropic_api_url: str,\\n        model_kwargs: NestedDict = {},\\n        temperature: Optional[float] = None,\\n    ) -> BaseLanguageModel:\\n        return Anthropic(\\n            anthropic_api_key=SecretStr(anthropic_api_key),\\n            anthropic_api_url=anthropic_api_url,\\n            model_kwargs=model_kwargs,\\n            temperature=temperature,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"model_kwargs\":{\"type\":\"NestedDict\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Anthropic large language models.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\"],\"display_name\":\"Anthropic\",\"documentation\":\"\",\"custom_fields\":{\"anthropic_api_key\":null,\"anthropic_api_url\":null,\"model_kwargs\":null,\"temperature\":null},\"output_types\":[\"BaseLanguageModel\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"AnthropicLLMSpecs\":{\"template\":{\"anthropic_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"anthropic_api_key\",\"display_name\":\"Anthropic API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"Your Anthropic API key.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"api_endpoint\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"api_endpoint\",\"display_name\":\"API Endpoint\",\"advanced\":false,\"dynamic\":false,\"info\":\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_community.chat_models.anthropic import ChatAnthropic\\nfrom langchain.llms.base import BaseLanguageModel\\nfrom pydantic.v1 import SecretStr\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass AnthropicLLM(CustomComponent):\\n    display_name: str = \\\"AnthropicLLM\\\"\\n    description: str = \\\"Anthropic Chat&Completion large language models.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"options\\\": [\\n                    \\\"claude-2.1\\\",\\n                    \\\"claude-2.0\\\",\\n                    \\\"claude-instant-1.2\\\",\\n                    \\\"claude-instant-1\\\",\\n                    # Add more models as needed\\n                ],\\n                \\\"info\\\": \\\"https://python.langchain.com/docs/integrations/chat/anthropic\\\",\\n                \\\"required\\\": True,\\n                \\\"value\\\": \\\"claude-2.1\\\",\\n            },\\n            \\\"anthropic_api_key\\\": {\\n                \\\"display_name\\\": \\\"Anthropic API Key\\\",\\n                \\\"required\\\": True,\\n                \\\"password\\\": True,\\n                \\\"info\\\": \\\"Your Anthropic API key.\\\",\\n            },\\n            \\\"max_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Tokens\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"value\\\": 256,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"value\\\": 0.7,\\n            },\\n            \\\"api_endpoint\\\": {\\n                \\\"display_name\\\": \\\"API Endpoint\\\",\\n                \\\"info\\\": \\\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        model: str,\\n        anthropic_api_key: Optional[str] = None,\\n        max_tokens: Optional[int] = None,\\n        temperature: Optional[float] = None,\\n        api_endpoint: Optional[str] = None,\\n    ) -> BaseLanguageModel:\\n        # Set default API endpoint if not provided\\n        if not api_endpoint:\\n            api_endpoint = \\\"https://api.anthropic.com\\\"\\n\\n        try:\\n            output = ChatAnthropic(\\n                model_name=model,\\n                anthropic_api_key=SecretStr(anthropic_api_key) if anthropic_api_key else None,\\n                max_tokens_to_sample=max_tokens,  # type: ignore\\n                temperature=temperature,\\n                anthropic_api_url=api_endpoint,\\n            )\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to Anthropic API.\\\") from e\\n        return output\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"max_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":256,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"claude-2.1\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"claude-2.1\",\"claude-2.0\",\"claude-instant-1.2\",\"claude-instant-1\"],\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"https://python.langchain.com/docs/integrations/chat/anthropic\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.7,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Anthropic Chat&Completion large language models.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\"],\"display_name\":\"AnthropicLLM\",\"documentation\":\"\",\"custom_fields\":{\"model\":null,\"anthropic_api_key\":null,\"max_tokens\":null,\"temperature\":null,\"api_endpoint\":null},\"output_types\":[\"BaseLanguageModel\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"CohereSpecs\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langchain_community.llms.cohere import Cohere\\nfrom langchain_core.language_models.base import BaseLanguageModel\\nfrom langflow import CustomComponent\\n\\n\\nclass CohereComponent(CustomComponent):\\n    display_name = \\\"Cohere\\\"\\n    description = \\\"Cohere large language models.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"cohere_api_key\\\": {\\\"display_name\\\": \\\"Cohere API Key\\\", \\\"type\\\": \\\"password\\\", \\\"password\\\": True},\\n            \\\"max_tokens\\\": {\\\"display_name\\\": \\\"Max Tokens\\\", \\\"default\\\": 256, \\\"type\\\": \\\"int\\\", \\\"show\\\": True},\\n            \\\"temperature\\\": {\\\"display_name\\\": \\\"Temperature\\\", \\\"default\\\": 0.75, \\\"type\\\": \\\"float\\\", \\\"show\\\": True},\\n        }\\n\\n    def build(\\n        self,\\n        cohere_api_key: str,\\n        max_tokens: int = 256,\\n        temperature: float = 0.75,\\n    ) -> BaseLanguageModel:\\n        return Cohere(cohere_api_key=cohere_api_key, max_tokens=max_tokens, temperature=temperature)  # type: ignore\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"cohere_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"cohere_api_key\",\"display_name\":\"Cohere API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_tokens\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":256,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"temperature\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.75,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Cohere large language models.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\"],\"display_name\":\"Cohere\",\"documentation\":\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere\",\"custom_fields\":{\"cohere_api_key\":null,\"max_tokens\":null,\"temperature\":null},\"output_types\":[\"BaseLanguageModel\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"GoogleGenerativeAISpecs\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain_google_genai import ChatGoogleGenerativeAI  # type: ignore\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, RangeSpec\\nfrom pydantic.v1.types import SecretStr\\n\\n\\nclass GoogleGenerativeAIComponent(CustomComponent):\\n    display_name: str = \\\"Google Generative AI\\\"\\n    description: str = \\\"A component that uses Google Generative AI to generate text.\\\"\\n    documentation: str = \\\"http://docs.langflow.org/components/custom\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"google_api_key\\\": {\\n                \\\"display_name\\\": \\\"Google API Key\\\",\\n                \\\"info\\\": \\\"The Google API Key to use for the Google Generative AI.\\\",\\n            },\\n            \\\"max_output_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Output Tokens\\\",\\n                \\\"info\\\": \\\"The maximum number of tokens to generate.\\\",\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"info\\\": \\\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\\\",\\n            },\\n            \\\"top_k\\\": {\\n                \\\"display_name\\\": \\\"Top K\\\",\\n                \\\"info\\\": \\\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\\\",\\n                \\\"range_spec\\\": RangeSpec(min=0, max=2, step=0.1),\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top P\\\",\\n                \\\"info\\\": \\\"The maximum cumulative probability of tokens to consider when sampling.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"n\\\": {\\n                \\\"display_name\\\": \\\"N\\\",\\n                \\\"info\\\": \\\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model\\\",\\n                \\\"info\\\": \\\"The name of the model to use. Supported examples: gemini-pro\\\",\\n                \\\"options\\\": [\\\"gemini-pro\\\", \\\"gemini-pro-vision\\\"],\\n            },\\n            \\\"code\\\": {\\n                \\\"advanced\\\": True,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        google_api_key: str,\\n        model: str,\\n        max_output_tokens: Optional[int] = None,\\n        temperature: float = 0.1,\\n        top_k: Optional[int] = None,\\n        top_p: Optional[float] = None,\\n        n: Optional[int] = 1,\\n    ) -> BaseLanguageModel:\\n        return ChatGoogleGenerativeAI(\\n            model=model,\\n            max_output_tokens=max_output_tokens or None,  # type: ignore\\n            temperature=temperature,\\n            top_k=top_k or None,\\n            top_p=top_p or None,  # type: ignore\\n            n=n or 1,\\n            google_api_key=SecretStr(google_api_key),\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":true,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"google_api_key\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"google_api_key\",\"display_name\":\"Google API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"The Google API Key to use for the Google Generative AI.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"max_output_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_output_tokens\",\"display_name\":\"Max Output Tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"The maximum number of tokens to generate.\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"gemini-pro\",\"gemini-pro-vision\"],\"name\":\"model\",\"display_name\":\"Model\",\"advanced\":false,\"dynamic\":false,\"info\":\"The name of the model to use. Supported examples: gemini-pro\",\"title_case\":false,\"input_types\":[\"Text\"]},\"n\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n\",\"display_name\":\"N\",\"advanced\":true,\"dynamic\":false,\"info\":\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\"title_case\":false},\"temperature\":{\"type\":\"float\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\"rangeSpec\":{\"min\":0.0,\"max\":2.0,\"step\":0.1},\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"The maximum cumulative probability of tokens to consider when sampling.\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"A component that uses Google Generative AI to generate text.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\"],\"display_name\":\"Google Generative AI\",\"documentation\":\"http://docs.langflow.org/components/custom\",\"custom_fields\":{\"google_api_key\":null,\"model\":null,\"max_output_tokens\":null,\"temperature\":null,\"top_k\":null,\"top_p\":null,\"n\":null},\"output_types\":[\"BaseLanguageModel\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"BaiduQianfanLLMEndpointsSpecs\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\nfrom langflow import CustomComponent\\nfrom langchain.llms.baidu_qianfan_endpoint import QianfanLLMEndpoint\\nfrom langchain.llms.base import BaseLLM\\n\\n\\nclass QianfanLLMEndpointComponent(CustomComponent):\\n    display_name: str = \\\"QianfanLLMEndpoint\\\"\\n    description: str = (\\n        \\\"Baidu Qianfan hosted open source or customized models. \\\"\\n        \\\"Get more detail from https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\\\"\\n    )\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"options\\\": [\\n                    \\\"ERNIE-Bot\\\",\\n                    \\\"ERNIE-Bot-turbo\\\",\\n                    \\\"BLOOMZ-7B\\\",\\n                    \\\"Llama-2-7b-chat\\\",\\n                    \\\"Llama-2-13b-chat\\\",\\n                    \\\"Llama-2-70b-chat\\\",\\n                    \\\"Qianfan-BLOOMZ-7B-compressed\\\",\\n                    \\\"Qianfan-Chinese-Llama-2-7B\\\",\\n                    \\\"ChatGLM2-6B-32K\\\",\\n                    \\\"AquilaChat-7B\\\",\\n                ],\\n                \\\"info\\\": \\\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\\\",\\n                \\\"required\\\": True,\\n            },\\n            \\\"qianfan_ak\\\": {\\n                \\\"display_name\\\": \\\"Qianfan Ak\\\",\\n                \\\"required\\\": True,\\n                \\\"password\\\": True,\\n                \\\"info\\\": \\\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\\\",\\n            },\\n            \\\"qianfan_sk\\\": {\\n                \\\"display_name\\\": \\\"Qianfan Sk\\\",\\n                \\\"required\\\": True,\\n                \\\"password\\\": True,\\n                \\\"info\\\": \\\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\\\",\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top p\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\\\",\\n                \\\"value\\\": 0.8,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\\\",\\n                \\\"value\\\": 0.95,\\n            },\\n            \\\"penalty_score\\\": {\\n                \\\"display_name\\\": \\\"Penalty Score\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\\\",\\n                \\\"value\\\": 1.0,\\n            },\\n            \\\"endpoint\\\": {\\n                \\\"display_name\\\": \\\"Endpoint\\\",\\n                \\\"info\\\": \\\"Endpoint of the Qianfan LLM, required if custom model used.\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        model: str = \\\"ERNIE-Bot-turbo\\\",\\n        qianfan_ak: Optional[str] = None,\\n        qianfan_sk: Optional[str] = None,\\n        top_p: Optional[float] = None,\\n        temperature: Optional[float] = None,\\n        penalty_score: Optional[float] = None,\\n        endpoint: Optional[str] = None,\\n    ) -> BaseLLM:\\n        try:\\n            output = QianfanLLMEndpoint(  # type: ignore\\n                model=model,\\n                qianfan_ak=qianfan_ak,\\n                qianfan_sk=qianfan_sk,\\n                top_p=top_p,\\n                temperature=temperature,\\n                penalty_score=penalty_score,\\n                endpoint=endpoint,\\n            )\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to Baidu Qianfan API.\\\") from e\\n        return output  # type: ignore\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"endpoint\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"endpoint\",\"display_name\":\"Endpoint\",\"advanced\":false,\"dynamic\":false,\"info\":\"Endpoint of the Qianfan LLM, required if custom model used.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"ERNIE-Bot-turbo\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"ERNIE-Bot\",\"ERNIE-Bot-turbo\",\"BLOOMZ-7B\",\"Llama-2-7b-chat\",\"Llama-2-13b-chat\",\"Llama-2-70b-chat\",\"Qianfan-BLOOMZ-7B-compressed\",\"Qianfan-Chinese-Llama-2-7B\",\"ChatGLM2-6B-32K\",\"AquilaChat-7B\"],\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\",\"title_case\":false,\"input_types\":[\"Text\"]},\"penalty_score\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1.0,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"penalty_score\",\"display_name\":\"Penalty Score\",\"advanced\":false,\"dynamic\":false,\"info\":\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"qianfan_ak\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"qianfan_ak\",\"display_name\":\"Qianfan Ak\",\"advanced\":false,\"dynamic\":false,\"info\":\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\"title_case\":false,\"input_types\":[\"Text\"]},\"qianfan_sk\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"qianfan_sk\",\"display_name\":\"Qianfan Sk\",\"advanced\":false,\"dynamic\":false,\"info\":\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.95,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top p\",\"advanced\":false,\"dynamic\":false,\"info\":\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Baidu Qianfan hosted open source or customized models. Get more detail from https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\"],\"display_name\":\"QianfanLLMEndpoint\",\"documentation\":\"\",\"custom_fields\":{\"model\":null,\"qianfan_ak\":null,\"qianfan_sk\":null,\"top_p\":null,\"temperature\":null,\"penalty_score\":null,\"endpoint\":null},\"output_types\":[\"BaseLLM\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"ChatLiteLLMSpecs\":{\"template\":{\"api_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"api_key\",\"display_name\":\"API key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Any, Callable, Dict, Optional, Union\\n\\nfrom langchain_community.chat_models.litellm import ChatLiteLLM, ChatLiteLLMException\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel\\n\\n\\nclass ChatLiteLLMComponent(CustomComponent):\\n    display_name = \\\"ChatLiteLLM\\\"\\n    description = \\\"`LiteLLM` collection of large language models.\\\"\\n    documentation = \\\"https://python.langchain.com/docs/integrations/chat/litellm\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model name\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": True,\\n                \\\"info\\\": \\\"The name of the model to use. For example, `gpt-3.5-turbo`.\\\",\\n            },\\n            \\\"api_key\\\": {\\n                \\\"display_name\\\": \\\"API key\\\",\\n                \\\"field_type\\\": \\\"str\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"password\\\": True,\\n            },\\n            \\\"provider\\\": {\\n                \\\"display_name\\\": \\\"Provider\\\",\\n                \\\"info\\\": \\\"The provider of the API key.\\\",\\n                \\\"options\\\": [\\n                    \\\"OpenAI\\\",\\n                    \\\"Azure\\\",\\n                    \\\"Anthropic\\\",\\n                    \\\"Replicate\\\",\\n                    \\\"Cohere\\\",\\n                    \\\"OpenRouter\\\",\\n                ],\\n            },\\n            \\\"streaming\\\": {\\n                \\\"display_name\\\": \\\"Streaming\\\",\\n                \\\"field_type\\\": \\\"bool\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n                \\\"default\\\": True,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"default\\\": 0.7,\\n            },\\n            \\\"model_kwargs\\\": {\\n                \\\"display_name\\\": \\\"Model kwargs\\\",\\n                \\\"field_type\\\": \\\"dict\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n                \\\"default\\\": {},\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top p\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n            },\\n            \\\"top_k\\\": {\\n                \\\"display_name\\\": \\\"Top k\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n            },\\n            \\\"n\\\": {\\n                \\\"display_name\\\": \\\"N\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n                \\\"info\\\": \\\"Number of chat completions to generate for each prompt. \\\"\\n                \\\"Note that the API may not return the full n completions if duplicates are generated.\\\",\\n                \\\"default\\\": 1,\\n            },\\n            \\\"max_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max tokens\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"default\\\": 256,\\n                \\\"info\\\": \\\"The maximum number of tokens to generate for each chat completion.\\\",\\n            },\\n            \\\"max_retries\\\": {\\n                \\\"display_name\\\": \\\"Max retries\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n                \\\"default\\\": 6,\\n            },\\n            \\\"verbose\\\": {\\n                \\\"display_name\\\": \\\"Verbose\\\",\\n                \\\"field_type\\\": \\\"bool\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n                \\\"default\\\": False,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        model: str,\\n        provider: str,\\n        api_key: Optional[str] = None,\\n        streaming: bool = True,\\n        temperature: Optional[float] = 0.7,\\n        model_kwargs: Optional[Dict[str, Any]] = {},\\n        top_p: Optional[float] = None,\\n        top_k: Optional[int] = None,\\n        n: int = 1,\\n        max_tokens: int = 256,\\n        max_retries: int = 6,\\n        verbose: bool = False,\\n    ) -> Union[BaseLanguageModel, Callable]:\\n        try:\\n            import litellm  # type: ignore\\n\\n            litellm.drop_params = True\\n            litellm.set_verbose = verbose\\n        except ImportError:\\n            raise ChatLiteLLMException(\\n                \\\"Could not import litellm python package. \\\" \\\"Please install it with `pip install litellm`\\\"\\n            )\\n        provider_map = {\\n            \\\"OpenAI\\\": \\\"openai_api_key\\\",\\n            \\\"Azure\\\": \\\"azure_api_key\\\",\\n            \\\"Anthropic\\\": \\\"anthropic_api_key\\\",\\n            \\\"Replicate\\\": \\\"replicate_api_key\\\",\\n            \\\"Cohere\\\": \\\"cohere_api_key\\\",\\n            \\\"OpenRouter\\\": \\\"openrouter_api_key\\\",\\n        }\\n        # Set the API key based on the provider\\n        kwarg = {provider_map[provider]: api_key}\\n\\n        LLM = ChatLiteLLM(\\n            model=model,\\n            client=None,\\n            streaming=streaming,\\n            temperature=temperature,\\n            model_kwargs=model_kwargs if model_kwargs is not None else {},\\n            top_p=top_p,\\n            top_k=top_k,\\n            n=n,\\n            max_tokens=max_tokens,\\n            max_retries=max_retries,\\n            **kwarg,\\n        )\\n        return LLM\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"max_retries\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":6,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_retries\",\"display_name\":\"Max retries\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"max_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":256,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"The maximum number of tokens to generate for each chat completion.\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model\",\"display_name\":\"Model name\",\"advanced\":false,\"dynamic\":false,\"info\":\"The name of the model to use. For example, `gpt-3.5-turbo`.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_kwargs\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"n\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":1,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n\",\"display_name\":\"N\",\"advanced\":true,\"dynamic\":false,\"info\":\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\"title_case\":false},\"provider\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"OpenAI\",\"Azure\",\"Anthropic\",\"Replicate\",\"Cohere\",\"OpenRouter\"],\"name\":\"provider\",\"display_name\":\"Provider\",\"advanced\":false,\"dynamic\":false,\"info\":\"The provider of the API key.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"streaming\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"streaming\",\"display_name\":\"Streaming\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.7,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top k\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"top_p\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top p\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"verbose\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"verbose\",\"display_name\":\"Verbose\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"`LiteLLM` collection of large language models.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"Callable\"],\"display_name\":\"ChatLiteLLM\",\"documentation\":\"https://python.langchain.com/docs/integrations/chat/litellm\",\"custom_fields\":{\"model\":null,\"provider\":null,\"api_key\":null,\"streaming\":null,\"temperature\":null,\"model_kwargs\":null,\"top_p\":null,\"top_k\":null,\"n\":null,\"max_tokens\":null,\"max_retries\":null,\"verbose\":null},\"output_types\":[\"BaseLanguageModel\",\"Callable\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"CTransformersSpecs\":{\"template\":{\"model_file\":{\"type\":\"file\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[\".bin\"],\"file_path\":\"\",\"password\":false,\"name\":\"model_file\",\"display_name\":\"Model File\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Dict, Optional\\n\\nfrom langchain_community.llms.ctransformers import CTransformers\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass CTransformersComponent(CustomComponent):\\n    display_name = \\\"CTransformers\\\"\\n    description = \\\"C Transformers LLM models\\\"\\n    documentation = \\\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/ctransformers\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"model\\\": {\\\"display_name\\\": \\\"Model\\\", \\\"required\\\": True},\\n            \\\"model_file\\\": {\\n                \\\"display_name\\\": \\\"Model File\\\",\\n                \\\"required\\\": False,\\n                \\\"field_type\\\": \\\"file\\\",\\n                \\\"file_types\\\": [\\\".bin\\\"],\\n            },\\n            \\\"model_type\\\": {\\\"display_name\\\": \\\"Model Type\\\", \\\"required\\\": True},\\n            \\\"config\\\": {\\n                \\\"display_name\\\": \\\"Config\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n                \\\"field_type\\\": \\\"dict\\\",\\n                \\\"value\\\": '{\\\"top_k\\\":40,\\\"top_p\\\":0.95,\\\"temperature\\\":0.8,\\\"repetition_penalty\\\":1.1,\\\"last_n_tokens\\\":64,\\\"seed\\\":-1,\\\"max_new_tokens\\\":256,\\\"stop\\\":\\\"\\\",\\\"stream\\\":\\\"False\\\",\\\"reset\\\":\\\"True\\\",\\\"batch_size\\\":8,\\\"threads\\\":-1,\\\"context_length\\\":-1,\\\"gpu_layers\\\":0}',\\n            },\\n        }\\n\\n    def build(self, model: str, model_file: str, model_type: str, config: Optional[Dict] = None) -> CTransformers:\\n        return CTransformers(model=model, model_file=model_file, model_type=model_type, config=config)  # type: ignore\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"config\":{\"type\":\"dict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"{\\\"top_k\\\":40,\\\"top_p\\\":0.95,\\\"temperature\\\":0.8,\\\"repetition_penalty\\\":1.1,\\\"last_n_tokens\\\":64,\\\"seed\\\":-1,\\\"max_new_tokens\\\":256,\\\"stop\\\":\\\"\\\",\\\"stream\\\":\\\"False\\\",\\\"reset\\\":\\\"True\\\",\\\"batch_size\\\":8,\\\"threads\\\":-1,\\\"context_length\\\":-1,\\\"gpu_layers\\\":0}\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"config\",\"display_name\":\"Config\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model\",\"display_name\":\"Model\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_type\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_type\",\"display_name\":\"Model Type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"C Transformers LLM models\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"CTransformers\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\",\"LLM\"],\"display_name\":\"CTransformers\",\"documentation\":\"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/ctransformers\",\"custom_fields\":{\"model\":null,\"model_file\":null,\"model_type\":null,\"config\":null},\"output_types\":[\"CTransformers\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"HuggingFaceEndpointsSpecs\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langchain.llms.base import BaseLLM\\nfrom langchain.llms.huggingface_endpoint import HuggingFaceEndpoint\\nfrom langflow import CustomComponent\\n\\n\\nclass HuggingFaceEndpointsComponent(CustomComponent):\\n    display_name: str = \\\"Hugging Face Inference API\\\"\\n    description: str = \\\"LLM model from Hugging Face Inference API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"endpoint_url\\\": {\\\"display_name\\\": \\\"Endpoint URL\\\", \\\"password\\\": True},\\n            \\\"task\\\": {\\n                \\\"display_name\\\": \\\"Task\\\",\\n                \\\"options\\\": [\\\"text2text-generation\\\", \\\"text-generation\\\", \\\"summarization\\\"],\\n            },\\n            \\\"huggingfacehub_api_token\\\": {\\\"display_name\\\": \\\"API token\\\", \\\"password\\\": True},\\n            \\\"model_kwargs\\\": {\\n                \\\"display_name\\\": \\\"Model Keyword Arguments\\\",\\n                \\\"field_type\\\": \\\"code\\\",\\n            },\\n            \\\"code\\\": {\\\"show\\\": False},\\n        }\\n\\n    def build(\\n        self,\\n        endpoint_url: str,\\n        task: str = \\\"text2text-generation\\\",\\n        huggingfacehub_api_token: Optional[str] = None,\\n        model_kwargs: Optional[dict] = None,\\n    ) -> BaseLLM:\\n        try:\\n            output = HuggingFaceEndpoint(  # type: ignore\\n                endpoint_url=endpoint_url,\\n                task=task,\\n                huggingfacehub_api_token=huggingfacehub_api_token,\\n                model_kwargs=model_kwargs or {},\\n            )\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to HuggingFace Endpoints API.\\\") from e\\n        return output\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"endpoint_url\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"endpoint_url\",\"display_name\":\"Endpoint URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"huggingfacehub_api_token\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"huggingfacehub_api_token\",\"display_name\":\"API token\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"model_kwargs\":{\"type\":\"code\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Keyword Arguments\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"task\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"text2text-generation\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"text2text-generation\",\"text-generation\",\"summarization\"],\"name\":\"task\",\"display_name\":\"Task\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"LLM model from Hugging Face Inference API.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\"],\"display_name\":\"Hugging Face Inference API\",\"documentation\":\"\",\"custom_fields\":{\"endpoint_url\":null,\"task\":null,\"huggingfacehub_api_token\":null,\"model_kwargs\":null},\"output_types\":[\"BaseLLM\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"ChatOpenAISpecs\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional, Union\\n\\nfrom langchain.llms import BaseLLM\\nfrom langchain_community.chat_models.openai import ChatOpenAI\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import BaseLanguageModel, NestedDict\\n\\n\\nclass ChatOpenAIComponent(CustomComponent):\\n    display_name = \\\"ChatOpenAI\\\"\\n    description = \\\"`OpenAI` Chat large language models API.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"max_tokens\\\": {\\n                \\\"display_name\\\": \\\"Max Tokens\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n            },\\n            \\\"model_kwargs\\\": {\\n                \\\"display_name\\\": \\\"Model Kwargs\\\",\\n                \\\"advanced\\\": True,\\n                \\\"required\\\": False,\\n            },\\n            \\\"model_name\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"options\\\": [\\n                    \\\"gpt-4-turbo-preview\\\",\\n                    \\\"gpt-4-0125-preview\\\",\\n                    \\\"gpt-4-1106-preview\\\",\\n                    \\\"gpt-4-vision-preview\\\",\\n                    \\\"gpt-3.5-turbo-0125\\\",\\n                    \\\"gpt-3.5-turbo-1106\\\",\\n                ],\\n            },\\n            \\\"openai_api_base\\\": {\\n                \\\"display_name\\\": \\\"OpenAI API Base\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"info\\\": (\\n                    \\\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\\\n\\\\n\\\"\\n                    \\\"You can change this to use other APIs like JinaChat, LocalAI and Prem.\\\"\\n                ),\\n            },\\n            \\\"openai_api_key\\\": {\\n                \\\"display_name\\\": \\\"OpenAI API Key\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"password\\\": True,\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"advanced\\\": False,\\n                \\\"required\\\": False,\\n                \\\"value\\\": 0.7,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        max_tokens: Optional[int] = 256,\\n        model_kwargs: NestedDict = {},\\n        model_name: str = \\\"gpt-4-1106-preview\\\",\\n        openai_api_base: Optional[str] = None,\\n        openai_api_key: Optional[str] = None,\\n        temperature: float = 0.7,\\n    ) -> Union[BaseLanguageModel, BaseLLM]:\\n        if not openai_api_base:\\n            openai_api_base = \\\"https://api.openai.com/v1\\\"\\n        return ChatOpenAI(\\n            max_tokens=max_tokens,\\n            model_kwargs=model_kwargs,\\n            model=model_name,\\n            base_url=openai_api_base,\\n            api_key=openai_api_key,\\n            temperature=temperature,\\n        )\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"max_tokens\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":256,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"max_tokens\",\"display_name\":\"Max Tokens\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_kwargs\":{\"type\":\"NestedDict\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":{},\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model_kwargs\",\"display_name\":\"Model Kwargs\",\"advanced\":true,\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"model_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"gpt-4-1106-preview\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"gpt-4-turbo-preview\",\"gpt-4-0125-preview\",\"gpt-4-1106-preview\",\"gpt-4-vision-preview\",\"gpt-3.5-turbo-0125\",\"gpt-3.5-turbo-1106\"],\"name\":\"model_name\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_api_base\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"openai_api_base\",\"display_name\":\"OpenAI API Base\",\"advanced\":false,\"dynamic\":false,\"info\":\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"openai_api_key\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":true,\"name\":\"openai_api_key\",\"display_name\":\"OpenAI API Key\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.7,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"`OpenAI` Chat large language models API.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\"],\"display_name\":\"ChatOpenAI\",\"documentation\":\"\",\"custom_fields\":{\"max_tokens\":null,\"model_kwargs\":null,\"model_name\":null,\"openai_api_base\":null,\"openai_api_key\":null,\"temperature\":null},\"output_types\":[\"BaseLanguageModel\",\"BaseLLM\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"OllamaLLMSpecs\":{\"template\":{\"base_url\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"base_url\",\"display_name\":\"Base URL\",\"advanced\":false,\"dynamic\":false,\"info\":\"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional\\n\\nfrom langchain.llms.base import BaseLLM\\nfrom langchain_community.llms.ollama import Ollama\\n\\nfrom langflow import CustomComponent\\n\\n\\nclass OllamaLLM(CustomComponent):\\n    display_name = \\\"Ollama\\\"\\n    description = \\\"Local LLM with Ollama.\\\"\\n\\n    def build_config(self) -> dict:\\n        return {\\n            \\\"base_url\\\": {\\n                \\\"display_name\\\": \\\"Base URL\\\",\\n                \\\"info\\\": \\\"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\\\",\\n            },\\n            \\\"model\\\": {\\n                \\\"display_name\\\": \\\"Model Name\\\",\\n                \\\"value\\\": \\\"llama2\\\",\\n                \\\"info\\\": \\\"Refer to https://ollama.ai/library for more models.\\\",\\n            },\\n            \\\"temperature\\\": {\\n                \\\"display_name\\\": \\\"Temperature\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"value\\\": 0.8,\\n                \\\"info\\\": \\\"Controls the creativity of model responses.\\\",\\n            },\\n            \\\"mirostat\\\": {\\n                \\\"display_name\\\": \\\"Mirostat\\\",\\n                \\\"options\\\": [\\\"Disabled\\\", \\\"Mirostat\\\", \\\"Mirostat 2.0\\\"],\\n                \\\"info\\\": \\\"Enable/disable Mirostat sampling for controlling perplexity.\\\",\\n                \\\"value\\\": \\\"Disabled\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"mirostat_eta\\\": {\\n                \\\"display_name\\\": \\\"Mirostat Eta\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Learning rate influencing the algorithm's response to feedback.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"mirostat_tau\\\": {\\n                \\\"display_name\\\": \\\"Mirostat Tau\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Controls balance between coherence and diversity.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"num_ctx\\\": {\\n                \\\"display_name\\\": \\\"Context Window Size\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Size of the context window for generating the next token.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"num_gpu\\\": {\\n                \\\"display_name\\\": \\\"Number of GPUs\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Number of GPUs to use for computation.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"num_thread\\\": {\\n                \\\"display_name\\\": \\\"Number of Threads\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Number of threads to use during computation.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"repeat_last_n\\\": {\\n                \\\"display_name\\\": \\\"Repeat Last N\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Sets how far back the model looks to prevent repetition.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"repeat_penalty\\\": {\\n                \\\"display_name\\\": \\\"Repeat Penalty\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Penalty for repetitions in generated text.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"stop\\\": {\\n                \\\"display_name\\\": \\\"Stop Tokens\\\",\\n                \\\"info\\\": \\\"List of tokens to signal the model to stop generating text.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"tfs_z\\\": {\\n                \\\"display_name\\\": \\\"TFS Z\\\",\\n                \\\"field_type\\\": \\\"float\\\",\\n                \\\"info\\\": \\\"Tail free sampling to reduce impact of less probable tokens.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_k\\\": {\\n                \\\"display_name\\\": \\\"Top K\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Limits token selection to top K for reducing nonsense generation.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n            \\\"top_p\\\": {\\n                \\\"display_name\\\": \\\"Top P\\\",\\n                \\\"field_type\\\": \\\"int\\\",\\n                \\\"info\\\": \\\"Works with top-k to control diversity of generated text.\\\",\\n                \\\"advanced\\\": True,\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        base_url: Optional[str],\\n        model: str,\\n        temperature: Optional[float],\\n        mirostat: Optional[str],\\n        mirostat_eta: Optional[float] = None,\\n        mirostat_tau: Optional[float] = None,\\n        num_ctx: Optional[int] = None,\\n        num_gpu: Optional[int] = None,\\n        num_thread: Optional[int] = None,\\n        repeat_last_n: Optional[int] = None,\\n        repeat_penalty: Optional[float] = None,\\n        stop: Optional[List[str]] = None,\\n        tfs_z: Optional[float] = None,\\n        top_k: Optional[int] = None,\\n        top_p: Optional[int] = None,\\n    ) -> BaseLLM:\\n        if not base_url:\\n            base_url = \\\"http://localhost:11434\\\"\\n\\n        # Mapping mirostat settings to their corresponding values\\n        mirostat_options = {\\\"Mirostat\\\": 1, \\\"Mirostat 2.0\\\": 2}\\n\\n        # Default to 0 for 'Disabled'\\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\\n\\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\\n        if mirostat_value == 0:\\n            mirostat_eta = None\\n            mirostat_tau = None\\n\\n        try:\\n            llm = Ollama(\\n                base_url=base_url,\\n                model=model,\\n                mirostat=mirostat_value,\\n                mirostat_eta=mirostat_eta,\\n                mirostat_tau=mirostat_tau,\\n                num_ctx=num_ctx,\\n                num_gpu=num_gpu,\\n                num_thread=num_thread,\\n                repeat_last_n=repeat_last_n,\\n                repeat_penalty=repeat_penalty,\\n                temperature=temperature,\\n                stop=stop,\\n                tfs_z=tfs_z,\\n                top_k=top_k,\\n                top_p=top_p,\\n            )\\n\\n        except Exception as e:\\n            raise ValueError(\\\"Could not connect to Ollama.\\\") from e\\n\\n        return llm\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"mirostat\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"Disabled\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"Disabled\",\"Mirostat\",\"Mirostat 2.0\"],\"name\":\"mirostat\",\"display_name\":\"Mirostat\",\"advanced\":true,\"dynamic\":false,\"info\":\"Enable/disable Mirostat sampling for controlling perplexity.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"mirostat_eta\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"mirostat_eta\",\"display_name\":\"Mirostat Eta\",\"advanced\":true,\"dynamic\":false,\"info\":\"Learning rate influencing the algorithm's response to feedback.\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"mirostat_tau\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"mirostat_tau\",\"display_name\":\"Mirostat Tau\",\"advanced\":true,\"dynamic\":false,\"info\":\"Controls balance between coherence and diversity.\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"model\":{\"type\":\"str\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"llama2\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"model\",\"display_name\":\"Model Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"Refer to https://ollama.ai/library for more models.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"num_ctx\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_ctx\",\"display_name\":\"Context Window Size\",\"advanced\":true,\"dynamic\":false,\"info\":\"Size of the context window for generating the next token.\",\"title_case\":false},\"num_gpu\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_gpu\",\"display_name\":\"Number of GPUs\",\"advanced\":true,\"dynamic\":false,\"info\":\"Number of GPUs to use for computation.\",\"title_case\":false},\"num_thread\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"num_thread\",\"display_name\":\"Number of Threads\",\"advanced\":true,\"dynamic\":false,\"info\":\"Number of threads to use during computation.\",\"title_case\":false},\"repeat_last_n\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"repeat_last_n\",\"display_name\":\"Repeat Last N\",\"advanced\":true,\"dynamic\":false,\"info\":\"Sets how far back the model looks to prevent repetition.\",\"title_case\":false},\"repeat_penalty\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"repeat_penalty\",\"display_name\":\"Repeat Penalty\",\"advanced\":true,\"dynamic\":false,\"info\":\"Penalty for repetitions in generated text.\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"stop\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"stop\",\"display_name\":\"Stop Tokens\",\"advanced\":true,\"dynamic\":false,\"info\":\"List of tokens to signal the model to stop generating text.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"temperature\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":0.8,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"temperature\",\"display_name\":\"Temperature\",\"advanced\":false,\"dynamic\":false,\"info\":\"Controls the creativity of model responses.\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"tfs_z\":{\"type\":\"float\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"tfs_z\",\"display_name\":\"TFS Z\",\"advanced\":true,\"dynamic\":false,\"info\":\"Tail free sampling to reduce impact of less probable tokens.\",\"rangeSpec\":{\"min\":-1.0,\"max\":1.0,\"step\":0.1},\"title_case\":false},\"top_k\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_k\",\"display_name\":\"Top K\",\"advanced\":true,\"dynamic\":false,\"info\":\"Limits token selection to top K for reducing nonsense generation.\",\"title_case\":false},\"top_p\":{\"type\":\"int\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"top_p\",\"display_name\":\"Top P\",\"advanced\":true,\"dynamic\":false,\"info\":\"Works with top-k to control diversity of generated text.\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Local LLM with Ollama.\",\"base_classes\":[\"BaseLanguageModel\",\"Runnable\",\"Generic\",\"RunnableSerializable\",\"Serializable\",\"object\",\"BaseLLM\"],\"display_name\":\"Ollama\",\"documentation\":\"\",\"custom_fields\":{\"base_url\":null,\"model\":null,\"temperature\":null,\"mirostat\":null,\"mirostat_eta\":null,\"mirostat_tau\":null,\"num_ctx\":null,\"num_gpu\":null,\"num_thread\":null,\"repeat_last_n\":null,\"repeat_penalty\":null,\"stop\":null,\"tfs_z\":null,\"top_k\":null,\"top_p\":null},\"output_types\":[\"BaseLLM\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"io\":{\"ChatOutput\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional, Union\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\nfrom langflow.schema import Record\\n\\n\\nclass ChatOutput(CustomComponent):\\n    display_name = \\\"Chat Output\\\"\\n    description = \\\"Used to send a message to the chat.\\\"\\n\\n    field_config = {\\n        \\\"code\\\": {\\n            \\\"show\\\": True,\\n        }\\n    }\\n\\n    def build_config(self):\\n        return {\\n            \\\"message\\\": {\\\"input_types\\\": [\\\"Text\\\"], \\\"display_name\\\": \\\"Message\\\"},\\n            \\\"sender\\\": {\\n                \\\"options\\\": [\\\"Machine\\\", \\\"User\\\"],\\n                \\\"display_name\\\": \\\"Sender Type\\\",\\n            },\\n            \\\"sender_name\\\": {\\\"display_name\\\": \\\"Sender Name\\\"},\\n            \\\"session_id\\\": {\\n                \\\"display_name\\\": \\\"Session ID\\\",\\n                \\\"info\\\": \\\"Session ID of the chat history.\\\",\\n                \\\"input_types\\\": [\\\"Text\\\"],\\n            },\\n            \\\"return_record\\\": {\\n                \\\"display_name\\\": \\\"Return Record\\\",\\n                \\\"info\\\": \\\"Return the message as a record containing the sender, sender_name, and session_id.\\\",\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        sender: Optional[str] = \\\"Machine\\\",\\n        sender_name: Optional[str] = \\\"AI\\\",\\n        session_id: Optional[str] = None,\\n        message: Optional[str] = None,\\n        return_record: Optional[bool] = False,\\n    ) -> Union[Text, Record]:\\n        if return_record:\\n            if isinstance(message, Record):\\n                # Update the data of the record\\n                message.data[\\\"sender\\\"] = sender\\n                message.data[\\\"sender_name\\\"] = sender_name\\n                message.data[\\\"session_id\\\"] = session_id\\n            else:\\n                message = Record(\\n                    text=message,\\n                    data={\\n                        \\\"sender\\\": sender,\\n                        \\\"sender_name\\\": sender_name,\\n                        \\\"session_id\\\": session_id,\\n                    },\\n                )\\n        if not message:\\n            message = \\\"\\\"\\n        self.status = message\\n        return message\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"message\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"message\",\"display_name\":\"Message\",\"advanced\":false,\"input_types\":[\"Text\",\"Text\"],\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"return_record\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_record\",\"display_name\":\"Return Record\",\"advanced\":false,\"dynamic\":false,\"info\":\"Return the message as a record containing the sender, sender_name, and session_id.\",\"title_case\":false},\"sender\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"Machine\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"Machine\",\"User\"],\"name\":\"sender\",\"display_name\":\"Sender Type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"sender_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"AI\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"sender_name\",\"display_name\":\"Sender Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"session_id\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"session_id\",\"display_name\":\"Session ID\",\"advanced\":false,\"input_types\":[\"Text\",\"Text\"],\"dynamic\":false,\"info\":\"Session ID of the chat history.\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Used to send a message to the chat.\",\"base_classes\":[\"Text\",\"object\",\"Record\"],\"display_name\":\"Chat Output\",\"documentation\":\"\",\"custom_fields\":{\"sender\":null,\"sender_name\":null,\"session_id\":null,\"message\":null,\"return_record\":null},\"output_types\":[\"Text\",\"Record\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"MessageHistory\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional\\n\\nfrom langflow import CustomComponent\\nfrom langflow.memory import get_messages\\nfrom langflow.schema import Record\\n\\n\\nclass MessageHistoryComponent(CustomComponent):\\n    display_name = \\\"Message History\\\"\\n    description = \\\"Used to retrieve stored messages.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"sender\\\": {\\n                \\\"options\\\": [\\\"Machine\\\", \\\"User\\\"],\\n                \\\"display_name\\\": \\\"Sender Type\\\",\\n            },\\n            \\\"sender_name\\\": {\\\"display_name\\\": \\\"Sender Name\\\"},\\n            \\\"file_path\\\": {\\n                \\\"display_name\\\": \\\"File Path\\\",\\n                \\\"info\\\": \\\"Path of the local JSON file to store the messages. It should be a unique path for each chat history.\\\",\\n            },\\n            \\\"n_messages\\\": {\\n                \\\"display_name\\\": \\\"Number of Messages\\\",\\n                \\\"info\\\": \\\"Number of messages to retrieve.\\\",\\n            },\\n            \\\"session_id\\\": {\\n                \\\"display_name\\\": \\\"Session ID\\\",\\n                \\\"info\\\": \\\"Session ID of the chat history.\\\",\\n                \\\"input_types\\\": [\\\"Text\\\"],\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        sender: Optional[str] = None,\\n        sender_name: Optional[str] = None,\\n        session_id: Optional[str] = None,\\n        n_messages: int = 5,\\n    ) -> List[Record]:\\n        messages = get_messages(\\n            sender=sender,\\n            sender_name=sender_name,\\n            session_id=session_id,\\n            limit=n_messages,\\n        )\\n        self.status = messages\\n        return messages\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"n_messages\":{\"type\":\"int\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":5,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"n_messages\",\"display_name\":\"Number of Messages\",\"advanced\":false,\"dynamic\":false,\"info\":\"Number of messages to retrieve.\",\"title_case\":false},\"sender\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"Machine\",\"User\"],\"name\":\"sender\",\"display_name\":\"Sender Type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"sender_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"sender_name\",\"display_name\":\"Sender Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"session_id\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"session_id\",\"display_name\":\"Session ID\",\"advanced\":false,\"input_types\":[\"Text\",\"Text\"],\"dynamic\":false,\"info\":\"Session ID of the chat history.\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"Used to retrieve stored messages.\",\"base_classes\":[\"Record\"],\"display_name\":\"Message History\",\"documentation\":\"\",\"custom_fields\":{\"sender\":null,\"sender_name\":null,\"session_id\":null,\"n_messages\":null},\"output_types\":[\"Record\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"TextOutput\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass TextOutput(CustomComponent):\\n    display_name = \\\"Text Output\\\"\\n    description = \\\"Used to pass text output to the next component.\\\"\\n\\n    field_config = {\\n        \\\"value\\\": {\\\"display_name\\\": \\\"Value\\\"},\\n    }\\n\\n    def build(self, value: Optional[str] = \\\"\\\") -> Text:\\n        self.status = value\\n        if not value:\\n            value = \\\"\\\"\\n        return value\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"value\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"value\",\"display_name\":\"Value\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Used to pass text output to the next component.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"Text Output\",\"documentation\":\"\",\"custom_fields\":{\"value\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"StoreMessages\":{\"template\":{\"records\":{\"type\":\"Record\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"records\",\"display_name\":\"Records\",\"advanced\":false,\"dynamic\":false,\"info\":\"The list of records to store. Each record should contain the keys 'sender', 'sender_name', and 'session_id'.\",\"title_case\":false},\"texts\":{\"type\":\"Text\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"texts\",\"display_name\":\"Texts\",\"advanced\":false,\"dynamic\":false,\"info\":\"The list of texts to store. If records is not provided, texts must be provided.\",\"title_case\":false},\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import List, Optional\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\nfrom langflow.memory import add_messages\\nfrom langflow.schema import Record\\n\\n\\nclass StoreMessages(CustomComponent):\\n    display_name = \\\"Store Messages\\\"\\n    description = \\\"Used to store messages.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"records\\\": {\\n                \\\"display_name\\\": \\\"Records\\\",\\n                \\\"info\\\": \\\"The list of records to store. Each record should contain the keys 'sender', 'sender_name', and 'session_id'.\\\",\\n            },\\n            \\\"texts\\\": {\\n                \\\"display_name\\\": \\\"Texts\\\",\\n                \\\"info\\\": \\\"The list of texts to store. If records is not provided, texts must be provided.\\\",\\n            },\\n            \\\"session_id\\\": {\\n                \\\"display_name\\\": \\\"Session ID\\\",\\n                \\\"info\\\": \\\"The session ID to store.\\\",\\n            },\\n            \\\"sender\\\": {\\n                \\\"display_name\\\": \\\"Sender\\\",\\n                \\\"info\\\": \\\"The sender to store.\\\",\\n            },\\n            \\\"sender_name\\\": {\\n                \\\"display_name\\\": \\\"Sender Name\\\",\\n                \\\"info\\\": \\\"The sender name to store.\\\",\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        records: Optional[List[Record]] = None,\\n        texts: Optional[List[Text]] = None,\\n        session_id: Optional[str] = None,\\n        sender: Optional[str] = None,\\n        sender_name: Optional[str] = None,\\n    ) -> List[Record]:\\n        # Records is the main way to store messages\\n        # If records is not provided, we can use texts\\n        # but we need to create the records from the texts\\n        # and the other parameters\\n        if not texts and not records:\\n            raise ValueError(\\\"Either texts or records must be provided.\\\")\\n\\n        if not records:\\n            records = []\\n            if not session_id or not sender or not sender_name:\\n                raise ValueError(\\\"If passing texts, session_id, sender, and sender_name must be provided.\\\")\\n            for text in texts:\\n                record = Record(\\n                    text=text,\\n                    data={\\n                        \\\"session_id\\\": session_id,\\n                        \\\"sender\\\": sender,\\n                        \\\"sender_name\\\": sender_name,\\n                    },\\n                )\\n                records.append(record)\\n        elif isinstance(records, Record):\\n            records = [records]\\n\\n        self.status = records\\n        records = add_messages(records)\\n        return records\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"sender\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"sender\",\"display_name\":\"Sender\",\"advanced\":false,\"dynamic\":false,\"info\":\"The sender to store.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"sender_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"sender_name\",\"display_name\":\"Sender Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"The sender name to store.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"session_id\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"session_id\",\"display_name\":\"Session ID\",\"advanced\":false,\"dynamic\":false,\"info\":\"The session ID to store.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Used to store messages.\",\"base_classes\":[\"Record\"],\"display_name\":\"Store Messages\",\"documentation\":\"\",\"custom_fields\":{\"records\":null,\"texts\":null,\"session_id\":null,\"sender\":null,\"sender_name\":null},\"output_types\":[\"Record\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"ChatInput\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langflow import CustomComponent\\nfrom langflow.schema import Record\\n\\n\\nclass ChatInput(CustomComponent):\\n    display_name = \\\"Chat Input\\\"\\n    description = \\\"Used to get user input from the chat.\\\"\\n\\n    def build_config(self):\\n        return {\\n            \\\"message\\\": {\\n                \\\"input_types\\\": [\\\"Text\\\"],\\n                \\\"display_name\\\": \\\"Message\\\",\\n                \\\"multiline\\\": True,\\n            },\\n            \\\"sender\\\": {\\n                \\\"options\\\": [\\\"Machine\\\", \\\"User\\\"],\\n                \\\"display_name\\\": \\\"Sender Type\\\",\\n            },\\n            \\\"sender_name\\\": {\\\"display_name\\\": \\\"Sender Name\\\"},\\n            \\\"session_id\\\": {\\n                \\\"display_name\\\": \\\"Session ID\\\",\\n                \\\"info\\\": \\\"Session ID of the chat history.\\\",\\n            },\\n            \\\"return_record\\\": {\\n                \\\"display_name\\\": \\\"Return Record\\\",\\n                \\\"info\\\": \\\"Return the message as a record containing the sender, sender_name, and session_id.\\\",\\n            },\\n        }\\n\\n    def build(\\n        self,\\n        sender: Optional[str] = \\\"User\\\",\\n        sender_name: Optional[str] = \\\"User\\\",\\n        message: Optional[str] = None,\\n        session_id: Optional[str] = None,\\n        return_record: Optional[bool] = False,\\n    ) -> Record:\\n        if return_record:\\n            if isinstance(message, Record):\\n                # Update the data of the record\\n                message.data[\\\"sender\\\"] = sender\\n                message.data[\\\"sender_name\\\"] = sender_name\\n                message.data[\\\"session_id\\\"] = session_id\\n            else:\\n                message = Record(\\n                    text=message,\\n                    data={\\n                        \\\"sender\\\": sender,\\n                        \\\"sender_name\\\": sender_name,\\n                        \\\"session_id\\\": session_id,\\n                    },\\n                )\\n        if not message:\\n            message = \\\"\\\"\\n        self.status = message\\n        return message\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"message\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"message\",\"display_name\":\"Message\",\"advanced\":false,\"input_types\":[\"Text\",\"Text\"],\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"return_record\":{\"type\":\"bool\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"return_record\",\"display_name\":\"Return Record\",\"advanced\":false,\"dynamic\":false,\"info\":\"Return the message as a record containing the sender, sender_name, and session_id.\",\"title_case\":false},\"sender\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":true,\"show\":true,\"multiline\":false,\"value\":\"User\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"options\":[\"Machine\",\"User\"],\"name\":\"sender\",\"display_name\":\"Sender Type\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"sender_name\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"User\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"sender_name\",\"display_name\":\"Sender Name\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"session_id\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"session_id\",\"display_name\":\"Session ID\",\"advanced\":false,\"dynamic\":false,\"info\":\"Session ID of the chat history.\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Used to get user input from the chat.\",\"base_classes\":[\"Record\"],\"display_name\":\"Chat Input\",\"documentation\":\"\",\"custom_fields\":{\"sender\":null,\"sender_name\":null,\"message\":null,\"session_id\":null,\"return_record\":null},\"output_types\":[\"Record\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true},\"TextInput\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from typing import Optional\\n\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Text\\n\\n\\nclass TextInput(CustomComponent):\\n    display_name = \\\"Text Input\\\"\\n    description = \\\"Used to pass text input to the next component.\\\"\\n\\n    field_config = {\\n        \\\"value\\\": {\\\"display_name\\\": \\\"Value\\\"},\\n    }\\n\\n    def build(self, value: Optional[str] = \\\"\\\") -> Text:\\n        self.status = value\\n        if not value:\\n            value = \\\"\\\"\\n        return value\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":false,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"value\":{\"type\":\"str\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"value\",\"display_name\":\"Value\",\"advanced\":false,\"dynamic\":false,\"info\":\"\",\"title_case\":false,\"input_types\":[\"Text\"]},\"_type\":\"CustomComponent\"},\"description\":\"Used to pass text input to the next component.\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"Text Input\",\"documentation\":\"\",\"custom_fields\":{\"value\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}},\"prompts\":{\"Prompt\":{\"template\":{\"code\":{\"type\":\"code\",\"required\":true,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":true,\"value\":\"from langchain_core.prompts import PromptTemplate\\nfrom langflow import CustomComponent\\nfrom langflow.field_typing import Prompt, InputField, Text\\n\\n\\nclass PromptComponent(CustomComponent):\\n    display_name: str = \\\"Prompt\\\"\\n    description: str = \\\"A component for creating prompts using templates\\\"\\n    beta = True\\n\\n    def build_config(self):\\n        return {\\n            \\\"template\\\": InputField(display_name=\\\"Template\\\"),\\n            \\\"code\\\": InputField(advanced=True),\\n        }\\n\\n    def build(\\n        self,\\n        template: Prompt,\\n        **kwargs,\\n    ) -> Text:\\n        prompt_template = PromptTemplate.from_template(template)\\n\\n        attributes_to_check = [\\\"text\\\", \\\"page_content\\\"]\\n        for key, value in kwargs.items():\\n            for attribute in attributes_to_check:\\n                if hasattr(value, attribute):\\n                    kwargs[key] = getattr(value, attribute)\\n\\n        try:\\n            formated_prompt = prompt_template.format(**kwargs)\\n        except Exception as exc:\\n            raise ValueError(f\\\"Error formatting prompt: {exc}\\\") from exc\\n        self.status = f'Prompt: \\\"{formated_prompt}\\\"'\\n        return formated_prompt\\n\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"code\",\"advanced\":true,\"dynamic\":true,\"info\":\"\",\"title_case\":false},\"template\":{\"type\":\"prompt\",\"required\":false,\"placeholder\":\"\",\"list\":false,\"show\":true,\"multiline\":false,\"value\":\"\",\"fileTypes\":[],\"file_path\":\"\",\"password\":false,\"name\":\"template\",\"display_name\":\"Template\",\"advanced\":false,\"input_types\":[\"Text\"],\"dynamic\":false,\"info\":\"\",\"title_case\":false},\"_type\":\"CustomComponent\"},\"description\":\"A component for creating prompts using templates\",\"base_classes\":[\"Text\",\"object\"],\"display_name\":\"Prompt\",\"documentation\":\"\",\"custom_fields\":{\"template\":null},\"output_types\":[\"Text\"],\"field_formatters\":{},\"pinned\":false,\"beta\":true}}}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 2.771
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:30.976Z",
        "time": 0.753,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/store/check/",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "16"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:30 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"enabled\":true}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.753
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:30.976Z",
        "time": 0.525,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/store/check/api_key",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "38"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:30 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"has_api_key\":false,\"is_valid\":false}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.525
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:30.976Z",
        "time": 0.658,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/auto_login",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "227"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:30 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            },
            {
              "name": "set-cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc; Path=/; SameSite=none; Secure"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"access_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc\",\"refresh_token\":null,\"token_type\":\"bearer\"}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.658
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:31.023Z",
        "time": 0.787,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/users/whoami",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "253"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:30 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"id\":\"0389fb29-daa6-408c-b8cb-b8ff8d17343a\",\"username\":\"langflow\",\"profile_image\":null,\"is_active\":true,\"is_superuser\":true,\"create_at\":\"2024-02-28T14:31:41.362911\",\"updated_at\":\"2024-02-28T14:32:30.982826\",\"last_login_at\":\"2024-02-28T14:32:30.982478\"}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.787
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:32.479Z",
        "time": 0.836,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/flows/",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/flows"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "2"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:31 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "[]"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.836
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:36.617Z",
        "time": 1.679,
        "request": {
          "method": "POST",
          "url": "http://localhost:3000/api/v1/flows/",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Content-Length",
              "value": "170"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Origin",
              "value": "http://localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/flows"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1,
          "postData": {
            "mimeType": "application/json",
            "text": "{\"name\":\"Untitled document\",\"data\":{\"nodes\":[],\"edges\":[],\"viewport\":{\"zoom\":1,\"x\":0,\"y\":0}},\"description\":\"Harness the Power of Conversational AI.\",\"is_component\":false}",
            "params": []
          }
        },
        "response": {
          "status": 201,
          "statusText": "Created",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "access-control-allow-credentials",
              "value": "true"
            },
            {
              "name": "access-control-allow-origin",
              "value": "http://localhost:3000"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "319"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:35 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            },
            {
              "name": "vary",
              "value": "Origin"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"name\":\"Untitled document\",\"description\":\"Harness the Power of Conversational AI.\",\"data\":{\"nodes\":[],\"edges\":[],\"viewport\":{\"zoom\":1,\"x\":0,\"y\":0}},\"is_component\":false,\"updated_at\":\"2024-02-28T14:32:36.621261\",\"folder\":null,\"id\":\"b3aad40d-cf3b-49d2-804f-bfa33b70beef\",\"user_id\":\"0389fb29-daa6-408c-b8cb-b8ff8d17343a\"}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 1.679
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:36.774Z",
        "time": 1.023,
        "request": {
          "method": "GET",
          "url": "http://localhost:3000/api/v1/monitor/builds?flow_id=b3aad40d-cf3b-49d2-804f-bfa33b70beef",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/flow/b3aad40d-cf3b-49d2-804f-bfa33b70beef"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [
            {
              "name": "flow_id",
              "value": "b3aad40d-cf3b-49d2-804f-bfa33b70beef"
            }
          ],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "20"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:35 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"vertex_builds\":{}}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 1.023
        }
      },
      {
        "startedDateTime": "2024-02-28T14:32:49.526Z",
        "time": 0.977,
        "request": {
          "method": "DELETE",
          "url": "http://localhost:3000/api/v1/flows/b3aad40d-cf3b-49d2-804f-bfa33b70beef",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Encoding",
              "value": "gzip, deflate, br, zstd"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Connection",
              "value": "keep-alive"
            },
            {
              "name": "Cookie",
              "value": "access_token_lf=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIwMzg5ZmIyOS1kYWE2LTQwOGMtYjhjYi1iOGZmOGQxNzM0M2EiLCJleHAiOjE3NDA2NjY3NTB9.ef5W5jwNOeVzU3JZ7ylLYf2MLEJcVxC4-fF7EK9Ecdc"
            },
            {
              "name": "Host",
              "value": "localhost:3000"
            },
            {
              "name": "Origin",
              "value": "http://localhost:3000"
            },
            {
              "name": "Referer",
              "value": "http://localhost:3000/flow/b3aad40d-cf3b-49d2-804f-bfa33b70beef"
            },
            {
              "name": "Sec-Fetch-Dest",
              "value": "empty"
            },
            {
              "name": "Sec-Fetch-Mode",
              "value": "cors"
            },
            {
              "name": "Sec-Fetch-Site",
              "value": "same-origin"
            },
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
            },
            {
              "name": "sec-ch-ua",
              "value": "\"Chromium\";v=\"123\", \"Not:A-Brand\";v=\"8\""
            },
            {
              "name": "sec-ch-ua-mobile",
              "value": "?0"
            },
            {
              "name": "sec-ch-ua-platform",
              "value": "\"Linux\""
            }
          ],
          "queryString": [],
          "headersSize": -1,
          "bodySize": -1
        },
        "response": {
          "status": 200,
          "statusText": "OK",
          "httpVersion": "HTTP/1.1",
          "cookies": [],
          "headers": [
            {
              "name": "access-control-allow-credentials",
              "value": "true"
            },
            {
              "name": "access-control-allow-origin",
              "value": "http://localhost:3000"
            },
            {
              "name": "connection",
              "value": "close"
            },
            {
              "name": "content-length",
              "value": "39"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "date",
              "value": "Wed, 28 Feb 2024 14:32:48 GMT"
            },
            {
              "name": "server",
              "value": "uvicorn"
            },
            {
              "name": "vary",
              "value": "Origin"
            }
          ],
          "content": {
            "size": -1,
            "mimeType": "application/json",
            "text": "{\"message\":\"Flow deleted successfully\"}"
          },
          "headersSize": -1,
          "bodySize": -1,
          "redirectURL": ""
        },
        "cache": {},
        "timings": {
          "send": -1,
          "wait": -1,
          "receive": 0.977
        }
      }
    ]
  }
}